{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGCN用データセット作り"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dist(df,col):\n",
    "    df_cnt = df.groupby([col]+['rating'])['time'].count().unstack(1,fill_value=0)\n",
    "    df_dist = pd.DataFrame(df_cnt.values / df_cnt.sum(1).values.reshape(-1,1),\n",
    "                                               columns=df_cnt.columns,\n",
    "                                               index=df_cnt.index)\n",
    "    return df_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon → SGCN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### user-product network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_dir = 'amazon'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "amazon_network = pd.read_csv('raw_data/{0}/{0}_network.csv'.format(amazon_dir),header=None)\n",
    "amazon_network.columns = ['user_id','product_id','rating','time']\n",
    "amazon_network['weight'] = amazon_network.rating.map(lambda x:(x-3)/2).round()\n",
    "\n",
    "amazon_gt = pd.read_csv('raw_data/{0}/{0}_gt.csv'.format(amazon_dir),header=None)\n",
    "amazon_gt.columns = ['user_id','label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "truncated_amazon_network = amazon_network.loc[amazon_network.weight!=0,['user_id','product_id','weight']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "label_encoder.fit(np.hstack((truncated_amazon_network.user_id,\n",
    "                                                   truncated_amazon_network.product_id,\n",
    "                                                   amazon_gt.user_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "truncated_amazon_network['id1'] = label_encoder.transform(truncated_amazon_network.user_id)\n",
    "\n",
    "truncated_amazon_network['id2'] = label_encoder.transform(truncated_amazon_network.product_id)\n",
    "\n",
    "amazon_gt['node_id'] = label_encoder.transform(amazon_gt.user_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### node features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dist = get_dist(amazon_network,'user_id')\n",
    "\n",
    "product_dist = get_dist(amazon_network,'product_id')\n",
    "\n",
    "# user_product_dist = user_dist.append(product_dist)\n",
    "\n",
    "user_product_dist = pd.concat([user_dist,product_dist],1).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "node_features_df = user_product_dist.loc[label_encoder.classes_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ファイル出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "truncated_amazon_network[['id1','id2','weight']].to_csv('input/{0}/{0}_network.csv'.format(amazon_dir),index=None)\n",
    "\n",
    "amazon_gt[['node_id','label']].to_csv('input/{0}/{0}_gt.csv'.format(amazon_dir),index=None)\n",
    "\n",
    "np.save(arr=label_encoder.classes_,file='input/{0}/{0}_label_encoder.npy'.format(amazon_dir))\n",
    "\n",
    "node_features_df.to_csv('input/{0}/{0}_node_feature.csv'.format(amazon_dir),index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## epinions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epinions_network = pd.read_csv('raw_data/epinions/epinions_network.csv',header=None)\n",
    "\n",
    "epinions_network.columns = ['id1','id2','rating','time']\n",
    "\n",
    "epinions_network['weight'] = epinions_network.rating.map(lambda x:-1 if x-3.5 < 0 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epinions_gt = pd.read_csv('raw_data/epinions/epinions_gt.csv',header=None)\n",
    "\n",
    "epinions_gt.columns = ['user_id','label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "label_encoder.fit(np.hstack((epinions_network.id1,\n",
    "                                                   epinions_network.id2,\n",
    "                                                   epinions_gt.user_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epinions_network['id1_'] = label_encoder.transform(epinions_network.id1)\n",
    "\n",
    "epinions_network['id2_'] = label_encoder.transform(epinions_network.id2)\n",
    "\n",
    "epinions_gt['node_id'] = label_encoder.transform(epinions_gt.user_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### node features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features_df = pd.concat([get_dist(epinions_network,'id1_'),get_dist(epinions_network,'id2_')],1).fillna(0).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ファイル出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epinions_network[['id1_','id2_','weight']].to_csv('input/epinions/epinions_network.csv',index=None)\n",
    "epinions_gt[['node_id','label']].to_csv('input/epinions/epinions_gt.csv',index=None)\n",
    "np.save(arr=label_encoder.classes_,file='input/epinions/epinions_label_encoder.npy')\n",
    "node_features_df.to_csv('input/epinions/epinions_node_feature.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## epinions_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_nodes = np.random.choice()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_network = pd.read_csv('raw_data/alpha/alpha_network.csv',header=None)\n",
    "\n",
    "alpha_network.columns = ['id1','id2','rating','time']\n",
    "\n",
    "alpha_network['weight'] = alpha_network.rating.map(lambda x:1 if x>0 else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_gt = pd.read_csv('raw_data/alpha/alpha_gt.csv',header=None)\n",
    "\n",
    "alpha_gt.columns = ['user_id','label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "label_encoder.fit(np.hstack((alpha_network.id1,\n",
    "                                                   alpha_network.id2,\n",
    "                                                   alpha_gt.user_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_network['id1_'] = label_encoder.transform(alpha_network.id1)\n",
    "\n",
    "alpha_network['id2_'] = label_encoder.transform(alpha_network.id2)\n",
    "\n",
    "alpha_gt['node_id'] = label_encoder.transform(alpha_gt.user_id)\n",
    "\n",
    "node_features_df = pd.concat([get_dist(alpha_network,'id1_'),get_dist(alpha_network,'id2_')],1).fillna(0).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_network[['id1_','id2_','weight']].to_csv('input/alpha/alpha_network.csv',index=None)\n",
    "alpha_gt[['node_id','label']].to_csv('input/alpha/alpha_gt.csv',index=None)\n",
    "np.save(arr=label_encoder.classes_,file='input/alpha/alpha_label_encoder.npy')\n",
    "node_features_df.to_csv('input/alpha/alpha_node_feature.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## otc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "otc_network = pd.read_csv('raw_data/otc/otc_network.csv',header=None)\n",
    "\n",
    "otc_network.columns = ['id1','id2','rating','time']\n",
    "\n",
    "otc_network['weight'] = otc_network.rating.map(lambda x:1 if x>0 else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "otc_gt = pd.read_csv('raw_data/otc/otc_gt.csv',header=None)\n",
    "\n",
    "otc_gt.columns = ['user_id','label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "label_encoder.fit(np.hstack((otc_network.id1,\n",
    "                                                   otc_network.id2,\n",
    "                                                   otc_gt.user_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "otc_network['id1_'] = label_encoder.transform(otc_network.id1)\n",
    "\n",
    "otc_network['id2_'] = label_encoder.transform(otc_network.id2)\n",
    "\n",
    "otc_gt['node_id'] = label_encoder.transform(otc_gt.user_id)\n",
    "\n",
    "node_features_df = pd.concat([get_dist(otc_network,'id1_'),get_dist(otc_network,'id2_')],1).fillna(0).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "otc_network[['id1_','id2_','weight']].to_csv('input/otc/otc_network.csv',index=None)\n",
    "otc_gt[['node_id','label']].to_csv('input/otc/otc_gt.csv',index=None)\n",
    "np.save(arr=label_encoder.classes_,file='input/otc/otc_label_encoder.npy')\n",
    "node_features_df.to_csv('input/otc/otc_node_feature.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon Extra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "file_path = 'http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Electronics_5.json.gz'\n",
    "review_df_raw = pd.read_json(file_path,lines=True)\n",
    "assert ~review_df_raw.duplicated(['asin','reviewerID']).any()\n",
    "\n",
    "def preprocessing(df):\n",
    "    df_ = df.copy()\n",
    "    # converting 'reviewTime' column to datetime\n",
    "    df_['reviewTime'] = pd.to_datetime(df_.reviewTime,format='%m %d, %Y')\n",
    "    # vote_sum and helpful rate, helpful_bin\n",
    "    df_['vote_sum'] = df_['helpful'].map(lambda x:x[1])\n",
    "    df_['helpful_rate'] = df_['helpful'].map(lambda x:x[0]/x[1] if x[1]>0 else float('nan'))\n",
    "    df_['helpful_bin'] = pd.cut(df_.helpful_rate,bins=np.arange(0,1.1,0.1),include_lowest=True,labels=range(10))    \n",
    "    # おかしいデータを取り除く\n",
    "    df_ = df_.loc[~(df_.helpful_rate>1.0)]\n",
    "    return df_\n",
    "\n",
    "review_df = preprocessing(review_df_raw)\n",
    "\n",
    "def generate_network_csv(df, from_date):\n",
    "    review_df_from_ = df.loc[df.reviewTime>=from_date]\n",
    "    return review_df_from_[['reviewerID','asin','overall','reviewTime']]\n",
    "\n",
    "def generate_gt(df,from_date):\n",
    "    reviewer_all_votes = \\\n",
    "        df.loc[df.reviewTime>=from_date].groupby('reviewerID',as_index=False)['helpful'].agg(lambda x:list(np.vstack(x).sum(0)))\n",
    "\n",
    "    reviewer_all_votes['vote_sum'] = reviewer_all_votes.helpful.map(lambda x:x[1])\n",
    "\n",
    "    reviewer_all_votes['rate'] = reviewer_all_votes.helpful.map(lambda x:x[0]/x[1])\n",
    "    selected_df = reviewer_all_votes.loc[(reviewer_all_votes.vote_sum>=50) &\n",
    "                                         ((reviewer_all_votes.rate<=0.25) | \n",
    "                                          (reviewer_all_votes.rate>=0.75))]\n",
    "    selected_df['label'] = selected_df['rate'].map(lambda x: -1 if x <= 0.25 else 1)\n",
    "    \n",
    "    return selected_df[['reviewerID','label']].set_index('reviewerID')\n",
    "\n",
    "amazon_network = generate_network_csv(review_df,pd.Timestamp(2013,1,1))\n",
    "\n",
    "amazon_gt = generate_gt(review_df,pd.Timestamp(2013,1,1))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appindix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## amazon user networkを作る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "self_joined = pd.merge(amazon_network,amazon_network,on='product_id',how='right')\n",
    "\n",
    "self_joined = self_joined.loc[~(self_joined.user_id_x==self_joined.user_id_y)]\n",
    "\n",
    "self_joined['sign'] = self_joined.weight_x*self_joined.weight_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "user_network = self_joined.loc[self_joined.sign!=0,['user_id_x','user_id_y','sign']]\n",
    "\n",
    "user_network = user_network.groupby(['user_id_x','user_id_y'],as_index=False)['sign'].mean().round()\n",
    "\n",
    "user_network = user_network.loc[user_network.sign!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "label_encoder.fit(np.hstack((user_network.user_id_x,\n",
    "                                                   user_network.user_id_y,\n",
    "                                                   amazon_gt.user_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_network['id1'] = label_encoder.transform(user_network.user_id_x)\n",
    "\n",
    "user_network['id2'] = label_encoder.transform(user_network.user_id_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_nx_network = user_network.copy()[['id1','id2','sign']]\n",
    "\n",
    "for_nx_network.columns = ['source','target','weight']\n",
    "\n",
    "G = nx.from_pandas_edgelist(for_nx_network,edge_attr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "amazon_user_network = nx.to_pandas_edgelist(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_gt['node_id'] = label_encoder.transform(amazon_gt.user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_user_network[['source','target','weight']].to_csv('input/amazon/user_network.csv',index=None)\n",
    "\n",
    "amazon_gt[['node_id','label']].to_csv('input/amazon/user_gt.csv',index=None)\n",
    "\n",
    "np.save(arr=label_encoder.classes_,file='input/amazon/user_label_encoder.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
