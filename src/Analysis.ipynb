{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!git branch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデルのアウトプットの分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sgcn import SignedGCNTrainer, SignedGCNPredictor\n",
    "from parser import parameter_parser\n",
    "from utils import tab_printer, read_graph, score_printer, save_logs\n",
    "import easydict\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "import networkx as nx\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_args = easydict.EasyDict({\n",
    "        \"edge_path\": f'../input/{data_name}/{data_name}_network.csv',\n",
    "        \"features_path\":  f'../input/{data_name}/{data_name}_node_feature.csv',\n",
    "        \"nodes_path\": f'../input/{data_name}/{data_name}_gt.csv',\n",
    "        \"embedding_path\": f'../tmp/embedding/{data_name}_sgcn_feature05.pkl', # tmp folder for cross-validation\n",
    "        \"regression_weights_path\": f'../tmp/weights/{data_name}_sgcn_feature05.pkl',\n",
    "        \"inductive_model_path\": f'../output/inductive/{data_name}_model', # or None\n",
    "        \"log_path\": f'../logs/{data_name}_logs_feature05.json',\n",
    "        \"epochs\":300,\n",
    "        \"test_size\":0.33,\n",
    "        \"reduction_iterations\": 128,\n",
    "        \"reduction_dimensions\": 30,\n",
    "        \"seed\": 42,\n",
    "        \"lamb\": 0.0,\n",
    "        \"learning_rate\": 0.001,  \n",
    "        \"weight_decay\": 10e-4, \n",
    "        # \"layers\": [64, 32,16,8],\n",
    "        \"layers\": [32, 2,],\n",
    "        \"spectral_features\":False,\n",
    "        \"general_features\": True,  \n",
    "        \"sample_num\":None,\n",
    "        \"class_weights\":False,\n",
    "        \"node_under_sampling\":False,\n",
    "        \"hidden_residual\":False,\n",
    "        \"eval_freq\":1,\n",
    "        \"subgraph_training\":False,\n",
    "        \"l1_lambda\":0.01,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_edges, new_nodes_dict = read_graph(new_args)\n",
    "if data_name  == 'amazon':\n",
    "    new_edges['positive_edges'] = new_edges['positive_edges'] + [[d,s] for s,d in new_edges['positive_edges']]\n",
    "    new_edges['negative_edges'] = new_edges['negative_edges'] + [[d,s] for s,d in new_edges['negative_edges']]\n",
    "X = np.array(pd.read_csv(f'../input/{data_name}/{data_name}_node_feature.csv')) # general node features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = input('学習に使ったデータセット：')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = SignedGCNPredictor(new_args, f'../output/inductive/{training_dataset}_model', X, new_edges,new_nodes_dict)\n",
    "\n",
    "predictions = predictor.predict()\n",
    "predict_labels = predictions.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = predictor.model.regression_weights.cpu().detach().numpy()\n",
    "\n",
    "all_z = predictor.z.cpu().detach().numpy()\n",
    "\n",
    "Z = all_z[new_nodes_dict['indice']]\n",
    "\n",
    "y = new_nodes_dict['label']\n",
    "\n",
    "y = np.array([1 if i==-1 else 0 for i in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "used_train_indcie = np.load(f'../output/inductive/{training_dataset}_train_indice.npy')\n",
    "\n",
    "used_test_indcie = np.load(f'../output/inductive/{training_dataset}_test_indice.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_ = plt.hist(weights[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ロジスティック回帰で確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression,Lasso\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=10,shuffle=True,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "auc_scores = []\n",
    "for train_idx, test_idx in kf.split(X=np.arange(len(y)),y=y):\n",
    "    Z_train, Z_test, y_train, y_test = Z[train_idx], Z[test_idx], y[train_idx], y[test_idx]\n",
    "    logistic = LogisticRegression()\n",
    "    logistic.fit(Z_train,y_train)\n",
    "    y_pred = logistic.predict_proba(Z_test)[:,1]\n",
    "    auc_score = roc_auc_score(y_true=y_test,y_score=y_pred)\n",
    "    auc_scores.append(auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.mean(auc_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(Z_train,weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(arr=Z,file=f'../for_analysis/Z_{data_name}_2.npy')\n",
    "\n",
    "np.save(arr=y,file=f'../for_analysis/y_{data_name}_2.npy')\n",
    "\n",
    "np.save(arr=weights, file=f'../for_analysis/weights_{data_name}_2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import lime\n",
    "import lime.lime_tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = [j+'-'+k+'-'+i+str(num) for i,j,k,num in itertools.product(['F','E'],['O','I'],['O','I'],range(2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime.lime_tabular.LimeTabularExplainer(Z_train, \n",
    "                                                   feature_names=feature_names, \n",
    "                                                   class_names=['benign','fraud'], \n",
    "                                                   discretize_continuous=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0 # np.random.randint(0, Z_test.shape[0])\n",
    "exp = explainer.explain_instance(Z_test[i], logistic.predict_proba, num_features=16, top_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_test[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp.show_in_notebook(show_table=True, show_all=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_df = pd.DataFrame()\n",
    "for i in range(len(y_test)):\n",
    "    exp = explainer.explain_instance(Z_test[i], logistic.predict_proba, num_features=16, top_labels=2)\n",
    "    current_exp_df = pd.DataFrame(exp.as_list())\n",
    "    current_exp_df['label'] = y_test[i]\n",
    "    exp_df = exp_df.append(current_exp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_df['relation'] = exp_df[0].str.extract('.*(.-.-.\\d).*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "agg = exp_df.groupby(['relation','label'])[1].mean().unstack(1).loc[feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=[20,5])\n",
    "ax[0].barh(agg.index,agg[0])\n",
    "ax[1].barh(agg.index,agg[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=[20,5])\n",
    "ax[0].barh(agg.index,weights[:,0])\n",
    "ax[1].barh(agg.index,weights[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forestで特徴量の重要度をみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "auc_scores = []\n",
    "feature_importances = []\n",
    "for train_idx, test_idx in kf.split(X=np.arange(len(y)),y=y):\n",
    "    Z_train, Z_test, y_train, y_test = Z[train_idx], Z[test_idx], y[train_idx], y[test_idx]\n",
    "    rf = RandomForestClassifier(n_estimators=500)\n",
    "    rf.fit(Z_train,y_train)\n",
    "    y_pred = rf.predict_proba(Z_test)[:,1]\n",
    "    auc_score = roc_auc_score(y_true=y_test,y_score=y_pred)\n",
    "    auc_scores.append(auc_score)\n",
    "    feature_importances.append(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.mean(auc_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "averaged_importance = sum(feature_importances) / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_df = pd.DataFrame(weights[:,1],columns=['weight'])\n",
    "\n",
    "weights_df['group'] = np.array([[i]*16 for i in range(8)]).flatten()\n",
    "\n",
    "weights_df['weight_abs'] = weights_df.weight.abs()\n",
    "weights_df['rf_importance'] = averaged_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "weights_df.groupby('group')['rf_importance'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_df.groupby('group')['rf_importance'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weights_df.groupby('group')['weight_abs'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(8,1,figsize=[10,20])\n",
    "for g in range(8):\n",
    "    ax[g].hist(weights_df.loc[weights_df.group==g,'rf_importance'],bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
