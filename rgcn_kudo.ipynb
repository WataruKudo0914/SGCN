{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  balance_theory\u001b[m\r\n",
      "  lab_balance_theory\u001b[m\r\n",
      "  lab_balance_theory2\u001b[m\r\n",
      "* \u001b[32mlab_rgcn\u001b[m\r\n",
      "  lab_server\u001b[m\r\n",
      "  master\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!git branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import copy as cp\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl import DGLGraph\n",
    "import dgl.function as fn\n",
    "from functools import partial\n",
    "\n",
    "class RGCNLayer(nn.Module):\n",
    "    def __init__(self, in_feat, out_feat, num_rels, num_bases=-1, bias=None,\n",
    "                 activation=None, is_input_layer=False):\n",
    "        super(RGCNLayer, self).__init__()\n",
    "        self.in_feat = in_feat\n",
    "        self.out_feat = out_feat\n",
    "        self.num_rels = num_rels\n",
    "        self.num_bases = num_bases\n",
    "        self.bias = bias\n",
    "        self.activation = activation\n",
    "        self.is_input_layer = is_input_layer\n",
    "\n",
    "        # sanity check\n",
    "        if self.num_bases <= 0 or self.num_bases > self.num_rels:\n",
    "            self.num_bases = self.num_rels\n",
    "\n",
    "        # weight bases in equation (3)\n",
    "        self.weight = nn.Parameter(torch.Tensor(self.num_bases, self.in_feat,\n",
    "                                                self.out_feat))\n",
    "        if self.num_bases < self.num_rels:\n",
    "            # linear combination coefficients in equation (3)\n",
    "            self.w_comp = nn.Parameter(torch.Tensor(self.num_rels, self.num_bases))\n",
    "\n",
    "        # add bias\n",
    "        if self.bias:\n",
    "            self.bias = nn.Parameter(torch.Tensor(out_feat))\n",
    "\n",
    "        # init trainable parameters\n",
    "        nn.init.xavier_uniform_(self.weight,\n",
    "                                gain=nn.init.calculate_gain('relu'))\n",
    "        if self.num_bases < self.num_rels:\n",
    "            nn.init.xavier_uniform_(self.w_comp,\n",
    "                                    gain=nn.init.calculate_gain('relu'))\n",
    "        if self.bias:\n",
    "            nn.init.xavier_uniform_(self.bias,\n",
    "                                    gain=nn.init.calculate_gain('relu'))\n",
    "\n",
    "    def forward(self, g):\n",
    "        if self.num_bases < self.num_rels:\n",
    "            # generate all weights from bases (equation (3))\n",
    "            weight = self.weight.view(self.in_feat, self.num_bases, self.out_feat)\n",
    "            weight = torch.matmul(self.w_comp, weight).view(self.num_rels,\n",
    "                                                        self.in_feat, self.out_feat)\n",
    "        else:\n",
    "            weight = self.weight\n",
    "\n",
    "        if self.is_input_layer:\n",
    "            def message_func(edges):\n",
    "                # for input layer, matrix multiply can be converted to be\n",
    "                # an embedding lookup using source node id\n",
    "                # embed = weight.view(-1, self.out_feat)\n",
    "                # index = edges.data['rel_type'] * self.in_feat + edges.src['id']\n",
    "                # index = edges.data['rel_type'] * self.in_feat + edges.src['id']\n",
    "                # return {'msg': embed[index] * edges.data['norm']}\n",
    "                w = weight[edges.data['rel_type']]\n",
    "                msg = torch.bmm(edges.src['init_h'].unsqueeze(1), w).squeeze()\n",
    "                msg = msg * edges.data['norm']\n",
    "                return {'msg': msg}                \n",
    "        else:\n",
    "            def message_func(edges):\n",
    "                w = weight[edges.data['rel_type']]\n",
    "                msg = torch.bmm(edges.src['h'].unsqueeze(1), w).squeeze()\n",
    "                msg = msg * edges.data['norm']\n",
    "                return {'msg': msg}\n",
    "\n",
    "        def apply_func(nodes):\n",
    "            h = nodes.data['h']\n",
    "            if self.bias:\n",
    "                h = h + self.bias\n",
    "            if self.activation:\n",
    "                h = self.activation(h)\n",
    "            return {'h': h}\n",
    "\n",
    "        g.update_all(message_func, fn.sum(msg='msg', out='h'), apply_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define full R-GCN model\n",
    "~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, num_nodes, h_dim, out_dim, num_rels,node_feature_array,\n",
    "                 num_bases=-1, num_hidden_layers=1):\n",
    "        super(Model, self).__init__()\n",
    "        self.num_nodes = num_nodes\n",
    "        self.h_dim = h_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.num_rels = num_rels\n",
    "        self.node_feature_array = node_feature_array\n",
    "        self.num_bases = num_bases\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        \n",
    "\n",
    "        # create rgcn layers\n",
    "        self.build_model()\n",
    "\n",
    "        # create initial features\n",
    "        self.features = self.create_features()\n",
    "\n",
    "    def build_model(self):\n",
    "        self.layers = nn.ModuleList()\n",
    "        # input to hidden\n",
    "        i2h = self.build_input_layer()\n",
    "        self.layers.append(i2h)\n",
    "        # hidden to hidden\n",
    "        for idx in range(self.num_hidden_layers - 1):\n",
    "            h2h = self.build_hidden_layer(idx)\n",
    "            self.layers.append(h2h)\n",
    "        # hidden to output\n",
    "        h2o = self.build_output_layer()\n",
    "        self.layers.append(h2o)\n",
    "\n",
    "    # initialize feature for each node\n",
    "    def create_features(self):\n",
    "        # features = torch.arange(self.num_nodes)\n",
    "        features = torch.from_numpy(self.node_feature_array)\n",
    "        return features\n",
    "\n",
    "    def build_input_layer(self):\n",
    "        return RGCNLayer(self.node_feature_array.shape[1], self.h_dim[0], self.num_rels, self.num_bases,\n",
    "                         activation=F.relu, is_input_layer=True)\n",
    "\n",
    "    def build_hidden_layer(self,idx):\n",
    "        return RGCNLayer(self.h_dim[idx], self.h_dim[idx+1], self.num_rels, self.num_bases,\n",
    "                         activation=F.relu)\n",
    "\n",
    "    def build_output_layer(self):\n",
    "        return RGCNLayer(self.h_dim[-1], self.out_dim, self.num_rels, self.num_bases,\n",
    "                         activation=partial(F.softmax, dim=1))\n",
    "\n",
    "    def forward(self, g):\n",
    "        if self.features is not None:\n",
    "            # g.ndata['id'] = self.features\n",
    "            g.ndata['init_h'] = self.features\n",
    "        for layer in self.layers:\n",
    "            layer(g)\n",
    "        return g.ndata.pop('h')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handle dataset\n",
    "~~~~~~~~~~~~~~~~\n",
    "In this tutorial, we use AIFB dataset from R-GCN paper:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dist(df,col):\n",
    "    df_cnt = df.groupby([col]+['etype'])['time'].count().unstack(1,fill_value=0)\n",
    "    df_dist = pd.DataFrame(df_cnt.values / df_cnt.sum(1).values.reshape(-1,1),\n",
    "                                               columns=df_cnt.columns,\n",
    "                                               index=df_cnt.index)\n",
    "    return df_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# etype = {1,2,3,4,5}\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "amazon_network_ = pd.read_csv('/home2/kudo/SGCN/raw_data/amazon/amazon_network.csv',header=None)\n",
    "amazon_network_.columns = ['src_raw','dst_raw','etype','time']\n",
    "amazon_network_inv = amazon_network_[['dst_raw','src_raw','etype','time']]\n",
    "amazon_network_inv.columns = ['src_raw','dst_raw','etype','time']\n",
    "\n",
    "amazon_network = amazon_network_.append(amazon_network_inv)\n",
    "\n",
    "etype_encoder = LabelEncoder()\n",
    "amazon_network['etype'] = etype_encoder.fit_transform(amazon_network.etype)\n",
    "amazon_gt = pd.read_csv('/home2/kudo/SGCN/raw_data/amazon/amazon_gt.csv',header=None)\n",
    "amazon_gt.columns = ['node_id_raw','label']\n",
    "amazon_gt = amazon_gt.drop_duplicates('node_id_raw')\n",
    "\n",
    "# edge_normの計算\n",
    "amazon_src_cnt = amazon_network.groupby(['src_raw','etype'])['time'].count().unstack(1,fill_value=0)\n",
    "\n",
    "amazon_src_dist = pd.DataFrame(amazon_src_cnt.values/amazon_src_cnt.sum(1).values.reshape(-1,1),\n",
    "                                                        index=amazon_src_cnt.index,\n",
    "                                                        columns=amazon_src_cnt.columns)\n",
    "\n",
    "merged_network = pd.merge(amazon_network,amazon_src_dist.stack().reset_index(),on=['src_raw','etype'])\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(np.hstack((merged_network.src_raw,\n",
    "                                                   merged_network.dst_raw,\n",
    "                                                   amazon_gt.node_id_raw)))\n",
    "\n",
    "merged_network['src'] = label_encoder.transform(merged_network.src_raw)\n",
    "\n",
    "merged_network['dst'] = label_encoder.transform(merged_network.dst_raw)\n",
    "\n",
    "amazon_gt['node_id'] = label_encoder.transform(amazon_gt.node_id_raw)\n",
    "amazon_gt['label'] = amazon_gt['label'].map(lambda x:1 if x==-1 else 0)\n",
    "\n",
    "# padding\n",
    "amazon_gt_padded = pd.merge(pd.DataFrame(np.arange(label_encoder.classes_.shape[0])),amazon_gt,\n",
    "                                      left_index=True,right_on='node_id',how='left').fillna(0.5).sort_values('node_id')\n",
    "\n",
    "num_nodes = label_encoder.classes_.shape[0]\n",
    "num_rels = merged_network.etype.unique().shape[0]\n",
    "num_classes = amazon_gt.label.unique().shape[0]\n",
    "labels = amazon_gt_padded['label'].values.astype(int).reshape(-1,1)\n",
    "all_idx = amazon_gt['node_id'].values\n",
    "\n",
    "# edge type and normalization factor\n",
    "edge_type = torch.from_numpy(merged_network['etype'].values)\n",
    "edge_norm = torch.from_numpy(merged_network[0].values.astype('float32')).unsqueeze(1)\n",
    "\n",
    "labels = torch.from_numpy(labels).view(-1)\n",
    "\n",
    "merged_network_directed = merged_network.copy().iloc[:merged_network.shape[0]//2,:]\n",
    "node_feature_df = pd.concat([get_dist(merged_network_directed,'src'),get_dist(merged_network_directed,'dst')],1).fillna(0).sort_index()\n",
    "node_feature_array = node_feature_df.values.astype('float32')\n",
    "\n",
    "known_labels = amazon_gt['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# etype = {-1,1}\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "amazon_network_ = pd.read_csv('/home2/kudo/SGCN/input/amazon/amazon_network.csv')\n",
    "\n",
    "amazon_network_.columns = ['src_raw','dst_raw','etype']\n",
    "amazon_network_inv = amazon_network_[['dst_raw','src_raw','etype']]\n",
    "amazon_network_inv.columns = ['src_raw','dst_raw','etype']\n",
    "\n",
    "amazon_network = amazon_network_.append(amazon_network_inv)\n",
    "amazon_network['time'] = 1\n",
    "\n",
    "etype_encoder = LabelEncoder()\n",
    "amazon_network['etype'] = etype_encoder.fit_transform(amazon_network.etype)\n",
    "\n",
    "amazon_gt = pd.read_csv('/home2/kudo/SGCN/input/amazon/amazon_gt.csv')\n",
    "amazon_gt.columns = ['node_id_raw','label']\n",
    "amazon_gt = amazon_gt.drop_duplicates('node_id_raw')\n",
    "\n",
    "# edge_normの計算\n",
    "amazon_src_raw_cnt = amazon_network.groupby(['src_raw','etype'])['dst_raw'].count().unstack(1,fill_value=0)\n",
    "\n",
    "amazon_src_raw_dist = pd.DataFrame(amazon_src_raw_cnt.values/amazon_src_raw_cnt.sum(1).values.reshape(-1,1),\n",
    "                                                        index=amazon_src_raw_cnt.index,\n",
    "                                                        columns=amazon_src_raw_cnt.columns)\n",
    "\n",
    "merged_network = pd.merge(amazon_network,amazon_src_raw_dist.stack().reset_index(),on=['src_raw','etype'])\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(np.hstack((merged_network.src_raw,\n",
    "                                                   merged_network.dst_raw,\n",
    "                                                   amazon_gt.node_id_raw)))\n",
    "\n",
    "merged_network['src'] = label_encoder.transform(merged_network.src_raw)\n",
    "\n",
    "merged_network['dst'] = label_encoder.transform(merged_network.dst_raw)\n",
    "\n",
    "amazon_gt['node_id'] = label_encoder.transform(amazon_gt.node_id_raw)\n",
    "amazon_gt['label'] = amazon_gt['label'].map(lambda x:1 if x==-1 else 0)\n",
    "\n",
    "# padding\n",
    "amazon_gt_padded = pd.merge(pd.DataFrame(np.arange(label_encoder.classes_.shape[0])),amazon_gt,\n",
    "                                      left_index=True,right_on='node_id',how='left').fillna(0.5).sort_values('node_id')\n",
    "\n",
    "num_nodes = label_encoder.classes_.shape[0]\n",
    "num_rels = merged_network.etype.unique().shape[0]\n",
    "num_classes = amazon_gt.label.unique().shape[0]\n",
    "labels = amazon_gt_padded['label'].values.astype(int).reshape(-1,1)\n",
    "all_idx = amazon_gt['node_id'].values\n",
    "\n",
    "# edge type and normalization factor\n",
    "edge_type = torch.from_numpy(merged_network['etype'].values)\n",
    "edge_norm = torch.from_numpy(merged_network[0].values.astype('float32')).unsqueeze(1)\n",
    "\n",
    "labels = torch.from_numpy(labels).view(-1)\n",
    "\n",
    "# merged_network_directed = merged_network.copy().iloc[:merged_network.shape[0]//2,:]\n",
    "# node_feature_df = pd.concat([get_dist(merged_network_directed,'src'),get_dist(merged_network_directed,'dst')],1).fillna(0).sort_index()\n",
    "# node_feature_array = node_feature_df.values.astype('float32')\n",
    "node_feature_df = pd.read_csv('/home2/kudo/SGCN/input/amazon/amazon_node_feature.csv')\n",
    "node_feature_array = node_feature_df.values.astype('float32')\n",
    "\n",
    "known_labels = amazon_gt['label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## alpha ,otc and epinions Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "epinions_network = pd.read_csv('/home2/kudo/SGCN/raw_data/epinions/epinions_network.csv',header=None)\n",
    "epinions_network.columns = ['src_raw','dst_raw','etype','time']\n",
    "etype_encoder = LabelEncoder()\n",
    "epinions_network['etype'] = etype_encoder.fit_transform(epinions_network.etype)\n",
    "epinions_gt = pd.read_csv('/home2/kudo/SGCN/raw_data/epinions/epinions_gt.csv',header=None)\n",
    "epinions_gt.columns = ['node_id_raw','label']\n",
    "epinions_gt = epinions_gt.drop_duplicates('node_id_raw')\n",
    "epinions_gt = epinions_gt.loc[epinions_gt.node_id_raw.isin(set(epinions_network.src_raw)|set(epinions_network.dst_raw))]\n",
    "\n",
    "# edge_normの計算\n",
    "epinions_src_cnt = epinions_network.groupby(['src_raw','etype'])['time'].count().unstack(1,fill_value=0)\n",
    "\n",
    "epinions_src_dist = pd.DataFrame(epinions_src_cnt.values/epinions_src_cnt.sum(1).values.reshape(-1,1),\n",
    "                                                        index=epinions_src_cnt.index,\n",
    "                                                        columns=epinions_src_cnt.columns)\n",
    "\n",
    "merged_network = pd.merge(epinions_network,epinions_src_dist.stack().reset_index(),on=['src_raw','etype'])\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(np.hstack((merged_network.src_raw,\n",
    "                                                   merged_network.dst_raw,\n",
    "                                                   epinions_gt.node_id_raw)))\n",
    "\n",
    "merged_network['src'] = label_encoder.transform(merged_network.src_raw)\n",
    "\n",
    "merged_network['dst'] = label_encoder.transform(merged_network.dst_raw)\n",
    "\n",
    "epinions_gt['node_id'] = label_encoder.transform(epinions_gt.node_id_raw)\n",
    "epinions_gt['label'] = epinions_gt['label'].map(lambda x:1 if x==-1 else 0)\n",
    "\n",
    "# padding\n",
    "epinions_gt_padded = pd.merge(pd.DataFrame(np.arange(label_encoder.classes_.shape[0])),epinions_gt,\n",
    "                                      left_index=True,right_on='node_id',how='left').fillna(0.5).sort_values('node_id')\n",
    "\n",
    "num_nodes = label_encoder.classes_.shape[0]\n",
    "num_rels = merged_network.etype.unique().shape[0]\n",
    "num_classes = epinions_gt.label.unique().shape[0]\n",
    "labels = epinions_gt_padded['label'].values.astype(int).reshape(-1,1)\n",
    "all_idx = epinions_gt['node_id'].values\n",
    "\n",
    "# edge type and normalization factor\n",
    "edge_type = torch.from_numpy(merged_network['etype'].values)\n",
    "edge_norm = torch.from_numpy(merged_network[0].values.astype('float32')).unsqueeze(1)\n",
    "\n",
    "labels = torch.from_numpy(labels).view(-1)\n",
    "\n",
    "node_feature_df = pd.concat([get_dist(merged_network,'src'),get_dist(merged_network,'dst')],1).fillna(0).sort_index()\n",
    "node_feature_array = node_feature_df.values.astype('float32')\n",
    "\n",
    "known_labels = epinions_gt['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "#etype = {-1,1}\n",
    "\n",
    "epinions_network = pd.read_csv('/home2/kudo/SGCN/input/epinions/epinions_network.csv')\n",
    "epinions_network.columns = ['src_raw','dst_raw','etype']\n",
    "etype_encoder = LabelEncoder()\n",
    "epinions_network['etype'] = etype_encoder.fit_transform(epinions_network.etype)\n",
    "epinions_gt = pd.read_csv('/home2/kudo/SGCN/input/epinions/epinions_gt.csv')\n",
    "epinions_gt.columns = ['node_id_raw','label']\n",
    "epinions_gt = epinions_gt.drop_duplicates('node_id_raw')\n",
    "epinions_network['time'] = 1\n",
    "\n",
    "# edge_normの計算\n",
    "epinions_src_cnt = epinions_network.groupby(['src_raw','etype'])['time'].count().unstack(1,fill_value=0)\n",
    "\n",
    "epinions_src_dist = pd.DataFrame(epinions_src_cnt.values/epinions_src_cnt.sum(1).values.reshape(-1,1),\n",
    "                                                        index=epinions_src_cnt.index,\n",
    "                                                        columns=epinions_src_cnt.columns)\n",
    "\n",
    "merged_network = pd.merge(epinions_network,epinions_src_dist.stack().reset_index(),on=['src_raw','etype'])\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(np.hstack((merged_network.src_raw,\n",
    "                                                   merged_network.dst_raw,\n",
    "                                                   epinions_gt.node_id_raw)))\n",
    "\n",
    "merged_network['src'] = label_encoder.transform(merged_network.src_raw)\n",
    "\n",
    "merged_network['dst'] = label_encoder.transform(merged_network.dst_raw)\n",
    "\n",
    "epinions_gt['node_id'] = label_encoder.transform(epinions_gt.node_id_raw)\n",
    "epinions_gt['label'] = epinions_gt['label'].map(lambda x:1 if x==-1 else 0)\n",
    "\n",
    "# padding\n",
    "epinions_gt_padded = pd.merge(pd.DataFrame(np.arange(label_encoder.classes_.shape[0])),epinions_gt,\n",
    "                                      left_index=True,right_on='node_id',how='left').fillna(0.5).sort_values('node_id')\n",
    "\n",
    "num_nodes = label_encoder.classes_.shape[0]\n",
    "num_rels = merged_network.etype.unique().shape[0]\n",
    "num_classes = epinions_gt.label.unique().shape[0]\n",
    "labels = epinions_gt_padded['label'].values.astype(int).reshape(-1,1)\n",
    "all_idx = epinions_gt['node_id'].values\n",
    "\n",
    "# edge type and normalization factor\n",
    "edge_type = torch.from_numpy(merged_network['etype'].values)\n",
    "edge_norm = torch.from_numpy(merged_network[0].values.astype('float32')).unsqueeze(1)\n",
    "\n",
    "labels = torch.from_numpy(labels).view(-1)\n",
    "\n",
    "node_feature_df = pd.read_csv('/home2/kudo/SGCN/input/epinions/epinions_node_feature.csv')\n",
    "node_feature_array = node_feature_df.values.astype('float32')\n",
    "\n",
    "known_labels = epinions_gt['label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create graph and model\n",
    "~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configurations\n",
    "n_hidden = [32,16] # number of hidden units\n",
    "n_bases = -1 # -1 # use number of relations as number of bases\n",
    "n_hidden_layers = 2 # use 1 input layer, 1 output layer, no hidden layer\n",
    "n_epochs = 100 # epochs to train\n",
    "lr = 0.025 # learning rate\n",
    "l2norm = 0.00001 # L2 norm coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=10,shuffle=True,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "auc_scores = []\n",
    "\n",
    "for i, (for_train_val_idx, for_test_idx) in enumerate(kf.split(np.arange(len(all_idx)),y=known_labels)):\n",
    "    train_val_idx = all_idx[for_train_val_idx]\n",
    "    train_idx, val_idx = train_test_split(train_val_idx,test_size=0.33,stratify=known_labels[for_train_val_idx])\n",
    "    test_idx = all_idx[for_test_idx]\n",
    "    # create graph\n",
    "    g = DGLGraph()\n",
    "    g.add_nodes(num_nodes)\n",
    "    g.add_edges(merged_network['src'].values, merged_network['dst'].values)\n",
    "    g.edata.update({'rel_type': edge_type, 'norm': edge_norm})\n",
    "    # create model\n",
    "    model = Model(len(g),\n",
    "                  n_hidden,\n",
    "                  num_classes,\n",
    "                  num_rels,\n",
    "                  node_feature_array,\n",
    "                  num_bases=n_bases,\n",
    "                  num_hidden_layers=n_hidden_layers)\n",
    "    # optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=l2norm)\n",
    "    print(\"Start {}-th fold\".format(i))\n",
    "    print(\"==== Train Phase ====\")\n",
    "    model.train()\n",
    "    best_auc = 0.0\n",
    "    best_auc_logits = None\n",
    "    for epoch in range(n_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        logits = model.forward(g)\n",
    "        loss = F.cross_entropy(logits[train_idx], labels[train_idx])\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        train_auc = roc_auc_score(y_true=labels[train_idx].detach().numpy(),y_score=logits[train_idx].detach().numpy()[:,1])\n",
    "        train_loss = F.cross_entropy(logits[train_idx], labels[train_idx])\n",
    "        val_auc = roc_auc_score(y_true=labels[val_idx].detach().numpy(),y_score=logits[val_idx].detach().numpy()[:,1])\n",
    "        val_loss = F.cross_entropy(logits[val_idx], labels[val_idx])\n",
    "        \n",
    "        if val_auc >= best_auc:\n",
    "            best_auc = val_auc\n",
    "            best_auc_logits = logits\n",
    "            \n",
    "        print(\"Epoch {:05d} | \".format(epoch) +\n",
    "              \"Train AUC: {:.4f} | Train Loss: {:.4f} | \".format(\n",
    "                  train_auc, loss.item()) +\n",
    "              \"Validation AUC: {:.4f} | Validation loss: {:.4f}\".format(\n",
    "                  val_auc, val_loss.item()))\n",
    "    print(\"==== Test Phase ====\")\n",
    "    model.eval()\n",
    "    test_auc = roc_auc_score(y_true=labels[test_idx].detach().numpy(),y_score=best_auc_logits[test_idx].detach().numpy()[:,1])\n",
    "    auc_scores.append(test_auc)\n",
    "    print(\"test auc : {}\".format(test_auc))\n",
    "    print(\"=================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.mean(auc_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "結果\n",
    "\n",
    "- (32,16) , カーネルは独立\n",
    "    - amazon : 0.749413165 (150 epochs)\n",
    "    - alpha : 0.926 (150 epochs)\n",
    "    - otc : 0.9601 (300 epochs)\n",
    "    \n",
    "- (32,16) , base = 3\n",
    "    - amazon : 0.7517083258204111\n",
    "    - alpha : 0.895\n",
    "    - otc : 0.95332"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "結果\n",
    "\n",
    "- (32,16) , etype = {-1,1}\n",
    "    - amazon : 0.817841627 (150 epochs)\n",
    "    - alpha :  0.7928971028971029 (150 epochs)\n",
    "    - otc :  0.917612942612942 (150 epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "結果\n",
    "\n",
    "- (32,16, 8) , カーネルは独立\n",
    "    - amazon : (150 epochs)\n",
    "    - alpha : 0.9206768231768232 (150 epochs)\n",
    "    - otc :  (300 epochs)\n",
    "    \n",
    "- (32,16,8) , base=3\n",
    "    - amazon : \n",
    "    - alpha : \n",
    "    - otc : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cross-validation for epinions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subgraph_making(original_network_df,original_gt_df,all_ncount,sample_node_num,train_node_indice_original,neighbor_sampling=True):\n",
    "    if neighbor_sampling == True:\n",
    "        first_neighbors = np.unique(original_network_df.loc[(original_network_df.src.isin(train_node_indice_original)) | \n",
    "                                                       (original_network_df.dst.isin(train_node_indice_original)),['src','dst']].values)\n",
    "        sampled_node_indice = np.random.choice(first_neighbors,sample_node_num,replace=False)\n",
    "    else: \n",
    "        sampled_node_indice = set(np.random.choice(np.arange(all_ncount), sample_node_num,replace=False)) | set(train_node_indice_original)\n",
    "\n",
    "    sub_network_df = \\\n",
    "        original_network_df.loc[(original_network_df.src.isin(sampled_node_indice)) & (original_network_df.dst.isin(sampled_node_indice))]\n",
    "\n",
    "    sub_gt_df = \\\n",
    "        original_gt_df.copy().loc[(original_gt_df.node_id.isin(sub_network_df.src)) & (original_gt_df.node_id.isin(sub_network_df.dst))]\n",
    "\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "    subGraph_map_encoder = LabelEncoder()\n",
    "\n",
    "    subGraph_map_encoder.fit(list(set(sub_network_df.src) | set(sub_network_df.dst) | set(sub_gt_df.node_id)))\n",
    "\n",
    "    sub_gt_df['node_id'] = subGraph_map_encoder.transform(sub_gt_df.node_id)\n",
    "\n",
    "    sub_network_df['src'] = subGraph_map_encoder.transform(sub_network_df.src)\n",
    "\n",
    "    sub_network_df['dst'] = subGraph_map_encoder.transform(sub_network_df.dst)\n",
    "    \n",
    "    sub_network_df = add_edge_norm(sub_network_df)\n",
    "\n",
    "    return sub_network_df, sub_gt_df, subGraph_map_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subgraph_making_from_edges(original_network_df,original_gt_df,all_ncount,sample_node_num,train_node_indice_original,neighbor_sampling):\n",
    "    if neighbor_sampling == 'first':\n",
    "        first_neighbors = np.unique(original_network_df.loc[(original_network_df.src.isin(train_node_indice_original)) | \n",
    "                                                       (original_network_df.dst.isin(train_node_indice_original)),['src','dst']].values)\n",
    "        sampled_node_indice = np.random.choice(first_neighbors,sample_node_num,replace=False)\n",
    "    elif neighbor_sampling == 'first_second':\n",
    "        first_neighbors = np.unique(original_network_df.loc[(original_network_df.src.isin(train_node_indice_original)) | \n",
    "                                                       (original_network_df.dst.isin(train_node_indice_original)),['src','dst']].values)\n",
    "        second_neighbors = np.unique(original_network_df.loc[(original_network_df.src.isin(first_neighbors)) | \n",
    "                                                       (original_network_df.dst.isin(first_neighbors)),['src','dst']].values)\n",
    "        sampled_node_indice = np.random.choice(list(set(first_neighbors) | set (second_neighbors)),sample_node_num)\n",
    "        \n",
    "    else: \n",
    "        sampled_node_indice = set(np.random.choice(np.arange(all_ncount), sample_node_num,replace=False)) | set(train_node_indice_original)\n",
    "\n",
    "    sub_network_df = \\\n",
    "        original_network_df.loc[(original_network_df.src.isin(sampled_node_indice)) & (original_network_df.dst.isin(sampled_node_indice))]\n",
    "\n",
    "    sub_gt_df = \\\n",
    "        original_gt_df.copy().loc[(original_gt_df.node_id.isin(sub_network_df.src)) & (original_gt_df.node_id.isin(sub_network_df.dst))]\n",
    "\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "    subGraph_map_encoder = LabelEncoder()\n",
    "\n",
    "    subGraph_map_encoder.fit(list(set(sub_network_df.src) | set(sub_network_df.dst) | set(sub_gt_df.node_id)))\n",
    "\n",
    "    sub_gt_df['node_id'] = subGraph_map_encoder.transform(sub_gt_df.node_id)\n",
    "\n",
    "    sub_network_df['src'] = subGraph_map_encoder.transform(sub_network_df.src)\n",
    "\n",
    "    sub_network_df['dst'] = subGraph_map_encoder.transform(sub_network_df.dst)\n",
    "    \n",
    "    sub_network_df = add_edge_norm(sub_network_df)\n",
    "\n",
    "    return sub_network_df, sub_gt_df, subGraph_map_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_edge_norm(network_df,src='src'):\n",
    "    network_df_ = network_df.copy()\n",
    "    src_cnt = network_df_.groupby([src,'etype'])['time'].count().unstack(1,fill_value=0)\n",
    "    src_dist = pd.DataFrame(src_cnt.values/src_cnt.sum(1).values.reshape(-1,1),\n",
    "                                                        index=src_cnt.index,\n",
    "                                                        columns=src_cnt.columns)\n",
    "    src_dist_stacked = src_dist.stack()\n",
    "    src_dist_stacked.name = 'norm'\n",
    "    merged_network = pd.merge(network_df_,src_dist_stacked.reset_index(),on=['src','etype'])\n",
    "    return merged_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=10,shuffle=True,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create graph\n",
    "g = DGLGraph()\n",
    "g.add_nodes(num_nodes)\n",
    "g.add_edges(merged_network['src'].values, merged_network['dst'].values)\n",
    "g.edata.update({'rel_type': edge_type, 'norm': edge_norm})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kudo/.pyenv/versions/3.5.2/lib/python3.5/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/kudo/.pyenv/versions/3.5.2/lib/python3.5/site-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/kudo/.pyenv/versions/3.5.2/lib/python3.5/site-packages/dgl/frame.py:204: UserWarning: Initializer is not set. Use zero initializer instead. To suppress this warning, use `set_initializer` to explicitly specify which initializer to use.\n",
      "  dgl_warning('Initializer is not set. Use zero initializer instead.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([630,  63]))\n",
      "Start 0-th fold\n",
      "==== Train Phase ====\n",
      "Epoch 00000 | Train AUC: 0.5198 | Train Loss: 0.4038 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00001 | Train AUC: 0.5192 | Train Loss: 0.4033 | Validation AUC: 0.4936 | Validation loss: 0.4178\n",
      "Epoch 00002 | Train AUC: 0.5177 | Train Loss: 0.4032 | Validation AUC: 0.5013 | Validation loss: 0.4180\n",
      "Epoch 00003 | Train AUC: 0.5199 | Train Loss: 0.4031 | Validation AUC: 0.5077 | Validation loss: 0.4177\n",
      "Epoch 00004 | Train AUC: 0.5192 | Train Loss: 0.4031 | Validation AUC: 0.5077 | Validation loss: 0.4177\n",
      "Epoch 00005 | Train AUC: 0.5192 | Train Loss: 0.4031 | Validation AUC: 0.5077 | Validation loss: 0.4177\n",
      "Epoch 00006 | Train AUC: 0.5192 | Train Loss: 0.4031 | Validation AUC: 0.5077 | Validation loss: 0.4177\n",
      "Epoch 00007 | Train AUC: 0.5192 | Train Loss: 0.4031 | Validation AUC: 0.5061 | Validation loss: 0.4177\n",
      "Epoch 00008 | Train AUC: 0.5272 | Train Loss: 0.4017 | Validation AUC: 0.5061 | Validation loss: 0.4177\n",
      "Epoch 00009 | Train AUC: 0.5192 | Train Loss: 0.4031 | Validation AUC: 0.5077 | Validation loss: 0.4177\n",
      "Epoch 00010 | Train AUC: 0.5199 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00011 | Train AUC: 0.5199 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00012 | Train AUC: 0.5199 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00013 | Train AUC: 0.5199 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00014 | Train AUC: 0.5199 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00015 | Train AUC: 0.5279 | Train Loss: 0.4017 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00016 | Train AUC: 0.5279 | Train Loss: 0.4017 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00017 | Train AUC: 0.5279 | Train Loss: 0.4017 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00018 | Train AUC: 0.5279 | Train Loss: 0.4017 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00019 | Train AUC: 0.5279 | Train Loss: 0.4017 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00020 | Train AUC: 0.5279 | Train Loss: 0.4017 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00021 | Train AUC: 0.5272 | Train Loss: 0.4017 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00022 | Train AUC: 0.5264 | Train Loss: 0.4017 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00023 | Train AUC: 0.5264 | Train Loss: 0.4031 | Validation AUC: 0.5077 | Validation loss: 0.4177\n",
      "Epoch 00024 | Train AUC: 0.5264 | Train Loss: 0.4031 | Validation AUC: 0.5061 | Validation loss: 0.4177\n",
      "Epoch 00025 | Train AUC: 0.5263 | Train Loss: 0.4046 | Validation AUC: 0.5061 | Validation loss: 0.4177\n",
      "Epoch 00026 | Train AUC: 0.5272 | Train Loss: 0.4017 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00027 | Train AUC: 0.5279 | Train Loss: 0.4017 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00028 | Train AUC: 0.5279 | Train Loss: 0.4017 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00029 | Train AUC: 0.5279 | Train Loss: 0.4017 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00030 | Train AUC: 0.5279 | Train Loss: 0.4017 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00031 | Train AUC: 0.5279 | Train Loss: 0.4017 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00032 | Train AUC: 0.5199 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00033 | Train AUC: 0.5199 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00034 | Train AUC: 0.5199 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00035 | Train AUC: 0.5199 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00036 | Train AUC: 0.5199 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00037 | Train AUC: 0.5199 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00038 | Train AUC: 0.5199 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00039 | Train AUC: 0.5199 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00040 | Train AUC: 0.5199 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00041 | Train AUC: 0.5199 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00042 | Train AUC: 0.5199 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00043 | Train AUC: 0.5199 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00044 | Train AUC: 0.5199 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00045 | Train AUC: 0.5191 | Train Loss: 0.4046 | Validation AUC: 0.4920 | Validation loss: 0.4177\n",
      "Epoch 00046 | Train AUC: 0.5191 | Train Loss: 0.4046 | Validation AUC: 0.4920 | Validation loss: 0.4177\n",
      "Epoch 00047 | Train AUC: 0.5248 | Train Loss: 0.4046 | Validation AUC: 0.4887 | Validation loss: 0.4237\n",
      "Epoch 00048 | Train AUC: 0.5310 | Train Loss: 0.4089 | Validation AUC: 0.4839 | Validation loss: 0.4351\n",
      "Epoch 00049 | Train AUC: 0.5172 | Train Loss: 0.4320 | Validation AUC: 0.4646 | Validation loss: 0.4669\n",
      "Epoch 00050 | Train AUC: 0.5092 | Train Loss: 0.4435 | Validation AUC: 0.4598 | Validation loss: 0.4757\n",
      "Epoch 00051 | Train AUC: 0.5228 | Train Loss: 0.4450 | Validation AUC: 0.4534 | Validation loss: 0.4816\n",
      "Epoch 00052 | Train AUC: 0.5199 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00053 | Train AUC: 0.5199 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00054 | Train AUC: 0.5207 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00055 | Train AUC: 0.5207 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00056 | Train AUC: 0.5207 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00057 | Train AUC: 0.5207 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00058 | Train AUC: 0.5207 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00059 | Train AUC: 0.5207 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00060 | Train AUC: 0.5207 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00061 | Train AUC: 0.5207 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00062 | Train AUC: 0.5207 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00063 | Train AUC: 0.5207 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00064 | Train AUC: 0.5207 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00065 | Train AUC: 0.5207 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00066 | Train AUC: 0.5207 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00067 | Train AUC: 0.5207 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00068 | Train AUC: 0.5207 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00069 | Train AUC: 0.5207 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00070 | Train AUC: 0.5207 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00071 | Train AUC: 0.5207 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00072 | Train AUC: 0.5207 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00073 | Train AUC: 0.5207 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00074 | Train AUC: 0.5207 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00075 | Train AUC: 0.5207 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00076 | Train AUC: 0.5207 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00077 | Train AUC: 0.5207 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00078 | Train AUC: 0.5207 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00079 | Train AUC: 0.5207 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00080 | Train AUC: 0.5207 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00081 | Train AUC: 0.5207 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00082 | Train AUC: 0.5207 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00083 | Train AUC: 0.5207 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00084 | Train AUC: 0.5207 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00085 | Train AUC: 0.5207 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00086 | Train AUC: 0.5207 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00087 | Train AUC: 0.5207 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00088 | Train AUC: 0.5207 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00089 | Train AUC: 0.5207 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00090 | Train AUC: 0.5207 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00091 | Train AUC: 0.5207 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00092 | Train AUC: 0.5207 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00093 | Train AUC: 0.5207 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00094 | Train AUC: 0.5207 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00095 | Train AUC: 0.5207 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00096 | Train AUC: 0.5207 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00097 | Train AUC: 0.5207 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00098 | Train AUC: 0.5207 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "Epoch 00099 | Train AUC: 0.5207 | Train Loss: 0.4031 | Validation AUC: 0.4936 | Validation loss: 0.4177\n",
      "==== Test Phase ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kudo/.pyenv/versions/3.5.2/lib/python3.5/site-packages/dgl/frame.py:204: UserWarning: Initializer is not set. Use zero initializer instead. To suppress this warning, use `set_initializer` to explicitly specify which initializer to use.\n",
      "  dgl_warning('Initializer is not set. Use zero initializer instead.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test auc : 0.5487349778621126\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kudo/.pyenv/versions/3.5.2/lib/python3.5/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/kudo/.pyenv/versions/3.5.2/lib/python3.5/site-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/kudo/.pyenv/versions/3.5.2/lib/python3.5/site-packages/dgl/frame.py:204: UserWarning: Initializer is not set. Use zero initializer instead. To suppress this warning, use `set_initializer` to explicitly specify which initializer to use.\n",
      "  dgl_warning('Initializer is not set. Use zero initializer instead.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([641,  44]))\n",
      "Start 1-th fold\n",
      "==== Train Phase ====\n",
      "Epoch 00000 | Train AUC: 0.1659 | Train Loss: 1.2750 | Validation AUC: 0.1674 | Validation loss: 1.2661\n",
      "Epoch 00001 | Train AUC: 0.1556 | Train Loss: 1.2750 | Validation AUC: 0.1296 | Validation loss: 1.2742\n",
      "Epoch 00002 | Train AUC: 0.5474 | Train Loss: 0.3787 | Validation AUC: 0.5172 | Validation loss: 0.4254\n",
      "Epoch 00003 | Train AUC: 0.5482 | Train Loss: 0.3787 | Validation AUC: 0.5187 | Validation loss: 0.4254\n",
      "Epoch 00004 | Train AUC: 0.5482 | Train Loss: 0.3787 | Validation AUC: 0.5187 | Validation loss: 0.4254\n",
      "Epoch 00005 | Train AUC: 0.5475 | Train Loss: 0.3787 | Validation AUC: 0.5172 | Validation loss: 0.4254\n",
      "Epoch 00006 | Train AUC: 0.5579 | Train Loss: 0.3787 | Validation AUC: 0.5172 | Validation loss: 0.4254\n",
      "Epoch 00007 | Train AUC: 0.5572 | Train Loss: 0.3787 | Validation AUC: 0.5157 | Validation loss: 0.4255\n",
      "Epoch 00008 | Train AUC: 0.5574 | Train Loss: 0.3787 | Validation AUC: 0.5280 | Validation loss: 0.4255\n",
      "Epoch 00009 | Train AUC: 0.5890 | Train Loss: 0.3786 | Validation AUC: 0.5884 | Validation loss: 0.4255\n",
      "Epoch 00010 | Train AUC: 0.8324 | Train Loss: 0.3480 | Validation AUC: 0.8306 | Validation loss: 0.3612\n",
      "Epoch 00011 | Train AUC: 0.8328 | Train Loss: 0.3480 | Validation AUC: 0.8316 | Validation loss: 0.3584\n",
      "Epoch 00012 | Train AUC: 0.8331 | Train Loss: 0.3480 | Validation AUC: 0.8327 | Validation loss: 0.3583\n",
      "Epoch 00013 | Train AUC: 0.8331 | Train Loss: 0.3480 | Validation AUC: 0.8327 | Validation loss: 0.3583\n",
      "Epoch 00014 | Train AUC: 0.8331 | Train Loss: 0.3480 | Validation AUC: 0.8327 | Validation loss: 0.3583\n",
      "Epoch 00015 | Train AUC: 0.8328 | Train Loss: 0.3480 | Validation AUC: 0.8453 | Validation loss: 0.3556\n",
      "Epoch 00016 | Train AUC: 0.8440 | Train Loss: 0.3480 | Validation AUC: 0.8579 | Validation loss: 0.3528\n",
      "Epoch 00017 | Train AUC: 0.8442 | Train Loss: 0.3480 | Validation AUC: 0.8579 | Validation loss: 0.3528\n",
      "Epoch 00018 | Train AUC: 0.8440 | Train Loss: 0.3480 | Validation AUC: 0.8705 | Validation loss: 0.3500\n",
      "Epoch 00019 | Train AUC: 0.8547 | Train Loss: 0.3480 | Validation AUC: 0.8701 | Validation loss: 0.3500\n",
      "Epoch 00020 | Train AUC: 0.8771 | Train Loss: 0.3465 | Validation AUC: 0.8815 | Validation loss: 0.3500\n",
      "Epoch 00021 | Train AUC: 0.8771 | Train Loss: 0.3465 | Validation AUC: 0.8815 | Validation loss: 0.3500\n",
      "Epoch 00022 | Train AUC: 0.8876 | Train Loss: 0.3465 | Validation AUC: 0.8799 | Validation loss: 0.3528\n",
      "Epoch 00023 | Train AUC: 0.8866 | Train Loss: 0.3480 | Validation AUC: 0.8799 | Validation loss: 0.3528\n",
      "Epoch 00024 | Train AUC: 0.8856 | Train Loss: 0.3495 | Validation AUC: 0.8909 | Validation loss: 0.3528\n",
      "Epoch 00025 | Train AUC: 0.8956 | Train Loss: 0.3509 | Validation AUC: 0.8893 | Validation loss: 0.3556\n",
      "Epoch 00026 | Train AUC: 0.9055 | Train Loss: 0.3524 | Validation AUC: 0.8861 | Validation loss: 0.3611\n",
      "Epoch 00027 | Train AUC: 0.9022 | Train Loss: 0.3582 | Validation AUC: 0.8968 | Validation loss: 0.3611\n",
      "Epoch 00028 | Train AUC: 0.8963 | Train Loss: 0.3684 | Validation AUC: 0.8916 | Validation loss: 0.3727\n",
      "Epoch 00029 | Train AUC: 0.9028 | Train Loss: 0.3757 | Validation AUC: 0.8871 | Validation loss: 0.3779\n",
      "Epoch 00030 | Train AUC: 0.8856 | Train Loss: 0.3495 | Validation AUC: 0.8909 | Validation loss: 0.3528\n",
      "Epoch 00031 | Train AUC: 0.8771 | Train Loss: 0.3465 | Validation AUC: 0.8815 | Validation loss: 0.3500\n",
      "Epoch 00032 | Train AUC: 0.8442 | Train Loss: 0.3480 | Validation AUC: 0.8705 | Validation loss: 0.3500\n",
      "Epoch 00033 | Train AUC: 0.8338 | Train Loss: 0.3480 | Validation AUC: 0.8453 | Validation loss: 0.3556\n",
      "Epoch 00034 | Train AUC: 0.8338 | Train Loss: 0.3480 | Validation AUC: 0.8327 | Validation loss: 0.3583\n",
      "Epoch 00035 | Train AUC: 0.8338 | Train Loss: 0.3480 | Validation AUC: 0.8327 | Validation loss: 0.3583\n",
      "Epoch 00036 | Train AUC: 0.8338 | Train Loss: 0.3480 | Validation AUC: 0.8327 | Validation loss: 0.3583\n",
      "Epoch 00037 | Train AUC: 0.8338 | Train Loss: 0.3480 | Validation AUC: 0.8327 | Validation loss: 0.3583\n",
      "Epoch 00038 | Train AUC: 0.8223 | Train Loss: 0.3495 | Validation AUC: 0.7822 | Validation loss: 0.3695\n",
      "Epoch 00039 | Train AUC: 0.8223 | Train Loss: 0.3495 | Validation AUC: 0.7822 | Validation loss: 0.3695\n",
      "Epoch 00040 | Train AUC: 0.8223 | Train Loss: 0.3495 | Validation AUC: 0.7822 | Validation loss: 0.3695\n",
      "Epoch 00041 | Train AUC: 0.8223 | Train Loss: 0.3495 | Validation AUC: 0.7822 | Validation loss: 0.3695\n",
      "Epoch 00042 | Train AUC: 0.8231 | Train Loss: 0.3480 | Validation AUC: 0.7822 | Validation loss: 0.3695\n",
      "Epoch 00043 | Train AUC: 0.8240 | Train Loss: 0.3465 | Validation AUC: 0.7822 | Validation loss: 0.3695\n",
      "Epoch 00044 | Train AUC: 0.8240 | Train Loss: 0.3465 | Validation AUC: 0.7822 | Validation loss: 0.3695\n",
      "Epoch 00045 | Train AUC: 0.8240 | Train Loss: 0.3465 | Validation AUC: 0.7822 | Validation loss: 0.3695\n",
      "Epoch 00046 | Train AUC: 0.8240 | Train Loss: 0.3465 | Validation AUC: 0.7822 | Validation loss: 0.3695\n",
      "Epoch 00047 | Train AUC: 0.8240 | Train Loss: 0.3465 | Validation AUC: 0.7822 | Validation loss: 0.3695\n",
      "Epoch 00048 | Train AUC: 0.8237 | Train Loss: 0.3465 | Validation AUC: 0.7822 | Validation loss: 0.3695\n",
      "Epoch 00049 | Train AUC: 0.8237 | Train Loss: 0.3465 | Validation AUC: 0.7822 | Validation loss: 0.3695\n",
      "Epoch 00050 | Train AUC: 0.8237 | Train Loss: 0.3465 | Validation AUC: 0.7822 | Validation loss: 0.3695\n",
      "Epoch 00051 | Train AUC: 0.8237 | Train Loss: 0.3465 | Validation AUC: 0.7822 | Validation loss: 0.3695\n",
      "Epoch 00052 | Train AUC: 0.8237 | Train Loss: 0.3465 | Validation AUC: 0.7822 | Validation loss: 0.3695\n",
      "Epoch 00053 | Train AUC: 0.8237 | Train Loss: 0.3465 | Validation AUC: 0.7822 | Validation loss: 0.3695\n",
      "Epoch 00054 | Train AUC: 0.8234 | Train Loss: 0.3465 | Validation AUC: 0.7822 | Validation loss: 0.3695\n",
      "Epoch 00055 | Train AUC: 0.8234 | Train Loss: 0.3465 | Validation AUC: 0.7822 | Validation loss: 0.3695\n",
      "Epoch 00056 | Train AUC: 0.8232 | Train Loss: 0.3465 | Validation AUC: 0.7822 | Validation loss: 0.3695\n",
      "Epoch 00057 | Train AUC: 0.8232 | Train Loss: 0.3465 | Validation AUC: 0.7822 | Validation loss: 0.3695\n",
      "Epoch 00058 | Train AUC: 0.8232 | Train Loss: 0.3465 | Validation AUC: 0.7822 | Validation loss: 0.3695\n",
      "Epoch 00059 | Train AUC: 0.8232 | Train Loss: 0.3465 | Validation AUC: 0.7822 | Validation loss: 0.3695\n",
      "Epoch 00060 | Train AUC: 0.8232 | Train Loss: 0.3465 | Validation AUC: 0.7822 | Validation loss: 0.3695\n",
      "Epoch 00061 | Train AUC: 0.8232 | Train Loss: 0.3465 | Validation AUC: 0.7822 | Validation loss: 0.3695\n",
      "Epoch 00062 | Train AUC: 0.8232 | Train Loss: 0.3465 | Validation AUC: 0.7822 | Validation loss: 0.3695\n",
      "Epoch 00063 | Train AUC: 0.8232 | Train Loss: 0.3465 | Validation AUC: 0.7822 | Validation loss: 0.3695\n",
      "Epoch 00064 | Train AUC: 0.8232 | Train Loss: 0.3465 | Validation AUC: 0.7815 | Validation loss: 0.3695\n",
      "Epoch 00065 | Train AUC: 0.8232 | Train Loss: 0.3465 | Validation AUC: 0.7815 | Validation loss: 0.3695\n",
      "Epoch 00066 | Train AUC: 0.8232 | Train Loss: 0.3465 | Validation AUC: 0.7815 | Validation loss: 0.3695\n",
      "Epoch 00067 | Train AUC: 0.8232 | Train Loss: 0.3465 | Validation AUC: 0.7809 | Validation loss: 0.3695\n",
      "Epoch 00068 | Train AUC: 0.8228 | Train Loss: 0.3465 | Validation AUC: 0.7809 | Validation loss: 0.3695\n",
      "Epoch 00069 | Train AUC: 0.8233 | Train Loss: 0.3465 | Validation AUC: 0.7809 | Validation loss: 0.3695\n",
      "Epoch 00070 | Train AUC: 0.8233 | Train Loss: 0.3465 | Validation AUC: 0.7809 | Validation loss: 0.3695\n",
      "Epoch 00071 | Train AUC: 0.8228 | Train Loss: 0.3465 | Validation AUC: 0.7809 | Validation loss: 0.3696\n",
      "Epoch 00072 | Train AUC: 0.8228 | Train Loss: 0.3465 | Validation AUC: 0.7808 | Validation loss: 0.3696\n",
      "Epoch 00073 | Train AUC: 0.8225 | Train Loss: 0.3465 | Validation AUC: 0.7801 | Validation loss: 0.3696\n",
      "Epoch 00074 | Train AUC: 0.8222 | Train Loss: 0.3465 | Validation AUC: 0.7801 | Validation loss: 0.3696\n",
      "Epoch 00075 | Train AUC: 0.8220 | Train Loss: 0.3465 | Validation AUC: 0.7801 | Validation loss: 0.3697\n",
      "Epoch 00076 | Train AUC: 0.8225 | Train Loss: 0.3451 | Validation AUC: 0.7674 | Validation loss: 0.3725\n",
      "Epoch 00077 | Train AUC: 0.7425 | Train Loss: 0.3552 | Validation AUC: 0.7186 | Validation loss: 0.3818\n",
      "Epoch 00078 | Train AUC: 0.8317 | Train Loss: 0.3480 | Validation AUC: 0.8295 | Validation loss: 0.3587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00079 | Train AUC: 0.8951 | Train Loss: 0.3495 | Validation AUC: 0.8887 | Validation loss: 0.3533\n",
      "Epoch 00080 | Train AUC: 0.8323 | Train Loss: 0.3480 | Validation AUC: 0.8316 | Validation loss: 0.3584\n",
      "Epoch 00081 | Train AUC: 0.8331 | Train Loss: 0.3480 | Validation AUC: 0.8322 | Validation loss: 0.3583\n",
      "Epoch 00082 | Train AUC: 0.8215 | Train Loss: 0.3495 | Validation AUC: 0.7822 | Validation loss: 0.3695\n",
      "Epoch 00083 | Train AUC: 0.8226 | Train Loss: 0.3480 | Validation AUC: 0.7822 | Validation loss: 0.3695\n",
      "Epoch 00084 | Train AUC: 0.8229 | Train Loss: 0.3480 | Validation AUC: 0.7822 | Validation loss: 0.3695\n",
      "Epoch 00085 | Train AUC: 0.8240 | Train Loss: 0.3465 | Validation AUC: 0.7822 | Validation loss: 0.3695\n",
      "Epoch 00086 | Train AUC: 0.8240 | Train Loss: 0.3465 | Validation AUC: 0.7822 | Validation loss: 0.3695\n",
      "Epoch 00087 | Train AUC: 0.8240 | Train Loss: 0.3465 | Validation AUC: 0.7822 | Validation loss: 0.3695\n",
      "Epoch 00088 | Train AUC: 0.8240 | Train Loss: 0.3465 | Validation AUC: 0.7822 | Validation loss: 0.3695\n",
      "Epoch 00089 | Train AUC: 0.8240 | Train Loss: 0.3465 | Validation AUC: 0.7822 | Validation loss: 0.3695\n",
      "Epoch 00090 | Train AUC: 0.8240 | Train Loss: 0.3465 | Validation AUC: 0.7822 | Validation loss: 0.3695\n",
      "Epoch 00091 | Train AUC: 0.8240 | Train Loss: 0.3465 | Validation AUC: 0.7822 | Validation loss: 0.3695\n",
      "Epoch 00092 | Train AUC: 0.8240 | Train Loss: 0.3465 | Validation AUC: 0.7822 | Validation loss: 0.3695\n",
      "Epoch 00093 | Train AUC: 0.8240 | Train Loss: 0.3465 | Validation AUC: 0.7822 | Validation loss: 0.3695\n",
      "Epoch 00094 | Train AUC: 0.8240 | Train Loss: 0.3465 | Validation AUC: 0.7822 | Validation loss: 0.3695\n",
      "Epoch 00095 | Train AUC: 0.8240 | Train Loss: 0.3465 | Validation AUC: 0.7822 | Validation loss: 0.3695\n",
      "Epoch 00096 | Train AUC: 0.8240 | Train Loss: 0.3465 | Validation AUC: 0.7822 | Validation loss: 0.3695\n",
      "Epoch 00097 | Train AUC: 0.8240 | Train Loss: 0.3465 | Validation AUC: 0.7822 | Validation loss: 0.3695\n",
      "Epoch 00098 | Train AUC: 0.8240 | Train Loss: 0.3465 | Validation AUC: 0.7822 | Validation loss: 0.3695\n",
      "Epoch 00099 | Train AUC: 0.8240 | Train Loss: 0.3465 | Validation AUC: 0.7822 | Validation loss: 0.3695\n",
      "==== Test Phase ====\n",
      "test auc : 0.8855558369741869\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kudo/.pyenv/versions/3.5.2/lib/python3.5/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/kudo/.pyenv/versions/3.5.2/lib/python3.5/site-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/kudo/.pyenv/versions/3.5.2/lib/python3.5/site-packages/dgl/frame.py:204: UserWarning: Initializer is not set. Use zero initializer instead. To suppress this warning, use `set_initializer` to explicitly specify which initializer to use.\n",
      "  dgl_warning('Initializer is not set. Use zero initializer instead.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([667,  53]))\n",
      "Start 2-th fold\n",
      "==== Train Phase ====\n",
      "Epoch 00000 | Train AUC: 0.8619 | Train Loss: 0.3767 | Validation AUC: 0.9057 | Validation loss: 0.3720\n",
      "Epoch 00001 | Train AUC: 0.8094 | Train Loss: 0.3601 | Validation AUC: 0.8678 | Validation loss: 0.3570\n",
      "Epoch 00002 | Train AUC: 0.7997 | Train Loss: 0.3615 | Validation AUC: 0.8678 | Validation loss: 0.3570\n",
      "Epoch 00003 | Train AUC: 0.7997 | Train Loss: 0.3615 | Validation AUC: 0.8678 | Validation loss: 0.3570\n",
      "Epoch 00004 | Train AUC: 0.7997 | Train Loss: 0.3615 | Validation AUC: 0.8678 | Validation loss: 0.3571\n",
      "Epoch 00005 | Train AUC: 0.8182 | Train Loss: 0.3601 | Validation AUC: 0.8670 | Validation loss: 0.3571\n",
      "Epoch 00006 | Train AUC: 0.8246 | Train Loss: 0.3628 | Validation AUC: 0.8656 | Validation loss: 0.3601\n",
      "Epoch 00007 | Train AUC: 0.7816 | Train Loss: 0.3615 | Validation AUC: 0.8146 | Validation loss: 0.3661\n",
      "Epoch 00008 | Train AUC: 0.7827 | Train Loss: 0.3601 | Validation AUC: 0.8146 | Validation loss: 0.3661\n",
      "Epoch 00009 | Train AUC: 0.7827 | Train Loss: 0.3601 | Validation AUC: 0.7977 | Validation loss: 0.3690\n",
      "Epoch 00010 | Train AUC: 0.7827 | Train Loss: 0.3601 | Validation AUC: 0.7977 | Validation loss: 0.3690\n",
      "Epoch 00011 | Train AUC: 0.7642 | Train Loss: 0.3615 | Validation AUC: 0.7969 | Validation loss: 0.3720\n",
      "Epoch 00012 | Train AUC: 0.7449 | Train Loss: 0.3642 | Validation AUC: 0.7644 | Validation loss: 0.3720\n",
      "Epoch 00013 | Train AUC: 0.7449 | Train Loss: 0.3642 | Validation AUC: 0.7644 | Validation loss: 0.3720\n",
      "Epoch 00014 | Train AUC: 0.7449 | Train Loss: 0.3642 | Validation AUC: 0.7644 | Validation loss: 0.3720\n",
      "Epoch 00015 | Train AUC: 0.7449 | Train Loss: 0.3642 | Validation AUC: 0.7812 | Validation loss: 0.3720\n",
      "Epoch 00016 | Train AUC: 0.7637 | Train Loss: 0.3628 | Validation AUC: 0.7969 | Validation loss: 0.3720\n",
      "Epoch 00017 | Train AUC: 0.8005 | Train Loss: 0.3601 | Validation AUC: 0.8678 | Validation loss: 0.3571\n",
      "Epoch 00018 | Train AUC: 0.8351 | Train Loss: 0.3615 | Validation AUC: 0.8656 | Validation loss: 0.3601\n",
      "Epoch 00019 | Train AUC: 0.8467 | Train Loss: 0.3726 | Validation AUC: 0.8795 | Validation loss: 0.3631\n",
      "Epoch 00020 | Train AUC: 0.8692 | Train Loss: 0.3809 | Validation AUC: 0.8966 | Validation loss: 0.3870\n",
      "Epoch 00021 | Train AUC: 0.8736 | Train Loss: 0.3878 | Validation AUC: 0.8966 | Validation loss: 0.3870\n",
      "Epoch 00022 | Train AUC: 0.8747 | Train Loss: 0.4017 | Validation AUC: 0.9385 | Validation loss: 0.3960\n",
      "Epoch 00023 | Train AUC: 0.8719 | Train Loss: 0.4226 | Validation AUC: 0.9313 | Validation loss: 0.4080\n",
      "Epoch 00024 | Train AUC: 0.8586 | Train Loss: 0.4462 | Validation AUC: 0.9276 | Validation loss: 0.4140\n",
      "Epoch 00025 | Train AUC: 0.8530 | Train Loss: 0.4559 | Validation AUC: 0.9186 | Validation loss: 0.4290\n",
      "Epoch 00026 | Train AUC: 0.8710 | Train Loss: 0.3767 | Validation AUC: 0.9023 | Validation loss: 0.3780\n",
      "Epoch 00027 | Train AUC: 0.8467 | Train Loss: 0.3726 | Validation AUC: 0.8781 | Validation loss: 0.3659\n",
      "Epoch 00028 | Train AUC: 0.8224 | Train Loss: 0.3684 | Validation AUC: 0.8802 | Validation loss: 0.3629\n",
      "Epoch 00029 | Train AUC: 0.8266 | Train Loss: 0.3615 | Validation AUC: 0.8664 | Validation loss: 0.3598\n",
      "Epoch 00030 | Train AUC: 0.8172 | Train Loss: 0.3628 | Validation AUC: 0.8664 | Validation loss: 0.3598\n",
      "Epoch 00031 | Train AUC: 0.8091 | Train Loss: 0.3615 | Validation AUC: 0.8664 | Validation loss: 0.3597\n",
      "Epoch 00032 | Train AUC: 0.8003 | Train Loss: 0.3615 | Validation AUC: 0.8682 | Validation loss: 0.3567\n",
      "Epoch 00033 | Train AUC: 0.8011 | Train Loss: 0.3601 | Validation AUC: 0.8682 | Validation loss: 0.3567\n",
      "Epoch 00034 | Train AUC: 0.8011 | Train Loss: 0.3601 | Validation AUC: 0.8682 | Validation loss: 0.3567\n",
      "Epoch 00035 | Train AUC: 0.7922 | Train Loss: 0.3601 | Validation AUC: 0.8507 | Validation loss: 0.3596\n",
      "Epoch 00036 | Train AUC: 0.7922 | Train Loss: 0.3601 | Validation AUC: 0.8332 | Validation loss: 0.3626\n",
      "Epoch 00037 | Train AUC: 0.7826 | Train Loss: 0.3615 | Validation AUC: 0.8332 | Validation loss: 0.3626\n",
      "Epoch 00038 | Train AUC: 0.7826 | Train Loss: 0.3615 | Validation AUC: 0.8158 | Validation loss: 0.3656\n",
      "Epoch 00039 | Train AUC: 0.7834 | Train Loss: 0.3601 | Validation AUC: 0.8158 | Validation loss: 0.3656\n",
      "Epoch 00040 | Train AUC: 0.7834 | Train Loss: 0.3601 | Validation AUC: 0.8158 | Validation loss: 0.3656\n",
      "Epoch 00041 | Train AUC: 0.7834 | Train Loss: 0.3601 | Validation AUC: 0.8150 | Validation loss: 0.3686\n",
      "Epoch 00042 | Train AUC: 0.7834 | Train Loss: 0.3601 | Validation AUC: 0.7983 | Validation loss: 0.3686\n",
      "Epoch 00043 | Train AUC: 0.7834 | Train Loss: 0.3601 | Validation AUC: 0.7983 | Validation loss: 0.3686\n",
      "Epoch 00044 | Train AUC: 0.7834 | Train Loss: 0.3601 | Validation AUC: 0.7983 | Validation loss: 0.3686\n",
      "Epoch 00045 | Train AUC: 0.7834 | Train Loss: 0.3601 | Validation AUC: 0.7983 | Validation loss: 0.3686\n",
      "Epoch 00046 | Train AUC: 0.7834 | Train Loss: 0.3601 | Validation AUC: 0.7983 | Validation loss: 0.3686\n",
      "Epoch 00047 | Train AUC: 0.7834 | Train Loss: 0.3601 | Validation AUC: 0.7983 | Validation loss: 0.3686\n",
      "Epoch 00048 | Train AUC: 0.7738 | Train Loss: 0.3615 | Validation AUC: 0.7983 | Validation loss: 0.3686\n",
      "Epoch 00049 | Train AUC: 0.7649 | Train Loss: 0.3615 | Validation AUC: 0.7983 | Validation loss: 0.3686\n",
      "Epoch 00050 | Train AUC: 0.7649 | Train Loss: 0.3615 | Validation AUC: 0.7983 | Validation loss: 0.3686\n",
      "Epoch 00051 | Train AUC: 0.7649 | Train Loss: 0.3615 | Validation AUC: 0.7983 | Validation loss: 0.3686\n",
      "Epoch 00052 | Train AUC: 0.7649 | Train Loss: 0.3615 | Validation AUC: 0.7994 | Validation loss: 0.3686\n",
      "Epoch 00053 | Train AUC: 0.7649 | Train Loss: 0.3615 | Validation AUC: 0.7994 | Validation loss: 0.3686\n",
      "Epoch 00054 | Train AUC: 0.7649 | Train Loss: 0.3615 | Validation AUC: 0.7994 | Validation loss: 0.3686\n",
      "Epoch 00055 | Train AUC: 0.7645 | Train Loss: 0.3628 | Validation AUC: 0.7994 | Validation loss: 0.3686\n",
      "Epoch 00056 | Train AUC: 0.7645 | Train Loss: 0.3628 | Validation AUC: 0.7994 | Validation loss: 0.3686\n",
      "Epoch 00057 | Train AUC: 0.7648 | Train Loss: 0.3615 | Validation AUC: 0.7994 | Validation loss: 0.3686\n",
      "Epoch 00058 | Train AUC: 0.7826 | Train Loss: 0.3615 | Validation AUC: 0.8332 | Validation loss: 0.3626\n",
      "Epoch 00059 | Train AUC: 0.8011 | Train Loss: 0.3601 | Validation AUC: 0.8682 | Validation loss: 0.3566\n",
      "Epoch 00060 | Train AUC: 0.8091 | Train Loss: 0.3615 | Validation AUC: 0.8664 | Validation loss: 0.3595\n",
      "Epoch 00061 | Train AUC: 0.8172 | Train Loss: 0.3628 | Validation AUC: 0.8664 | Validation loss: 0.3595\n",
      "Epoch 00062 | Train AUC: 0.8266 | Train Loss: 0.3615 | Validation AUC: 0.8664 | Validation loss: 0.3595\n",
      "Epoch 00063 | Train AUC: 0.8245 | Train Loss: 0.3656 | Validation AUC: 0.8838 | Validation loss: 0.3565\n",
      "Epoch 00064 | Train AUC: 0.8325 | Train Loss: 0.3670 | Validation AUC: 0.8802 | Validation loss: 0.3625\n",
      "Epoch 00065 | Train AUC: 0.8488 | Train Loss: 0.3698 | Validation AUC: 0.8802 | Validation loss: 0.3625\n",
      "Epoch 00066 | Train AUC: 0.8479 | Train Loss: 0.3712 | Validation AUC: 0.8802 | Validation loss: 0.3625\n",
      "Epoch 00067 | Train AUC: 0.8479 | Train Loss: 0.3712 | Validation AUC: 0.8802 | Validation loss: 0.3625\n",
      "Epoch 00068 | Train AUC: 0.8471 | Train Loss: 0.3726 | Validation AUC: 0.8784 | Validation loss: 0.3655\n",
      "Epoch 00069 | Train AUC: 0.8463 | Train Loss: 0.3740 | Validation AUC: 0.8784 | Validation loss: 0.3655\n",
      "Epoch 00070 | Train AUC: 0.8455 | Train Loss: 0.3753 | Validation AUC: 0.8766 | Validation loss: 0.3685\n",
      "Epoch 00071 | Train AUC: 0.8455 | Train Loss: 0.3753 | Validation AUC: 0.8766 | Validation loss: 0.3685\n",
      "Epoch 00072 | Train AUC: 0.8552 | Train Loss: 0.3740 | Validation AUC: 0.8748 | Validation loss: 0.3715\n",
      "Epoch 00073 | Train AUC: 0.8552 | Train Loss: 0.3740 | Validation AUC: 0.8748 | Validation loss: 0.3715\n",
      "Epoch 00074 | Train AUC: 0.8552 | Train Loss: 0.3740 | Validation AUC: 0.9097 | Validation loss: 0.3655\n",
      "Epoch 00075 | Train AUC: 0.8552 | Train Loss: 0.3740 | Validation AUC: 0.9043 | Validation loss: 0.3745\n",
      "Epoch 00076 | Train AUC: 0.8552 | Train Loss: 0.3740 | Validation AUC: 0.9043 | Validation loss: 0.3745\n",
      "Epoch 00077 | Train AUC: 0.8552 | Train Loss: 0.3740 | Validation AUC: 0.9043 | Validation loss: 0.3745\n",
      "Epoch 00078 | Train AUC: 0.8552 | Train Loss: 0.3740 | Validation AUC: 0.9043 | Validation loss: 0.3745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00079 | Train AUC: 0.8552 | Train Loss: 0.3740 | Validation AUC: 0.9043 | Validation loss: 0.3745\n",
      "Epoch 00080 | Train AUC: 0.8552 | Train Loss: 0.3740 | Validation AUC: 0.9043 | Validation loss: 0.3745\n",
      "Epoch 00081 | Train AUC: 0.8552 | Train Loss: 0.3740 | Validation AUC: 0.9043 | Validation loss: 0.3745\n",
      "Epoch 00082 | Train AUC: 0.8552 | Train Loss: 0.3740 | Validation AUC: 0.9043 | Validation loss: 0.3745\n",
      "Epoch 00083 | Train AUC: 0.8552 | Train Loss: 0.3740 | Validation AUC: 0.9043 | Validation loss: 0.3745\n",
      "Epoch 00084 | Train AUC: 0.8552 | Train Loss: 0.3740 | Validation AUC: 0.9043 | Validation loss: 0.3745\n",
      "Epoch 00085 | Train AUC: 0.8552 | Train Loss: 0.3740 | Validation AUC: 0.9043 | Validation loss: 0.3745\n",
      "Epoch 00086 | Train AUC: 0.8552 | Train Loss: 0.3740 | Validation AUC: 0.9043 | Validation loss: 0.3745\n",
      "Epoch 00087 | Train AUC: 0.8552 | Train Loss: 0.3740 | Validation AUC: 0.9043 | Validation loss: 0.3745\n",
      "Epoch 00088 | Train AUC: 0.8552 | Train Loss: 0.3740 | Validation AUC: 0.9043 | Validation loss: 0.3745\n",
      "Epoch 00089 | Train AUC: 0.8552 | Train Loss: 0.3740 | Validation AUC: 0.9043 | Validation loss: 0.3745\n",
      "Epoch 00090 | Train AUC: 0.8552 | Train Loss: 0.3740 | Validation AUC: 0.9077 | Validation loss: 0.3685\n",
      "Epoch 00091 | Train AUC: 0.8552 | Train Loss: 0.3740 | Validation AUC: 0.9097 | Validation loss: 0.3655\n",
      "Epoch 00092 | Train AUC: 0.8552 | Train Loss: 0.3740 | Validation AUC: 0.8923 | Validation loss: 0.3685\n",
      "Epoch 00093 | Train AUC: 0.8552 | Train Loss: 0.3740 | Validation AUC: 0.8748 | Validation loss: 0.3715\n",
      "Epoch 00094 | Train AUC: 0.8552 | Train Loss: 0.3740 | Validation AUC: 0.8748 | Validation loss: 0.3715\n",
      "Epoch 00095 | Train AUC: 0.8552 | Train Loss: 0.3740 | Validation AUC: 0.8748 | Validation loss: 0.3715\n",
      "Epoch 00096 | Train AUC: 0.8552 | Train Loss: 0.3740 | Validation AUC: 0.8748 | Validation loss: 0.3715\n",
      "Epoch 00097 | Train AUC: 0.8552 | Train Loss: 0.3740 | Validation AUC: 0.8748 | Validation loss: 0.3715\n",
      "Epoch 00098 | Train AUC: 0.8552 | Train Loss: 0.3740 | Validation AUC: 0.8748 | Validation loss: 0.3715\n",
      "Epoch 00099 | Train AUC: 0.8552 | Train Loss: 0.3740 | Validation AUC: 0.8748 | Validation loss: 0.3715\n",
      "==== Test Phase ====\n",
      "test auc : 0.939071107452669\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kudo/.pyenv/versions/3.5.2/lib/python3.5/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/kudo/.pyenv/versions/3.5.2/lib/python3.5/site-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/kudo/.pyenv/versions/3.5.2/lib/python3.5/site-packages/dgl/frame.py:204: UserWarning: Initializer is not set. Use zero initializer instead. To suppress this warning, use `set_initializer` to explicitly specify which initializer to use.\n",
      "  dgl_warning('Initializer is not set. Use zero initializer instead.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([632,  63]))\n",
      "Start 3-th fold\n",
      "==== Train Phase ====\n",
      "Epoch 00000 | Train AUC: 0.4540 | Train Loss: 1.2241 | Validation AUC: 0.5015 | Validation loss: 1.2183\n",
      "Epoch 00001 | Train AUC: 0.4461 | Train Loss: 1.2241 | Validation AUC: 0.5015 | Validation loss: 1.2183\n",
      "Epoch 00002 | Train AUC: 0.4547 | Train Loss: 1.2241 | Validation AUC: 0.5031 | Validation loss: 1.2182\n",
      "Epoch 00003 | Train AUC: 0.4679 | Train Loss: 1.2123 | Validation AUC: 0.5170 | Validation loss: 1.2055\n",
      "Epoch 00004 | Train AUC: 0.8446 | Train Loss: 0.3526 | Validation AUC: 0.6979 | Validation loss: 0.3803\n",
      "Epoch 00005 | Train AUC: 0.8593 | Train Loss: 0.3507 | Validation AUC: 0.6948 | Validation loss: 0.3859\n",
      "Epoch 00006 | Train AUC: 0.8593 | Train Loss: 0.3507 | Validation AUC: 0.6957 | Validation loss: 0.3859\n",
      "Epoch 00007 | Train AUC: 0.8593 | Train Loss: 0.3507 | Validation AUC: 0.6957 | Validation loss: 0.3859\n",
      "Epoch 00008 | Train AUC: 0.8593 | Train Loss: 0.3507 | Validation AUC: 0.6966 | Validation loss: 0.3859\n",
      "Epoch 00009 | Train AUC: 0.8593 | Train Loss: 0.3507 | Validation AUC: 0.6966 | Validation loss: 0.3859\n",
      "Epoch 00010 | Train AUC: 0.8593 | Train Loss: 0.3507 | Validation AUC: 0.6966 | Validation loss: 0.3859\n",
      "Epoch 00011 | Train AUC: 0.8593 | Train Loss: 0.3507 | Validation AUC: 0.6966 | Validation loss: 0.3859\n",
      "Epoch 00012 | Train AUC: 0.8593 | Train Loss: 0.3507 | Validation AUC: 0.6966 | Validation loss: 0.3859\n",
      "Epoch 00013 | Train AUC: 0.8593 | Train Loss: 0.3507 | Validation AUC: 0.6966 | Validation loss: 0.3859\n",
      "Epoch 00014 | Train AUC: 0.8593 | Train Loss: 0.3507 | Validation AUC: 0.6966 | Validation loss: 0.3859\n",
      "Epoch 00015 | Train AUC: 0.8673 | Train Loss: 0.3493 | Validation AUC: 0.6966 | Validation loss: 0.3859\n",
      "Epoch 00016 | Train AUC: 0.8673 | Train Loss: 0.3493 | Validation AUC: 0.6966 | Validation loss: 0.3859\n",
      "Epoch 00017 | Train AUC: 0.8673 | Train Loss: 0.3493 | Validation AUC: 0.6966 | Validation loss: 0.3859\n",
      "Epoch 00018 | Train AUC: 0.8673 | Train Loss: 0.3493 | Validation AUC: 0.6966 | Validation loss: 0.3859\n",
      "Epoch 00019 | Train AUC: 0.8664 | Train Loss: 0.3507 | Validation AUC: 0.6966 | Validation loss: 0.3859\n",
      "Epoch 00020 | Train AUC: 0.8664 | Train Loss: 0.3507 | Validation AUC: 0.7113 | Validation loss: 0.3831\n",
      "Epoch 00021 | Train AUC: 0.8664 | Train Loss: 0.3507 | Validation AUC: 0.7260 | Validation loss: 0.3803\n",
      "Epoch 00022 | Train AUC: 0.8664 | Train Loss: 0.3507 | Validation AUC: 0.7260 | Validation loss: 0.3803\n",
      "Epoch 00023 | Train AUC: 0.8664 | Train Loss: 0.3507 | Validation AUC: 0.7260 | Validation loss: 0.3803\n",
      "Epoch 00024 | Train AUC: 0.8664 | Train Loss: 0.3507 | Validation AUC: 0.7260 | Validation loss: 0.3803\n",
      "Epoch 00025 | Train AUC: 0.8664 | Train Loss: 0.3507 | Validation AUC: 0.7260 | Validation loss: 0.3803\n",
      "Epoch 00026 | Train AUC: 0.8664 | Train Loss: 0.3507 | Validation AUC: 0.7260 | Validation loss: 0.3803\n",
      "Epoch 00027 | Train AUC: 0.8664 | Train Loss: 0.3507 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00028 | Train AUC: 0.8664 | Train Loss: 0.3507 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00029 | Train AUC: 0.8664 | Train Loss: 0.3507 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00030 | Train AUC: 0.8664 | Train Loss: 0.3507 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00031 | Train AUC: 0.8664 | Train Loss: 0.3507 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00032 | Train AUC: 0.8664 | Train Loss: 0.3507 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00033 | Train AUC: 0.8664 | Train Loss: 0.3507 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00034 | Train AUC: 0.8664 | Train Loss: 0.3507 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00035 | Train AUC: 0.8664 | Train Loss: 0.3507 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00036 | Train AUC: 0.8664 | Train Loss: 0.3507 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00037 | Train AUC: 0.8664 | Train Loss: 0.3507 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00038 | Train AUC: 0.8664 | Train Loss: 0.3507 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00039 | Train AUC: 0.8664 | Train Loss: 0.3507 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00040 | Train AUC: 0.8664 | Train Loss: 0.3507 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00041 | Train AUC: 0.8664 | Train Loss: 0.3507 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00042 | Train AUC: 0.8664 | Train Loss: 0.3507 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00043 | Train AUC: 0.8664 | Train Loss: 0.3507 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00044 | Train AUC: 0.8664 | Train Loss: 0.3507 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00045 | Train AUC: 0.8664 | Train Loss: 0.3507 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00046 | Train AUC: 0.8662 | Train Loss: 0.3507 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00047 | Train AUC: 0.8655 | Train Loss: 0.3522 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00048 | Train AUC: 0.8655 | Train Loss: 0.3522 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00049 | Train AUC: 0.8655 | Train Loss: 0.3522 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00050 | Train AUC: 0.8655 | Train Loss: 0.3522 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00051 | Train AUC: 0.8655 | Train Loss: 0.3522 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00052 | Train AUC: 0.8655 | Train Loss: 0.3522 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00053 | Train AUC: 0.8655 | Train Loss: 0.3522 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00054 | Train AUC: 0.8655 | Train Loss: 0.3522 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00055 | Train AUC: 0.8655 | Train Loss: 0.3522 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00056 | Train AUC: 0.8655 | Train Loss: 0.3522 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00057 | Train AUC: 0.8655 | Train Loss: 0.3522 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00058 | Train AUC: 0.8655 | Train Loss: 0.3522 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00059 | Train AUC: 0.8655 | Train Loss: 0.3522 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00060 | Train AUC: 0.8655 | Train Loss: 0.3522 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00061 | Train AUC: 0.8655 | Train Loss: 0.3522 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00062 | Train AUC: 0.8647 | Train Loss: 0.3536 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00063 | Train AUC: 0.8647 | Train Loss: 0.3536 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00064 | Train AUC: 0.8647 | Train Loss: 0.3536 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00065 | Train AUC: 0.8647 | Train Loss: 0.3536 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00066 | Train AUC: 0.8647 | Train Loss: 0.3536 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00067 | Train AUC: 0.8647 | Train Loss: 0.3536 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00068 | Train AUC: 0.8647 | Train Loss: 0.3536 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00069 | Train AUC: 0.8647 | Train Loss: 0.3536 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00070 | Train AUC: 0.8647 | Train Loss: 0.3536 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00071 | Train AUC: 0.8647 | Train Loss: 0.3536 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00072 | Train AUC: 0.8647 | Train Loss: 0.3536 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00073 | Train AUC: 0.8647 | Train Loss: 0.3536 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00074 | Train AUC: 0.8647 | Train Loss: 0.3536 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00075 | Train AUC: 0.8647 | Train Loss: 0.3536 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00076 | Train AUC: 0.8647 | Train Loss: 0.3536 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00077 | Train AUC: 0.8647 | Train Loss: 0.3536 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00078 | Train AUC: 0.8647 | Train Loss: 0.3536 | Validation AUC: 0.7407 | Validation loss: 0.3775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00079 | Train AUC: 0.8647 | Train Loss: 0.3536 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00080 | Train AUC: 0.8647 | Train Loss: 0.3536 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00081 | Train AUC: 0.8647 | Train Loss: 0.3536 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00082 | Train AUC: 0.8647 | Train Loss: 0.3536 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00083 | Train AUC: 0.8647 | Train Loss: 0.3536 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00084 | Train AUC: 0.8647 | Train Loss: 0.3536 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00085 | Train AUC: 0.8647 | Train Loss: 0.3536 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00086 | Train AUC: 0.8647 | Train Loss: 0.3536 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00087 | Train AUC: 0.8647 | Train Loss: 0.3536 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00088 | Train AUC: 0.8647 | Train Loss: 0.3536 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00089 | Train AUC: 0.8647 | Train Loss: 0.3536 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00090 | Train AUC: 0.8647 | Train Loss: 0.3536 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00091 | Train AUC: 0.8647 | Train Loss: 0.3536 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00092 | Train AUC: 0.8647 | Train Loss: 0.3536 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00093 | Train AUC: 0.8647 | Train Loss: 0.3536 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00094 | Train AUC: 0.8647 | Train Loss: 0.3536 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00095 | Train AUC: 0.8647 | Train Loss: 0.3536 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00096 | Train AUC: 0.8647 | Train Loss: 0.3536 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00097 | Train AUC: 0.8647 | Train Loss: 0.3536 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00098 | Train AUC: 0.8647 | Train Loss: 0.3536 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "Epoch 00099 | Train AUC: 0.8647 | Train Loss: 0.3536 | Validation AUC: 0.7407 | Validation loss: 0.3775\n",
      "==== Test Phase ====\n",
      "test auc : 0.7544895501390828\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kudo/.pyenv/versions/3.5.2/lib/python3.5/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/kudo/.pyenv/versions/3.5.2/lib/python3.5/site-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/kudo/.pyenv/versions/3.5.2/lib/python3.5/site-packages/dgl/frame.py:204: UserWarning: Initializer is not set. Use zero initializer instead. To suppress this warning, use `set_initializer` to explicitly specify which initializer to use.\n",
      "  dgl_warning('Initializer is not set. Use zero initializer instead.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([622,  61]))\n",
      "Start 4-th fold\n",
      "==== Train Phase ====\n",
      "Epoch 00000 | Train AUC: 0.4832 | Train Loss: 1.2193 | Validation AUC: 0.4634 | Validation loss: 1.2358\n",
      "Epoch 00001 | Train AUC: 0.5100 | Train Loss: 0.4049 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00002 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00003 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00004 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00005 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00006 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00007 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00008 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00009 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00010 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00011 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00012 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00013 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00014 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00015 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00016 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00017 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00018 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00019 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00020 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00021 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00022 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00023 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00024 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00025 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00026 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00027 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00028 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00029 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00030 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00031 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00032 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00033 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00034 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00035 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00036 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5382 | Validation loss: 0.3885\n",
      "Epoch 00037 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5382 | Validation loss: 0.3885\n",
      "Epoch 00038 | Train AUC: 0.5092 | Train Loss: 0.4047 | Validation AUC: 0.5366 | Validation loss: 0.3885\n",
      "Epoch 00039 | Train AUC: 0.5165 | Train Loss: 0.4047 | Validation AUC: 0.5366 | Validation loss: 0.3885\n",
      "Epoch 00040 | Train AUC: 0.7079 | Train Loss: 0.3739 | Validation AUC: 0.6821 | Validation loss: 0.3698\n",
      "Epoch 00041 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5382 | Validation loss: 0.3885\n",
      "Epoch 00042 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00043 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00044 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00045 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00046 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00047 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00048 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00049 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00050 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00051 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00052 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00053 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00054 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00055 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00056 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00057 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00058 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00059 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00060 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00061 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00062 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00063 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00064 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00065 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00066 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5382 | Validation loss: 0.3885\n",
      "Epoch 00067 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5382 | Validation loss: 0.3885\n",
      "Epoch 00068 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5382 | Validation loss: 0.3885\n",
      "Epoch 00069 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5382 | Validation loss: 0.3885\n",
      "Epoch 00070 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5382 | Validation loss: 0.3885\n",
      "Epoch 00071 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5366 | Validation loss: 0.3885\n",
      "Epoch 00072 | Train AUC: 0.5084 | Train Loss: 0.4047 | Validation AUC: 0.5366 | Validation loss: 0.3885\n",
      "Epoch 00073 | Train AUC: 0.5084 | Train Loss: 0.4047 | Validation AUC: 0.5366 | Validation loss: 0.3885\n",
      "Epoch 00074 | Train AUC: 0.5246 | Train Loss: 0.4047 | Validation AUC: 0.5366 | Validation loss: 0.3885\n",
      "Epoch 00075 | Train AUC: 0.5326 | Train Loss: 0.4047 | Validation AUC: 0.5366 | Validation loss: 0.3884\n",
      "Epoch 00076 | Train AUC: 0.5649 | Train Loss: 0.4047 | Validation AUC: 0.5572 | Validation loss: 0.3883\n",
      "Epoch 00077 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00078 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00079 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00080 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00081 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00082 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00083 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00084 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00085 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00086 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00087 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00088 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00089 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00090 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00091 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00092 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00093 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00094 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00095 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00096 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00097 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00098 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "Epoch 00099 | Train AUC: 0.5100 | Train Loss: 0.4047 | Validation AUC: 0.5175 | Validation loss: 0.3885\n",
      "==== Test Phase ====\n",
      "test auc : 0.5724243037866757\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kudo/.pyenv/versions/3.5.2/lib/python3.5/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/kudo/.pyenv/versions/3.5.2/lib/python3.5/site-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/kudo/.pyenv/versions/3.5.2/lib/python3.5/site-packages/dgl/frame.py:204: UserWarning: Initializer is not set. Use zero initializer instead. To suppress this warning, use `set_initializer` to explicitly specify which initializer to use.\n",
      "  dgl_warning('Initializer is not set. Use zero initializer instead.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([642,  58]))\n",
      "Start 5-th fold\n",
      "==== Train Phase ====\n",
      "Epoch 00000 | Train AUC: 0.1218 | Train Loss: 1.2718 | Validation AUC: 0.2300 | Validation loss: 1.2508\n",
      "Epoch 00001 | Train AUC: 0.0603 | Train Loss: 1.2560 | Validation AUC: 0.1329 | Validation loss: 1.2481\n",
      "Epoch 00002 | Train AUC: 0.1540 | Train Loss: 1.2699 | Validation AUC: 0.2567 | Validation loss: 1.2508\n",
      "Epoch 00003 | Train AUC: 0.1541 | Train Loss: 1.2688 | Validation AUC: 0.2707 | Validation loss: 1.2481\n",
      "Epoch 00004 | Train AUC: 0.1628 | Train Loss: 1.2674 | Validation AUC: 0.2847 | Validation loss: 1.2454\n",
      "Epoch 00005 | Train AUC: 0.1713 | Train Loss: 1.2674 | Validation AUC: 0.2847 | Validation loss: 1.2454\n",
      "Epoch 00006 | Train AUC: 0.1886 | Train Loss: 1.2645 | Validation AUC: 0.2847 | Validation loss: 1.2477\n",
      "Epoch 00007 | Train AUC: 0.1886 | Train Loss: 1.2645 | Validation AUC: 0.2847 | Validation loss: 1.2480\n",
      "Epoch 00008 | Train AUC: 0.1886 | Train Loss: 1.2645 | Validation AUC: 0.2847 | Validation loss: 1.2479\n",
      "Epoch 00009 | Train AUC: 0.1891 | Train Loss: 1.2645 | Validation AUC: 0.2847 | Validation loss: 1.2476\n",
      "Epoch 00010 | Train AUC: 0.1891 | Train Loss: 1.2645 | Validation AUC: 0.2847 | Validation loss: 1.2469\n",
      "Epoch 00011 | Train AUC: 0.1891 | Train Loss: 1.2645 | Validation AUC: 0.2847 | Validation loss: 1.2466\n",
      "Epoch 00012 | Train AUC: 0.1883 | Train Loss: 1.2660 | Validation AUC: 0.2847 | Validation loss: 1.2464\n",
      "Epoch 00013 | Train AUC: 0.1883 | Train Loss: 1.2660 | Validation AUC: 0.2987 | Validation loss: 1.2436\n",
      "Epoch 00014 | Train AUC: 0.1883 | Train Loss: 1.2660 | Validation AUC: 0.2987 | Validation loss: 1.2433\n",
      "Epoch 00015 | Train AUC: 0.1883 | Train Loss: 1.2660 | Validation AUC: 0.3127 | Validation loss: 1.2402\n",
      "Epoch 00016 | Train AUC: 0.1883 | Train Loss: 1.2660 | Validation AUC: 0.3127 | Validation loss: 1.2401\n",
      "Epoch 00017 | Train AUC: 0.1883 | Train Loss: 1.2660 | Validation AUC: 0.3127 | Validation loss: 1.2400\n",
      "Epoch 00018 | Train AUC: 0.1883 | Train Loss: 1.2660 | Validation AUC: 0.3127 | Validation loss: 1.2400\n",
      "Epoch 00019 | Train AUC: 0.1883 | Train Loss: 1.2660 | Validation AUC: 0.3127 | Validation loss: 1.2400\n",
      "Epoch 00020 | Train AUC: 0.1883 | Train Loss: 1.2660 | Validation AUC: 0.3127 | Validation loss: 1.2400\n",
      "Epoch 00021 | Train AUC: 0.1883 | Train Loss: 1.2660 | Validation AUC: 0.3127 | Validation loss: 1.2400\n",
      "Epoch 00022 | Train AUC: 0.1883 | Train Loss: 1.2660 | Validation AUC: 0.3127 | Validation loss: 1.2400\n",
      "Epoch 00023 | Train AUC: 0.1883 | Train Loss: 1.2660 | Validation AUC: 0.3127 | Validation loss: 1.2400\n",
      "Epoch 00024 | Train AUC: 0.1883 | Train Loss: 1.2660 | Validation AUC: 0.3268 | Validation loss: 1.2373\n",
      "Epoch 00025 | Train AUC: 0.1883 | Train Loss: 1.2660 | Validation AUC: 0.3268 | Validation loss: 1.2373\n",
      "Epoch 00026 | Train AUC: 0.1883 | Train Loss: 1.2660 | Validation AUC: 0.3408 | Validation loss: 1.2347\n",
      "Epoch 00027 | Train AUC: 0.1884 | Train Loss: 1.2660 | Validation AUC: 0.3408 | Validation loss: 1.2347\n",
      "Epoch 00028 | Train AUC: 0.2131 | Train Loss: 1.2631 | Validation AUC: 0.3813 | Validation loss: 1.2293\n",
      "Epoch 00029 | Train AUC: 0.2116 | Train Loss: 1.2660 | Validation AUC: 0.3810 | Validation loss: 1.2294\n",
      "Epoch 00030 | Train AUC: 0.2123 | Train Loss: 1.2645 | Validation AUC: 0.3813 | Validation loss: 1.2293\n",
      "Epoch 00031 | Train AUC: 0.2131 | Train Loss: 1.2631 | Validation AUC: 0.3813 | Validation loss: 1.2293\n",
      "Epoch 00032 | Train AUC: 0.2135 | Train Loss: 1.2631 | Validation AUC: 0.3813 | Validation loss: 1.2293\n",
      "Epoch 00033 | Train AUC: 0.2135 | Train Loss: 1.2631 | Validation AUC: 0.3673 | Validation loss: 1.2320\n",
      "Epoch 00034 | Train AUC: 0.1970 | Train Loss: 1.2645 | Validation AUC: 0.3548 | Validation loss: 1.2320\n",
      "Epoch 00035 | Train AUC: 0.1970 | Train Loss: 1.2645 | Validation AUC: 0.3548 | Validation loss: 1.2320\n",
      "Epoch 00036 | Train AUC: 0.1970 | Train Loss: 1.2645 | Validation AUC: 0.3548 | Validation loss: 1.2320\n",
      "Epoch 00037 | Train AUC: 0.1970 | Train Loss: 1.2645 | Validation AUC: 0.3548 | Validation loss: 1.2320\n",
      "Epoch 00038 | Train AUC: 0.1970 | Train Loss: 1.2645 | Validation AUC: 0.3268 | Validation loss: 1.2373\n",
      "Epoch 00039 | Train AUC: 0.1974 | Train Loss: 1.2645 | Validation AUC: 0.3127 | Validation loss: 1.2400\n",
      "Epoch 00040 | Train AUC: 0.1974 | Train Loss: 1.2645 | Validation AUC: 0.3127 | Validation loss: 1.2400\n",
      "Epoch 00041 | Train AUC: 0.1974 | Train Loss: 1.2645 | Validation AUC: 0.3127 | Validation loss: 1.2400\n",
      "Epoch 00042 | Train AUC: 0.1888 | Train Loss: 1.2660 | Validation AUC: 0.3127 | Validation loss: 1.2400\n",
      "Epoch 00043 | Train AUC: 0.1887 | Train Loss: 1.2660 | Validation AUC: 0.3127 | Validation loss: 1.2400\n",
      "Epoch 00044 | Train AUC: 0.1887 | Train Loss: 1.2660 | Validation AUC: 0.3127 | Validation loss: 1.2400\n",
      "Epoch 00045 | Train AUC: 0.1887 | Train Loss: 1.2660 | Validation AUC: 0.3127 | Validation loss: 1.2400\n",
      "Epoch 00046 | Train AUC: 0.1887 | Train Loss: 1.2660 | Validation AUC: 0.3127 | Validation loss: 1.2400\n",
      "Epoch 00047 | Train AUC: 0.1887 | Train Loss: 1.2660 | Validation AUC: 0.3127 | Validation loss: 1.2400\n",
      "Epoch 00048 | Train AUC: 0.1887 | Train Loss: 1.2660 | Validation AUC: 0.3127 | Validation loss: 1.2400\n",
      "Epoch 00049 | Train AUC: 0.1887 | Train Loss: 1.2660 | Validation AUC: 0.3127 | Validation loss: 1.2400\n",
      "Epoch 00050 | Train AUC: 0.1887 | Train Loss: 1.2660 | Validation AUC: 0.3127 | Validation loss: 1.2400\n",
      "Epoch 00051 | Train AUC: 0.1887 | Train Loss: 1.2660 | Validation AUC: 0.3127 | Validation loss: 1.2400\n",
      "Epoch 00052 | Train AUC: 0.1887 | Train Loss: 1.2660 | Validation AUC: 0.2987 | Validation loss: 1.2427\n",
      "Epoch 00053 | Train AUC: 0.1887 | Train Loss: 1.2660 | Validation AUC: 0.2987 | Validation loss: 1.2427\n",
      "Epoch 00054 | Train AUC: 0.1887 | Train Loss: 1.2660 | Validation AUC: 0.2987 | Validation loss: 1.2427\n",
      "Epoch 00055 | Train AUC: 0.1887 | Train Loss: 1.2660 | Validation AUC: 0.2987 | Validation loss: 1.2427\n",
      "Epoch 00056 | Train AUC: 0.1887 | Train Loss: 1.2660 | Validation AUC: 0.2987 | Validation loss: 1.2427\n",
      "Epoch 00057 | Train AUC: 0.1887 | Train Loss: 1.2660 | Validation AUC: 0.2987 | Validation loss: 1.2427\n",
      "Epoch 00058 | Train AUC: 0.1887 | Train Loss: 1.2660 | Validation AUC: 0.2987 | Validation loss: 1.2427\n",
      "Epoch 00059 | Train AUC: 0.1887 | Train Loss: 1.2660 | Validation AUC: 0.2987 | Validation loss: 1.2427\n",
      "Epoch 00060 | Train AUC: 0.1887 | Train Loss: 1.2660 | Validation AUC: 0.2987 | Validation loss: 1.2427\n",
      "Epoch 00061 | Train AUC: 0.1887 | Train Loss: 1.2660 | Validation AUC: 0.2987 | Validation loss: 1.2427\n",
      "Epoch 00062 | Train AUC: 0.1887 | Train Loss: 1.2660 | Validation AUC: 0.2987 | Validation loss: 1.2427\n",
      "Epoch 00063 | Train AUC: 0.1887 | Train Loss: 1.2660 | Validation AUC: 0.2987 | Validation loss: 1.2427\n",
      "Epoch 00064 | Train AUC: 0.1887 | Train Loss: 1.2660 | Validation AUC: 0.2987 | Validation loss: 1.2427\n",
      "Epoch 00065 | Train AUC: 0.1887 | Train Loss: 1.2660 | Validation AUC: 0.2987 | Validation loss: 1.2427\n",
      "Epoch 00066 | Train AUC: 0.1887 | Train Loss: 1.2660 | Validation AUC: 0.2987 | Validation loss: 1.2427\n",
      "Epoch 00067 | Train AUC: 0.1887 | Train Loss: 1.2660 | Validation AUC: 0.2987 | Validation loss: 1.2427\n",
      "Epoch 00068 | Train AUC: 0.1887 | Train Loss: 1.2660 | Validation AUC: 0.2987 | Validation loss: 1.2427\n",
      "Epoch 00069 | Train AUC: 0.1887 | Train Loss: 1.2660 | Validation AUC: 0.2987 | Validation loss: 1.2427\n",
      "Epoch 00070 | Train AUC: 0.1887 | Train Loss: 1.2660 | Validation AUC: 0.2987 | Validation loss: 1.2427\n",
      "Epoch 00071 | Train AUC: 0.1887 | Train Loss: 1.2660 | Validation AUC: 0.2987 | Validation loss: 1.2427\n",
      "Epoch 00072 | Train AUC: 0.1887 | Train Loss: 1.2660 | Validation AUC: 0.2987 | Validation loss: 1.2427\n",
      "Epoch 00073 | Train AUC: 0.1887 | Train Loss: 1.2660 | Validation AUC: 0.2987 | Validation loss: 1.2427\n",
      "Epoch 00074 | Train AUC: 0.1887 | Train Loss: 1.2660 | Validation AUC: 0.2987 | Validation loss: 1.2427\n",
      "Epoch 00075 | Train AUC: 0.1887 | Train Loss: 1.2660 | Validation AUC: 0.2987 | Validation loss: 1.2427\n",
      "Epoch 00076 | Train AUC: 0.1887 | Train Loss: 1.2660 | Validation AUC: 0.2987 | Validation loss: 1.2427\n",
      "Epoch 00077 | Train AUC: 0.1887 | Train Loss: 1.2660 | Validation AUC: 0.2987 | Validation loss: 1.2427\n",
      "Epoch 00078 | Train AUC: 0.1887 | Train Loss: 1.2660 | Validation AUC: 0.2987 | Validation loss: 1.2427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00079 | Train AUC: 0.1887 | Train Loss: 1.2660 | Validation AUC: 0.2987 | Validation loss: 1.2427\n",
      "Epoch 00080 | Train AUC: 0.1887 | Train Loss: 1.2660 | Validation AUC: 0.2987 | Validation loss: 1.2427\n",
      "Epoch 00081 | Train AUC: 0.1887 | Train Loss: 1.2660 | Validation AUC: 0.2987 | Validation loss: 1.2427\n",
      "Epoch 00082 | Train AUC: 0.1887 | Train Loss: 1.2660 | Validation AUC: 0.2987 | Validation loss: 1.2427\n",
      "Epoch 00083 | Train AUC: 0.1887 | Train Loss: 1.2660 | Validation AUC: 0.2987 | Validation loss: 1.2427\n",
      "Epoch 00084 | Train AUC: 0.1887 | Train Loss: 1.2660 | Validation AUC: 0.2987 | Validation loss: 1.2427\n",
      "Epoch 00085 | Train AUC: 0.1887 | Train Loss: 1.2660 | Validation AUC: 0.2987 | Validation loss: 1.2427\n",
      "Epoch 00086 | Train AUC: 0.1887 | Train Loss: 1.2660 | Validation AUC: 0.2987 | Validation loss: 1.2427\n",
      "Epoch 00087 | Train AUC: 0.1887 | Train Loss: 1.2660 | Validation AUC: 0.2987 | Validation loss: 1.2427\n",
      "Epoch 00088 | Train AUC: 0.1887 | Train Loss: 1.2660 | Validation AUC: 0.2987 | Validation loss: 1.2427\n",
      "Epoch 00089 | Train AUC: 0.1887 | Train Loss: 1.2660 | Validation AUC: 0.2987 | Validation loss: 1.2427\n",
      "Epoch 00090 | Train AUC: 0.1887 | Train Loss: 1.2660 | Validation AUC: 0.2987 | Validation loss: 1.2427\n",
      "Epoch 00091 | Train AUC: 0.1887 | Train Loss: 1.2660 | Validation AUC: 0.2987 | Validation loss: 1.2427\n",
      "Epoch 00092 | Train AUC: 0.1887 | Train Loss: 1.2660 | Validation AUC: 0.2987 | Validation loss: 1.2427\n",
      "Epoch 00093 | Train AUC: 0.1887 | Train Loss: 1.2660 | Validation AUC: 0.2987 | Validation loss: 1.2427\n",
      "Epoch 00094 | Train AUC: 0.1887 | Train Loss: 1.2660 | Validation AUC: 0.2987 | Validation loss: 1.2427\n",
      "Epoch 00095 | Train AUC: 0.1887 | Train Loss: 1.2660 | Validation AUC: 0.2987 | Validation loss: 1.2427\n",
      "Epoch 00096 | Train AUC: 0.1887 | Train Loss: 1.2660 | Validation AUC: 0.2987 | Validation loss: 1.2427\n",
      "Epoch 00097 | Train AUC: 0.1887 | Train Loss: 1.2660 | Validation AUC: 0.2987 | Validation loss: 1.2427\n",
      "Epoch 00098 | Train AUC: 0.1887 | Train Loss: 1.2660 | Validation AUC: 0.2987 | Validation loss: 1.2427\n",
      "Epoch 00099 | Train AUC: 0.1887 | Train Loss: 1.2660 | Validation AUC: 0.2987 | Validation loss: 1.2427\n",
      "==== Test Phase ====\n",
      "test auc : 0.34638011702138993\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kudo/.pyenv/versions/3.5.2/lib/python3.5/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/kudo/.pyenv/versions/3.5.2/lib/python3.5/site-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/kudo/.pyenv/versions/3.5.2/lib/python3.5/site-packages/dgl/frame.py:204: UserWarning: Initializer is not set. Use zero initializer instead. To suppress this warning, use `set_initializer` to explicitly specify which initializer to use.\n",
      "  dgl_warning('Initializer is not set. Use zero initializer instead.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([670,  72]))\n",
      "Start 6-th fold\n",
      "==== Train Phase ====\n",
      "Epoch 00000 | Train AUC: 0.4804 | Train Loss: 1.2099 | Validation AUC: 0.4889 | Validation loss: 1.2139\n",
      "Epoch 00001 | Train AUC: 0.4811 | Train Loss: 1.2099 | Validation AUC: 0.4889 | Validation loss: 1.2139\n",
      "Epoch 00002 | Train AUC: 0.2055 | Train Loss: 1.2503 | Validation AUC: 0.2525 | Validation loss: 1.2445\n",
      "Epoch 00003 | Train AUC: 0.1931 | Train Loss: 1.2503 | Validation AUC: 0.1904 | Validation loss: 1.2537\n",
      "Epoch 00004 | Train AUC: 0.1875 | Train Loss: 1.2490 | Validation AUC: 0.1742 | Validation loss: 1.2537\n",
      "Epoch 00005 | Train AUC: 0.1933 | Train Loss: 1.2490 | Validation AUC: 0.1904 | Validation loss: 1.2537\n",
      "Epoch 00006 | Train AUC: 0.5154 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00007 | Train AUC: 0.5168 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00008 | Train AUC: 0.5189 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00009 | Train AUC: 0.5189 | Train Loss: 0.4121 | Validation AUC: 0.5094 | Validation loss: 0.4097\n",
      "Epoch 00010 | Train AUC: 0.5189 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00011 | Train AUC: 0.5189 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00012 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00013 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00014 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00015 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00016 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00017 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00018 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00019 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00020 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00021 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00022 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00023 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00024 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00025 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00026 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00027 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00028 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00029 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00030 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00031 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00032 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00033 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00034 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00035 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00036 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00037 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00038 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00039 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00040 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00041 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00042 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00043 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00044 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00045 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00046 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00047 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00048 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00049 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00050 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00051 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00052 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00053 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00054 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00055 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00056 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00057 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00058 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00059 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00060 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00061 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00062 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00063 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00064 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00065 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00066 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00067 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00068 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00069 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00070 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00071 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00072 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00073 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00074 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00075 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00076 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00077 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00078 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00079 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00080 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00081 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00082 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00083 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00084 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00085 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00086 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00087 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00088 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00089 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00090 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00091 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00092 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00093 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00094 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00095 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00096 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00097 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00098 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "Epoch 00099 | Train AUC: 0.5196 | Train Loss: 0.4121 | Validation AUC: 0.5111 | Validation loss: 0.4097\n",
      "==== Test Phase ====\n",
      "test auc : 0.5366944121753403\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kudo/.pyenv/versions/3.5.2/lib/python3.5/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/kudo/.pyenv/versions/3.5.2/lib/python3.5/site-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([639,  54]))\n",
      "Start 7-th fold\n",
      "==== Train Phase ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kudo/.pyenv/versions/3.5.2/lib/python3.5/site-packages/dgl/frame.py:204: UserWarning: Initializer is not set. Use zero initializer instead. To suppress this warning, use `set_initializer` to explicitly specify which initializer to use.\n",
      "  dgl_warning('Initializer is not set. Use zero initializer instead.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000 | Train AUC: 0.5231 | Train Loss: 0.3912 | Validation AUC: 0.5103 | Validation loss: 0.4110\n",
      "Epoch 00001 | Train AUC: 0.5224 | Train Loss: 0.3912 | Validation AUC: 0.5103 | Validation loss: 0.4110\n",
      "Epoch 00002 | Train AUC: 0.5300 | Train Loss: 0.3912 | Validation AUC: 0.5087 | Validation loss: 0.4110\n",
      "Epoch 00003 | Train AUC: 0.5286 | Train Loss: 0.3912 | Validation AUC: 0.5386 | Validation loss: 0.4110\n",
      "Epoch 00004 | Train AUC: 0.6672 | Train Loss: 0.3754 | Validation AUC: 0.7047 | Validation loss: 0.3786\n",
      "Epoch 00005 | Train AUC: 0.1338 | Train Loss: 1.2512 | Validation AUC: 0.1501 | Validation loss: 1.2574\n",
      "Epoch 00006 | Train AUC: 0.5238 | Train Loss: 0.3945 | Validation AUC: 0.5087 | Validation loss: 0.4120\n",
      "Epoch 00007 | Train AUC: 0.5308 | Train Loss: 0.3912 | Validation AUC: 0.5103 | Validation loss: 0.4110\n",
      "Epoch 00008 | Train AUC: 0.5316 | Train Loss: 0.3912 | Validation AUC: 0.5253 | Validation loss: 0.4110\n",
      "Epoch 00009 | Train AUC: 0.5316 | Train Loss: 0.3912 | Validation AUC: 0.5253 | Validation loss: 0.4110\n",
      "Epoch 00010 | Train AUC: 0.5323 | Train Loss: 0.3912 | Validation AUC: 0.5253 | Validation loss: 0.4110\n",
      "Epoch 00011 | Train AUC: 0.5323 | Train Loss: 0.3912 | Validation AUC: 0.5103 | Validation loss: 0.4110\n",
      "Epoch 00012 | Train AUC: 0.5323 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00013 | Train AUC: 0.5331 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00014 | Train AUC: 0.5331 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00015 | Train AUC: 0.5331 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00016 | Train AUC: 0.5331 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00017 | Train AUC: 0.5331 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00018 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00019 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00020 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00021 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00022 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00023 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00024 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00025 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00026 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00027 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00028 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00029 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00030 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00031 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00032 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00033 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00034 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00035 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00036 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00037 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00038 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00039 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00040 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00041 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00042 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00043 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00044 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00045 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00046 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00047 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00048 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00049 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00050 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00051 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00052 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00053 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00054 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00055 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00056 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00057 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00058 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00059 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00060 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00061 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00062 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00063 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00064 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00065 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00066 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00067 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00068 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00069 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00070 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00071 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00072 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00073 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00074 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00075 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00076 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00077 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00078 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00079 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00080 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00081 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00082 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00083 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00084 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00085 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00086 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00087 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00088 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00089 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00090 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00091 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00092 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00093 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00094 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00095 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00096 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00097 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00098 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "Epoch 00099 | Train AUC: 0.5239 | Train Loss: 0.3912 | Validation AUC: 0.5119 | Validation loss: 0.4110\n",
      "==== Test Phase ====\n",
      "test auc : 0.09160813820886933\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kudo/.pyenv/versions/3.5.2/lib/python3.5/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/kudo/.pyenv/versions/3.5.2/lib/python3.5/site-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/kudo/.pyenv/versions/3.5.2/lib/python3.5/site-packages/dgl/frame.py:204: UserWarning: Initializer is not set. Use zero initializer instead. To suppress this warning, use `set_initializer` to explicitly specify which initializer to use.\n",
      "  dgl_warning('Initializer is not set. Use zero initializer instead.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([647,  53]))\n",
      "Start 8-th fold\n",
      "==== Train Phase ====\n",
      "Epoch 00000 | Train AUC: 0.1133 | Train Loss: 1.2576 | Validation AUC: 0.0991 | Validation loss: 1.2715\n",
      "Epoch 00001 | Train AUC: 0.5292 | Train Loss: 0.3907 | Validation AUC: 0.5114 | Validation loss: 0.3925\n",
      "Epoch 00002 | Train AUC: 0.5299 | Train Loss: 0.3907 | Validation AUC: 0.5114 | Validation loss: 0.3926\n",
      "Epoch 00003 | Train AUC: 0.5207 | Train Loss: 0.3907 | Validation AUC: 0.5114 | Validation loss: 0.3926\n",
      "Epoch 00004 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5114 | Validation loss: 0.3926\n",
      "Epoch 00005 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5114 | Validation loss: 0.3926\n",
      "Epoch 00006 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5114 | Validation loss: 0.3926\n",
      "Epoch 00007 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00008 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00009 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00010 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00011 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00012 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00013 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00014 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00015 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00016 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00017 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00018 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00019 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00020 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00021 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00022 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00023 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00024 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00025 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00026 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00027 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00028 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00029 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00030 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00031 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00032 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00033 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00034 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00035 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00036 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00037 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00038 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00039 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00040 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00041 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00042 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00043 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00044 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00045 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00046 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00047 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00048 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00049 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00050 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00051 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00052 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00053 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00054 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00055 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00056 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00057 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00058 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00059 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00060 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00061 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00062 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00063 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00064 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00065 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00066 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00067 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00068 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00069 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00070 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00071 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00072 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00073 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00074 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00075 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00076 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00077 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00078 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00079 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00080 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00081 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00082 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00083 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00084 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00085 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00086 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00087 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00088 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00089 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00090 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00091 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00092 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00093 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00094 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00095 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00096 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00097 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00098 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "Epoch 00099 | Train AUC: 0.5214 | Train Loss: 0.3907 | Validation AUC: 0.5128 | Validation loss: 0.3926\n",
      "==== Test Phase ====\n",
      "test auc : 0.5333585565230367\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kudo/.pyenv/versions/3.5.2/lib/python3.5/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/kudo/.pyenv/versions/3.5.2/lib/python3.5/site-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/kudo/.pyenv/versions/3.5.2/lib/python3.5/site-packages/dgl/frame.py:204: UserWarning: Initializer is not set. Use zero initializer instead. To suppress this warning, use `set_initializer` to explicitly specify which initializer to use.\n",
      "  dgl_warning('Initializer is not set. Use zero initializer instead.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([666,  57]))\n",
      "Start 9-th fold\n",
      "==== Train Phase ====\n",
      "Epoch 00000 | Train AUC: 0.5249 | Train Loss: 0.3927 | Validation AUC: 0.4937 | Validation loss: 0.3784\n",
      "Epoch 00001 | Train AUC: 0.5291 | Train Loss: 0.3924 | Validation AUC: 0.4953 | Validation loss: 0.3783\n",
      "Epoch 00002 | Train AUC: 0.5291 | Train Loss: 0.3924 | Validation AUC: 0.4953 | Validation loss: 0.3782\n",
      "Epoch 00003 | Train AUC: 0.5291 | Train Loss: 0.3923 | Validation AUC: 0.4953 | Validation loss: 0.3781\n",
      "Epoch 00004 | Train AUC: 0.5291 | Train Loss: 0.3923 | Validation AUC: 0.4953 | Validation loss: 0.3780\n",
      "Epoch 00005 | Train AUC: 0.5291 | Train Loss: 0.3923 | Validation AUC: 0.4953 | Validation loss: 0.3779\n",
      "Epoch 00006 | Train AUC: 0.5291 | Train Loss: 0.3923 | Validation AUC: 0.4953 | Validation loss: 0.3779\n",
      "Epoch 00007 | Train AUC: 0.5291 | Train Loss: 0.3923 | Validation AUC: 0.4953 | Validation loss: 0.3778\n",
      "Epoch 00008 | Train AUC: 0.5291 | Train Loss: 0.3923 | Validation AUC: 0.4953 | Validation loss: 0.3778\n",
      "Epoch 00009 | Train AUC: 0.5291 | Train Loss: 0.3923 | Validation AUC: 0.4953 | Validation loss: 0.3777\n",
      "Epoch 00010 | Train AUC: 0.5291 | Train Loss: 0.3923 | Validation AUC: 0.4953 | Validation loss: 0.3777\n",
      "Epoch 00011 | Train AUC: 0.5291 | Train Loss: 0.3923 | Validation AUC: 0.4953 | Validation loss: 0.3777\n",
      "Epoch 00012 | Train AUC: 0.5291 | Train Loss: 0.3923 | Validation AUC: 0.4953 | Validation loss: 0.3776\n",
      "Epoch 00013 | Train AUC: 0.5291 | Train Loss: 0.3923 | Validation AUC: 0.4953 | Validation loss: 0.3776\n",
      "Epoch 00014 | Train AUC: 0.5291 | Train Loss: 0.3923 | Validation AUC: 0.4953 | Validation loss: 0.3776\n",
      "Epoch 00015 | Train AUC: 0.5291 | Train Loss: 0.3923 | Validation AUC: 0.4953 | Validation loss: 0.3776\n",
      "Epoch 00016 | Train AUC: 0.5378 | Train Loss: 0.3923 | Validation AUC: 0.4953 | Validation loss: 0.3776\n",
      "Epoch 00017 | Train AUC: 0.5378 | Train Loss: 0.3923 | Validation AUC: 0.4953 | Validation loss: 0.3776\n",
      "Epoch 00018 | Train AUC: 0.5378 | Train Loss: 0.3923 | Validation AUC: 0.4953 | Validation loss: 0.3776\n",
      "Epoch 00019 | Train AUC: 0.5378 | Train Loss: 0.3923 | Validation AUC: 0.5189 | Validation loss: 0.3776\n",
      "Epoch 00020 | Train AUC: 0.5552 | Train Loss: 0.3923 | Validation AUC: 0.5189 | Validation loss: 0.3776\n",
      "Epoch 00021 | Train AUC: 0.7140 | Train Loss: 0.3661 | Validation AUC: 0.6395 | Validation loss: 0.3599\n",
      "Epoch 00022 | Train AUC: 0.7216 | Train Loss: 0.3661 | Validation AUC: 0.6395 | Validation loss: 0.3599\n",
      "Epoch 00023 | Train AUC: 0.7394 | Train Loss: 0.3633 | Validation AUC: 0.6395 | Validation loss: 0.3599\n",
      "Epoch 00024 | Train AUC: 0.7390 | Train Loss: 0.3647 | Validation AUC: 0.6395 | Validation loss: 0.3599\n",
      "Epoch 00025 | Train AUC: 0.7390 | Train Loss: 0.3647 | Validation AUC: 0.6395 | Validation loss: 0.3599\n",
      "Epoch 00026 | Train AUC: 0.7390 | Train Loss: 0.3647 | Validation AUC: 0.6379 | Validation loss: 0.3628\n",
      "Epoch 00027 | Train AUC: 0.7390 | Train Loss: 0.3647 | Validation AUC: 0.6379 | Validation loss: 0.3628\n",
      "Epoch 00028 | Train AUC: 0.7390 | Train Loss: 0.3647 | Validation AUC: 0.6379 | Validation loss: 0.3628\n",
      "Epoch 00029 | Train AUC: 0.7390 | Train Loss: 0.3647 | Validation AUC: 0.6379 | Validation loss: 0.3628\n",
      "Epoch 00030 | Train AUC: 0.7382 | Train Loss: 0.3661 | Validation AUC: 0.6379 | Validation loss: 0.3628\n",
      "Epoch 00031 | Train AUC: 0.7382 | Train Loss: 0.3661 | Validation AUC: 0.6620 | Validation loss: 0.3599\n",
      "Epoch 00032 | Train AUC: 0.7374 | Train Loss: 0.3675 | Validation AUC: 0.6620 | Validation loss: 0.3599\n",
      "Epoch 00033 | Train AUC: 0.7374 | Train Loss: 0.3675 | Validation AUC: 0.6620 | Validation loss: 0.3599\n",
      "Epoch 00034 | Train AUC: 0.7374 | Train Loss: 0.3675 | Validation AUC: 0.6620 | Validation loss: 0.3599\n",
      "Epoch 00035 | Train AUC: 0.7374 | Train Loss: 0.3675 | Validation AUC: 0.6620 | Validation loss: 0.3599\n",
      "Epoch 00036 | Train AUC: 0.7374 | Train Loss: 0.3675 | Validation AUC: 0.6620 | Validation loss: 0.3599\n",
      "Epoch 00037 | Train AUC: 0.7462 | Train Loss: 0.3661 | Validation AUC: 0.6620 | Validation loss: 0.3599\n",
      "Epoch 00038 | Train AUC: 0.7462 | Train Loss: 0.3661 | Validation AUC: 0.6620 | Validation loss: 0.3599\n",
      "Epoch 00039 | Train AUC: 0.7462 | Train Loss: 0.3661 | Validation AUC: 0.6620 | Validation loss: 0.3599\n",
      "Epoch 00040 | Train AUC: 0.7462 | Train Loss: 0.3661 | Validation AUC: 0.6620 | Validation loss: 0.3599\n",
      "Epoch 00041 | Train AUC: 0.7462 | Train Loss: 0.3661 | Validation AUC: 0.6620 | Validation loss: 0.3599\n",
      "Epoch 00042 | Train AUC: 0.7462 | Train Loss: 0.3661 | Validation AUC: 0.6620 | Validation loss: 0.3600\n",
      "Epoch 00043 | Train AUC: 0.7462 | Train Loss: 0.3661 | Validation AUC: 0.6620 | Validation loss: 0.3600\n",
      "Epoch 00044 | Train AUC: 0.7462 | Train Loss: 0.3661 | Validation AUC: 0.6620 | Validation loss: 0.3600\n",
      "Epoch 00045 | Train AUC: 0.7551 | Train Loss: 0.3647 | Validation AUC: 0.6620 | Validation loss: 0.3600\n",
      "Epoch 00046 | Train AUC: 0.7551 | Train Loss: 0.3647 | Validation AUC: 0.6860 | Validation loss: 0.3570\n",
      "Epoch 00047 | Train AUC: 0.7551 | Train Loss: 0.3647 | Validation AUC: 0.6860 | Validation loss: 0.3570\n",
      "Epoch 00048 | Train AUC: 0.7551 | Train Loss: 0.3647 | Validation AUC: 0.6860 | Validation loss: 0.3571\n",
      "Epoch 00049 | Train AUC: 0.7551 | Train Loss: 0.3647 | Validation AUC: 0.6860 | Validation loss: 0.3571\n",
      "Epoch 00050 | Train AUC: 0.7551 | Train Loss: 0.3647 | Validation AUC: 0.6860 | Validation loss: 0.3571\n",
      "Epoch 00051 | Train AUC: 0.7551 | Train Loss: 0.3647 | Validation AUC: 0.6860 | Validation loss: 0.3571\n",
      "Epoch 00052 | Train AUC: 0.7551 | Train Loss: 0.3647 | Validation AUC: 0.6860 | Validation loss: 0.3571\n",
      "Epoch 00053 | Train AUC: 0.7543 | Train Loss: 0.3661 | Validation AUC: 0.6860 | Validation loss: 0.3571\n",
      "Epoch 00054 | Train AUC: 0.7543 | Train Loss: 0.3661 | Validation AUC: 0.6844 | Validation loss: 0.3600\n",
      "Epoch 00055 | Train AUC: 0.7543 | Train Loss: 0.3661 | Validation AUC: 0.6844 | Validation loss: 0.3601\n",
      "Epoch 00056 | Train AUC: 0.7543 | Train Loss: 0.3661 | Validation AUC: 0.6844 | Validation loss: 0.3601\n",
      "Epoch 00057 | Train AUC: 0.7543 | Train Loss: 0.3661 | Validation AUC: 0.6844 | Validation loss: 0.3601\n",
      "Epoch 00058 | Train AUC: 0.7543 | Train Loss: 0.3661 | Validation AUC: 0.6844 | Validation loss: 0.3601\n",
      "Epoch 00059 | Train AUC: 0.7543 | Train Loss: 0.3661 | Validation AUC: 0.6844 | Validation loss: 0.3601\n",
      "Epoch 00060 | Train AUC: 0.7543 | Train Loss: 0.3661 | Validation AUC: 0.6844 | Validation loss: 0.3601\n",
      "Epoch 00061 | Train AUC: 0.7543 | Train Loss: 0.3661 | Validation AUC: 0.6844 | Validation loss: 0.3601\n",
      "Epoch 00062 | Train AUC: 0.7632 | Train Loss: 0.3647 | Validation AUC: 0.6844 | Validation loss: 0.3601\n",
      "Epoch 00063 | Train AUC: 0.7632 | Train Loss: 0.3647 | Validation AUC: 0.6844 | Validation loss: 0.3601\n",
      "Epoch 00064 | Train AUC: 0.7632 | Train Loss: 0.3647 | Validation AUC: 0.6844 | Validation loss: 0.3601\n",
      "Epoch 00065 | Train AUC: 0.7632 | Train Loss: 0.3647 | Validation AUC: 0.6844 | Validation loss: 0.3601\n",
      "Epoch 00066 | Train AUC: 0.7632 | Train Loss: 0.3647 | Validation AUC: 0.6844 | Validation loss: 0.3601\n",
      "Epoch 00067 | Train AUC: 0.7632 | Train Loss: 0.3647 | Validation AUC: 0.6844 | Validation loss: 0.3602\n",
      "Epoch 00068 | Train AUC: 0.7632 | Train Loss: 0.3647 | Validation AUC: 0.6844 | Validation loss: 0.3602\n",
      "Epoch 00069 | Train AUC: 0.7721 | Train Loss: 0.3633 | Validation AUC: 0.6844 | Validation loss: 0.3602\n",
      "Epoch 00070 | Train AUC: 0.7721 | Train Loss: 0.3633 | Validation AUC: 0.6844 | Validation loss: 0.3602\n",
      "Epoch 00071 | Train AUC: 0.7713 | Train Loss: 0.3647 | Validation AUC: 0.6844 | Validation loss: 0.3602\n",
      "Epoch 00072 | Train AUC: 0.7713 | Train Loss: 0.3647 | Validation AUC: 0.6844 | Validation loss: 0.3602\n",
      "Epoch 00073 | Train AUC: 0.7713 | Train Loss: 0.3647 | Validation AUC: 0.6844 | Validation loss: 0.3602\n",
      "Epoch 00074 | Train AUC: 0.7713 | Train Loss: 0.3647 | Validation AUC: 0.6844 | Validation loss: 0.3602\n",
      "Epoch 00075 | Train AUC: 0.7713 | Train Loss: 0.3647 | Validation AUC: 0.6844 | Validation loss: 0.3602\n",
      "Epoch 00076 | Train AUC: 0.7801 | Train Loss: 0.3633 | Validation AUC: 0.6844 | Validation loss: 0.3602\n",
      "Epoch 00077 | Train AUC: 0.7801 | Train Loss: 0.3633 | Validation AUC: 0.6844 | Validation loss: 0.3602\n",
      "Epoch 00078 | Train AUC: 0.7890 | Train Loss: 0.3619 | Validation AUC: 0.6844 | Validation loss: 0.3603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00079 | Train AUC: 0.7890 | Train Loss: 0.3619 | Validation AUC: 0.6844 | Validation loss: 0.3603\n",
      "Epoch 00080 | Train AUC: 0.7882 | Train Loss: 0.3633 | Validation AUC: 0.6844 | Validation loss: 0.3603\n",
      "Epoch 00081 | Train AUC: 0.7882 | Train Loss: 0.3633 | Validation AUC: 0.7085 | Validation loss: 0.3573\n",
      "Epoch 00082 | Train AUC: 0.7882 | Train Loss: 0.3633 | Validation AUC: 0.7085 | Validation loss: 0.3573\n",
      "Epoch 00083 | Train AUC: 0.7882 | Train Loss: 0.3633 | Validation AUC: 0.7085 | Validation loss: 0.3573\n",
      "Epoch 00084 | Train AUC: 0.7882 | Train Loss: 0.3633 | Validation AUC: 0.7085 | Validation loss: 0.3574\n",
      "Epoch 00085 | Train AUC: 0.7882 | Train Loss: 0.3633 | Validation AUC: 0.7085 | Validation loss: 0.3574\n",
      "Epoch 00086 | Train AUC: 0.7882 | Train Loss: 0.3633 | Validation AUC: 0.7085 | Validation loss: 0.3574\n",
      "Epoch 00087 | Train AUC: 0.7882 | Train Loss: 0.3633 | Validation AUC: 0.7085 | Validation loss: 0.3574\n",
      "Epoch 00088 | Train AUC: 0.7882 | Train Loss: 0.3633 | Validation AUC: 0.7085 | Validation loss: 0.3574\n",
      "Epoch 00089 | Train AUC: 0.7882 | Train Loss: 0.3633 | Validation AUC: 0.7085 | Validation loss: 0.3574\n",
      "Epoch 00090 | Train AUC: 0.7882 | Train Loss: 0.3633 | Validation AUC: 0.7085 | Validation loss: 0.3574\n",
      "Epoch 00091 | Train AUC: 0.7882 | Train Loss: 0.3633 | Validation AUC: 0.7085 | Validation loss: 0.3574\n",
      "Epoch 00092 | Train AUC: 0.7882 | Train Loss: 0.3633 | Validation AUC: 0.7085 | Validation loss: 0.3574\n",
      "Epoch 00093 | Train AUC: 0.7882 | Train Loss: 0.3633 | Validation AUC: 0.7085 | Validation loss: 0.3574\n",
      "Epoch 00094 | Train AUC: 0.7882 | Train Loss: 0.3633 | Validation AUC: 0.7085 | Validation loss: 0.3574\n",
      "Epoch 00095 | Train AUC: 0.7882 | Train Loss: 0.3633 | Validation AUC: 0.7085 | Validation loss: 0.3574\n",
      "Epoch 00096 | Train AUC: 0.7882 | Train Loss: 0.3633 | Validation AUC: 0.7325 | Validation loss: 0.3545\n",
      "Epoch 00097 | Train AUC: 0.7882 | Train Loss: 0.3633 | Validation AUC: 0.7325 | Validation loss: 0.3545\n",
      "Epoch 00098 | Train AUC: 0.7882 | Train Loss: 0.3633 | Validation AUC: 0.7325 | Validation loss: 0.3545\n",
      "Epoch 00099 | Train AUC: 0.7882 | Train Loss: 0.3633 | Validation AUC: 0.7325 | Validation loss: 0.3545\n",
      "==== Test Phase ====\n",
      "test auc : 0.7880932334352919\n",
      "=================\n"
     ]
    }
   ],
   "source": [
    "auc_scores = []\n",
    "\n",
    "for i, (for_train_val_idx, for_test_idx) in enumerate(kf.split(np.arange(len(all_idx)),y=known_labels)):\n",
    "    # 元々のグラフにおけるインデックス\n",
    "    train_val_idx = all_idx[for_train_val_idx]\n",
    "    train_idx, val_idx = train_test_split(train_val_idx,test_size=0.33,stratify=known_labels[for_train_val_idx])\n",
    "    test_idx = all_idx[for_test_idx]\n",
    "    \n",
    "    # making subgrap\n",
    "    sub_network_df , sub_gt_df, subGraph_map_encoder =  subgraph_making(merged_network,epinions_gt_padded,num_nodes,20000,\n",
    "                                                                        train_val_idx)\n",
    "#     sub_network_df , sub_gt_df, subGraph_map_encoder =  subgraph_making_from_edges(merged_network,epinions_gt_padded,num_nodes,20000,\n",
    "#                                                                         np.random.choice(train_val_idx,10),'first_second')\n",
    "\n",
    "    sub_num_nodes = subGraph_map_encoder.classes_.shape[0]\n",
    "    sub_num_rels = num_rels\n",
    "    sub_node_feature_array =  node_feature_array[subGraph_map_encoder.classes_]\n",
    "    sub_edge_type = torch.from_numpy(sub_network_df['etype'].values)\n",
    "    sub_edge_norm = torch.from_numpy(sub_network_df['norm'].values.astype('float32')).unsqueeze(1)\n",
    "\n",
    "    # サブグラフ上のtrainとvalのインデックス\n",
    "    sub_train_idx = subGraph_map_encoder.transform([idx for idx in train_idx if idx in subGraph_map_encoder.classes_])\n",
    "    sub_val_idx = subGraph_map_encoder.transform([idx for idx in val_idx if idx in subGraph_map_encoder.classes_])\n",
    "    # create graph\n",
    "    subg = DGLGraph()\n",
    "    subg.add_nodes(sub_num_nodes)\n",
    "    subg.add_edges(sub_network_df['src'].values, sub_network_df['dst'].values)\n",
    "    subg.edata.update({'rel_type': sub_edge_type, 'norm': sub_edge_norm})\n",
    "    print(\"{}\".format(np.unique(labels[subGraph_map_encoder.inverse_transform(sub_train_idx)].numpy(),return_counts=True)))\n",
    "    # create model\n",
    "    model = Model(len(subg),\n",
    "                  n_hidden,\n",
    "                  num_classes,\n",
    "                  sub_num_rels,\n",
    "                  sub_node_feature_array,\n",
    "                  num_bases=n_bases,\n",
    "                  num_hidden_layers=n_hidden_layers)\n",
    "    # optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=l2norm)\n",
    "    print(\"Start {}-th fold\".format(i))\n",
    "    print(\"==== Train Phase ====\")\n",
    "    model.train()\n",
    "    best_auc = 0.0\n",
    "    best_model = None\n",
    "    for epoch in range(n_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        logits = model.forward(subg)\n",
    "        loss = F.cross_entropy(logits[sub_train_idx], labels[subGraph_map_encoder.inverse_transform(sub_train_idx)])\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        train_auc = roc_auc_score(y_true=labels[subGraph_map_encoder.inverse_transform(sub_train_idx)].detach().numpy(),\n",
    "                                  y_score=logits[sub_train_idx].detach().numpy()[:,1])\n",
    "        train_loss = F.cross_entropy(logits[sub_train_idx], labels[subGraph_map_encoder.inverse_transform(sub_train_idx)])\n",
    "        val_auc = roc_auc_score(y_true=labels[subGraph_map_encoder.inverse_transform(sub_val_idx)].detach().numpy(),\n",
    "                                y_score=logits[sub_val_idx].detach().numpy()[:,1])\n",
    "        val_loss = F.cross_entropy(logits[sub_val_idx], labels[subGraph_map_encoder.inverse_transform(sub_val_idx)])\n",
    "        \n",
    "        if val_auc >= best_auc:\n",
    "            best_auc = val_auc\n",
    "            best_model = cp.deepcopy(model)\n",
    "            \n",
    "        print(\"Epoch {:05d} | \".format(epoch) +\n",
    "              \"Train AUC: {:.4f} | Train Loss: {:.4f} | \".format(\n",
    "                  train_auc, loss.item()) +\n",
    "              \"Validation AUC: {:.4f} | Validation loss: {:.4f}\".format(\n",
    "                  val_auc, val_loss.item()))\n",
    "    del logits\n",
    "    print(\"==== Test Phase ====\")\n",
    "    best_model.eval()\n",
    "    best_model.features = torch.from_numpy(node_feature_array)\n",
    "    all_logits = best_model.forward(g)\n",
    "    test_auc = roc_auc_score(y_true=labels[test_idx].detach().numpy(),y_score=all_logits[test_idx].detach().numpy()[:,1])\n",
    "    auc_scores.append(test_auc)\n",
    "    print(\"test auc : {}\".format(test_auc))\n",
    "    del best_model\n",
    "    del all_logits\n",
    "    print(\"=================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5996410233578654"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(auc_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_varsize():\n",
    "    import types\n",
    "    print(\"{}{: >15}{}{: >10}{}\".format('|','Variable Name','|','  Size','|'))\n",
    "    print(\" -------------------------- \")\n",
    "    for k, v in globals().items():\n",
    "        if hasattr(v, 'size') and not k.startswith('_') and not isinstance(v,types.ModuleType):\n",
    "            print(\"{}{: >15}{}{: >10}{}\".format('|',k,'|',str(v.size),'|'))\n",
    "        elif hasattr(v, '__len__') and not k.startswith('_') and not isinstance(v,types.ModuleType):\n",
    "            try:\n",
    "                print(\"{}{: >15}{}{: >10}{}\".format('|',k,'|',str(len(v)),'|'))\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_varsize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
