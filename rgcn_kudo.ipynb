{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl import DGLGraph\n",
    "import dgl.function as fn\n",
    "from functools import partial\n",
    "\n",
    "class RGCNLayer(nn.Module):\n",
    "    def __init__(self, in_feat, out_feat, num_rels, num_bases=-1, bias=None,\n",
    "                 activation=None, is_input_layer=False):\n",
    "        super(RGCNLayer, self).__init__()\n",
    "        self.in_feat = in_feat\n",
    "        self.out_feat = out_feat\n",
    "        self.num_rels = num_rels\n",
    "        self.num_bases = num_bases\n",
    "        self.bias = bias\n",
    "        self.activation = activation\n",
    "        self.is_input_layer = is_input_layer\n",
    "\n",
    "        # sanity check\n",
    "        if self.num_bases <= 0 or self.num_bases > self.num_rels:\n",
    "            self.num_bases = self.num_rels\n",
    "\n",
    "        # weight bases in equation (3)\n",
    "        self.weight = nn.Parameter(torch.Tensor(self.num_bases, self.in_feat,\n",
    "                                                self.out_feat))\n",
    "        if self.num_bases < self.num_rels:\n",
    "            # linear combination coefficients in equation (3)\n",
    "            self.w_comp = nn.Parameter(torch.Tensor(self.num_rels, self.num_bases))\n",
    "\n",
    "        # add bias\n",
    "        if self.bias:\n",
    "            self.bias = nn.Parameter(torch.Tensor(out_feat))\n",
    "\n",
    "        # init trainable parameters\n",
    "        nn.init.xavier_uniform_(self.weight,\n",
    "                                gain=nn.init.calculate_gain('relu'))\n",
    "        if self.num_bases < self.num_rels:\n",
    "            nn.init.xavier_uniform_(self.w_comp,\n",
    "                                    gain=nn.init.calculate_gain('relu'))\n",
    "        if self.bias:\n",
    "            nn.init.xavier_uniform_(self.bias,\n",
    "                                    gain=nn.init.calculate_gain('relu'))\n",
    "\n",
    "    def forward(self, g):\n",
    "        if self.num_bases < self.num_rels:\n",
    "            # generate all weights from bases (equation (3))\n",
    "            weight = self.weight.view(self.in_feat, self.num_bases, self.out_feat)\n",
    "            weight = torch.matmul(self.w_comp, weight).view(self.num_rels,\n",
    "                                                        self.in_feat, self.out_feat)\n",
    "        else:\n",
    "            weight = self.weight\n",
    "\n",
    "        if self.is_input_layer:\n",
    "            def message_func(edges):\n",
    "                # for input layer, matrix multiply can be converted to be\n",
    "                # an embedding lookup using source node id\n",
    "                # embed = weight.view(-1, self.out_feat)\n",
    "                # index = edges.data['rel_type'] * self.in_feat + edges.src['id']\n",
    "                # index = edges.data['rel_type'] * self.in_feat + edges.src['id']\n",
    "                # return {'msg': embed[index] * edges.data['norm']}\n",
    "                w = weight[edges.data['rel_type']]\n",
    "                msg = torch.bmm(edges.src['init_h'].unsqueeze(1), w).squeeze()\n",
    "                msg = msg * edges.data['norm']\n",
    "                return {'msg': msg}                \n",
    "        else:\n",
    "            def message_func(edges):\n",
    "                w = weight[edges.data['rel_type']]\n",
    "                msg = torch.bmm(edges.src['h'].unsqueeze(1), w).squeeze()\n",
    "                msg = msg * edges.data['norm']\n",
    "                return {'msg': msg}\n",
    "\n",
    "        def apply_func(nodes):\n",
    "            h = nodes.data['h']\n",
    "            if self.bias:\n",
    "                h = h + self.bias\n",
    "            if self.activation:\n",
    "                h = self.activation(h)\n",
    "            return {'h': h}\n",
    "\n",
    "        g.update_all(message_func, fn.sum(msg='msg', out='h'), apply_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define full R-GCN model\n",
    "~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, num_nodes, h_dim, out_dim, num_rels,node_feature_array,\n",
    "                 num_bases=-1, num_hidden_layers=1):\n",
    "        super(Model, self).__init__()\n",
    "        self.num_nodes = num_nodes\n",
    "        self.h_dim = h_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.num_rels = num_rels\n",
    "        self.node_feature_array = node_feature_array\n",
    "        self.num_bases = num_bases\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        \n",
    "\n",
    "        # create rgcn layers\n",
    "        self.build_model()\n",
    "\n",
    "        # create initial features\n",
    "        self.features = self.create_features()\n",
    "\n",
    "    def build_model(self):\n",
    "        self.layers = nn.ModuleList()\n",
    "        # input to hidden\n",
    "        i2h = self.build_input_layer()\n",
    "        self.layers.append(i2h)\n",
    "        # hidden to hidden\n",
    "        for idx in range(self.num_hidden_layers - 1):\n",
    "            h2h = self.build_hidden_layer(idx)\n",
    "            self.layers.append(h2h)\n",
    "        # hidden to output\n",
    "        h2o = self.build_output_layer()\n",
    "        self.layers.append(h2o)\n",
    "\n",
    "    # initialize feature for each node\n",
    "    def create_features(self):\n",
    "        # features = torch.arange(self.num_nodes)\n",
    "        features = torch.from_numpy(self.node_feature_array)\n",
    "        return features\n",
    "\n",
    "    def build_input_layer(self):\n",
    "        return RGCNLayer(self.node_feature_array.shape[1], self.h_dim[0], self.num_rels, self.num_bases,\n",
    "                         activation=F.relu, is_input_layer=True)\n",
    "\n",
    "    def build_hidden_layer(self,idx):\n",
    "        return RGCNLayer(self.h_dim[idx], self.h_dim[idx+1], self.num_rels, self.num_bases,\n",
    "                         activation=F.relu)\n",
    "\n",
    "    def build_output_layer(self):\n",
    "        return RGCNLayer(self.h_dim[-1], self.out_dim, self.num_rels, self.num_bases,\n",
    "                         activation=partial(F.softmax, dim=1))\n",
    "\n",
    "    def forward(self, g):\n",
    "        if self.features is not None:\n",
    "            # g.ndata['id'] = self.features\n",
    "            g.ndata['init_h'] = self.features\n",
    "        for layer in self.layers:\n",
    "            layer(g)\n",
    "        return g.ndata.pop('h')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handle dataset\n",
    "~~~~~~~~~~~~~~~~\n",
    "In this tutorial, we use AIFB dataset from R-GCN paper:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dist(df,col):\n",
    "    df_cnt = df.groupby([col]+['etype'])['time'].count().unstack(1,fill_value=0)\n",
    "    df_dist = pd.DataFrame(df_cnt.values / df_cnt.sum(1).values.reshape(-1,1),\n",
    "                                               columns=df_cnt.columns,\n",
    "                                               index=df_cnt.index)\n",
    "    return df_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "alpha_network = pd.read_csv('raw_data/alpha/alpha_network.csv',header=None)\n",
    "alpha_network.columns = ['src_raw','dst_raw','etype','time']\n",
    "etype_encoder = LabelEncoder()\n",
    "alpha_network['etype'] = etype_encoder.fit_transform(alpha_network.etype)\n",
    "alpha_gt = pd.read_csv('raw_data/alpha/alpha_gt.csv',header=None)\n",
    "alpha_gt.columns = ['node_id_raw','label']\n",
    "alpha_gt = alpha_gt.drop_duplicates('node_id_raw')\n",
    "\n",
    "# edge_normの計算\n",
    "alpha_src_cnt = alpha_network.groupby(['src_raw','etype'])['time'].count().unstack(1,fill_value=0)\n",
    "\n",
    "alpha_src_dist = pd.DataFrame(alpha_src_cnt.values/alpha_src_cnt.sum(1).values.reshape(-1,1),\n",
    "                                                        index=alpha_src_cnt.index,\n",
    "                                                        columns=alpha_src_cnt.columns)\n",
    "\n",
    "merged_network = pd.merge(alpha_network,alpha_src_dist.stack().reset_index(),on=['src_raw','etype'])\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(np.hstack((merged_network.src_raw,\n",
    "                                                   merged_network.dst_raw,\n",
    "                                                   alpha_gt.node_id_raw)))\n",
    "\n",
    "merged_network['src'] = label_encoder.transform(merged_network.src_raw)\n",
    "\n",
    "merged_network['dst'] = label_encoder.transform(merged_network.dst_raw)\n",
    "\n",
    "alpha_gt['node_id'] = label_encoder.transform(alpha_gt.node_id_raw)\n",
    "alpha_gt['label'] = alpha_gt['label'].map(lambda x:1 if x==-1 else 0)\n",
    "\n",
    "# padding\n",
    "alpha_gt_padded = pd.merge(pd.DataFrame(np.arange(label_encoder.classes_.shape[0])),alpha_gt,\n",
    "                                      left_index=True,right_on='node_id',how='left').fillna(0.5).sort_values('node_id')\n",
    "\n",
    "num_nodes = label_encoder.classes_.shape[0]\n",
    "num_rels = merged_network.etype.unique().shape[0]\n",
    "num_classes = alpha_gt.label.unique().shape[0]\n",
    "labels = alpha_gt_padded['label'].values.astype(int).reshape(-1,1)\n",
    "all_idx = alpha_gt['node_id'].values\n",
    "\n",
    "# edge type and normalization factor\n",
    "edge_type = torch.from_numpy(merged_network['etype'].values)\n",
    "edge_norm = torch.from_numpy(merged_network[0].values.astype('float32')).unsqueeze(1)\n",
    "\n",
    "labels = torch.from_numpy(labels).view(-1)\n",
    "\n",
    "node_feature_df = pd.concat([get_dist(merged_network,'src'),get_dist(merged_network,'dst')],1).fillna(0).sort_index()\n",
    "node_feature_array = node_feature_df.values.astype('float32')\n",
    "\n",
    "known_labels = alpha_gt['label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create graph and model\n",
    "~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configurations\n",
    "n_hidden = [32,16] # number of hidden units\n",
    "n_bases = -1 # -1 # use number of relations as number of bases\n",
    "n_hidden_layers = 2 # use 1 input layer, 1 output layer, no hidden layer\n",
    "n_epochs = 300 # epochs to train\n",
    "lr = 0.01 # learning rate\n",
    "l2norm = 0.0001 # L2 norm coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start 0-th fold\n",
      "==== Train Phase ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/dgl/frame.py:204: UserWarning: Initializer is not set. Use zero initializer instead. To suppress this warning, use `set_initializer` to explicitly specify which initializer to use.\n",
      "  dgl_warning('Initializer is not set. Use zero initializer instead.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000 | Train AUC: 0.2319 | Train Loss: 0.8954 | Validation AUC: 0.2842 | Validation loss: 0.8627\n",
      "Epoch 00001 | Train AUC: 0.8344 | Train Loss: 0.5357 | Validation AUC: 0.8475 | Validation loss: 0.5171\n",
      "Epoch 00002 | Train AUC: 0.6549 | Train Loss: 0.6968 | Validation AUC: 0.7583 | Validation loss: 0.6112\n",
      "Epoch 00003 | Train AUC: 0.8555 | Train Loss: 0.5260 | Validation AUC: 0.8633 | Validation loss: 0.4876\n",
      "Epoch 00004 | Train AUC: 0.8503 | Train Loss: 0.5326 | Validation AUC: 0.8658 | Validation loss: 0.4876\n",
      "Epoch 00005 | Train AUC: 0.8438 | Train Loss: 0.5282 | Validation AUC: 0.8538 | Validation loss: 0.5028\n",
      "Epoch 00006 | Train AUC: 0.8403 | Train Loss: 0.5275 | Validation AUC: 0.8400 | Validation loss: 0.5181\n",
      "Epoch 00007 | Train AUC: 0.8380 | Train Loss: 0.5280 | Validation AUC: 0.8375 | Validation loss: 0.5237\n",
      "Epoch 00008 | Train AUC: 0.8355 | Train Loss: 0.5270 | Validation AUC: 0.8383 | Validation loss: 0.5254\n",
      "Epoch 00009 | Train AUC: 0.8284 | Train Loss: 0.5241 | Validation AUC: 0.8400 | Validation loss: 0.5235\n",
      "Epoch 00010 | Train AUC: 0.8310 | Train Loss: 0.5207 | Validation AUC: 0.8450 | Validation loss: 0.5184\n",
      "Epoch 00011 | Train AUC: 0.8289 | Train Loss: 0.5153 | Validation AUC: 0.8542 | Validation loss: 0.5097\n",
      "Epoch 00012 | Train AUC: 0.8315 | Train Loss: 0.5119 | Validation AUC: 0.8487 | Validation loss: 0.4988\n",
      "Epoch 00013 | Train AUC: 0.8403 | Train Loss: 0.5099 | Validation AUC: 0.8550 | Validation loss: 0.4881\n",
      "Epoch 00014 | Train AUC: 0.8415 | Train Loss: 0.5075 | Validation AUC: 0.8604 | Validation loss: 0.4801\n",
      "Epoch 00015 | Train AUC: 0.8434 | Train Loss: 0.5035 | Validation AUC: 0.8733 | Validation loss: 0.4762\n",
      "Epoch 00016 | Train AUC: 0.8454 | Train Loss: 0.4987 | Validation AUC: 0.8767 | Validation loss: 0.4739\n",
      "Epoch 00017 | Train AUC: 0.8482 | Train Loss: 0.4903 | Validation AUC: 0.8800 | Validation loss: 0.4679\n",
      "Epoch 00018 | Train AUC: 0.8504 | Train Loss: 0.4866 | Validation AUC: 0.8825 | Validation loss: 0.4571\n",
      "Epoch 00019 | Train AUC: 0.8630 | Train Loss: 0.4840 | Validation AUC: 0.8875 | Validation loss: 0.4511\n",
      "Epoch 00020 | Train AUC: 0.8732 | Train Loss: 0.4786 | Validation AUC: 0.8900 | Validation loss: 0.4402\n",
      "Epoch 00021 | Train AUC: 0.8812 | Train Loss: 0.4683 | Validation AUC: 0.8908 | Validation loss: 0.4277\n",
      "Epoch 00022 | Train AUC: 0.8893 | Train Loss: 0.4491 | Validation AUC: 0.8908 | Validation loss: 0.4271\n",
      "Epoch 00023 | Train AUC: 0.8952 | Train Loss: 0.4317 | Validation AUC: 0.8917 | Validation loss: 0.4269\n",
      "Epoch 00024 | Train AUC: 0.9031 | Train Loss: 0.4279 | Validation AUC: 0.8996 | Validation loss: 0.4272\n",
      "Epoch 00025 | Train AUC: 0.9055 | Train Loss: 0.4221 | Validation AUC: 0.9079 | Validation loss: 0.4307\n",
      "Epoch 00026 | Train AUC: 0.9136 | Train Loss: 0.4196 | Validation AUC: 0.9200 | Validation loss: 0.4342\n",
      "Epoch 00027 | Train AUC: 0.9174 | Train Loss: 0.4108 | Validation AUC: 0.9350 | Validation loss: 0.4035\n",
      "Epoch 00028 | Train AUC: 0.9194 | Train Loss: 0.4057 | Validation AUC: 0.9404 | Validation loss: 0.3961\n",
      "Epoch 00029 | Train AUC: 0.9272 | Train Loss: 0.3991 | Validation AUC: 0.9488 | Validation loss: 0.3971\n",
      "Epoch 00030 | Train AUC: 0.9287 | Train Loss: 0.3993 | Validation AUC: 0.9533 | Validation loss: 0.3905\n",
      "Epoch 00031 | Train AUC: 0.9294 | Train Loss: 0.3972 | Validation AUC: 0.9458 | Validation loss: 0.3850\n",
      "Epoch 00032 | Train AUC: 0.9247 | Train Loss: 0.4047 | Validation AUC: 0.9433 | Validation loss: 0.3927\n",
      "Epoch 00033 | Train AUC: 0.9199 | Train Loss: 0.4069 | Validation AUC: 0.9383 | Validation loss: 0.3957\n",
      "Epoch 00034 | Train AUC: 0.9259 | Train Loss: 0.4045 | Validation AUC: 0.9392 | Validation loss: 0.3953\n",
      "Epoch 00035 | Train AUC: 0.9273 | Train Loss: 0.4005 | Validation AUC: 0.9442 | Validation loss: 0.3938\n",
      "Epoch 00036 | Train AUC: 0.9334 | Train Loss: 0.3926 | Validation AUC: 0.9533 | Validation loss: 0.3814\n",
      "Epoch 00037 | Train AUC: 0.9347 | Train Loss: 0.3852 | Validation AUC: 0.9571 | Validation loss: 0.3705\n",
      "Epoch 00038 | Train AUC: 0.9373 | Train Loss: 0.3900 | Validation AUC: 0.9708 | Validation loss: 0.3552\n",
      "Epoch 00039 | Train AUC: 0.9385 | Train Loss: 0.3911 | Validation AUC: 0.9708 | Validation loss: 0.3522\n",
      "Epoch 00040 | Train AUC: 0.9407 | Train Loss: 0.3911 | Validation AUC: 0.9708 | Validation loss: 0.3521\n",
      "Epoch 00041 | Train AUC: 0.9452 | Train Loss: 0.3849 | Validation AUC: 0.9704 | Validation loss: 0.3529\n",
      "Epoch 00042 | Train AUC: 0.9519 | Train Loss: 0.3944 | Validation AUC: 0.9725 | Validation loss: 0.3696\n",
      "Epoch 00043 | Train AUC: 0.9490 | Train Loss: 0.3852 | Validation AUC: 0.9696 | Validation loss: 0.3527\n",
      "Epoch 00044 | Train AUC: 0.9431 | Train Loss: 0.3873 | Validation AUC: 0.9708 | Validation loss: 0.3416\n",
      "Epoch 00045 | Train AUC: 0.9390 | Train Loss: 0.3839 | Validation AUC: 0.9721 | Validation loss: 0.3646\n",
      "Epoch 00046 | Train AUC: 0.9365 | Train Loss: 0.3901 | Validation AUC: 0.9587 | Validation loss: 0.3763\n",
      "Epoch 00047 | Train AUC: 0.9215 | Train Loss: 0.3910 | Validation AUC: 0.9529 | Validation loss: 0.3915\n",
      "Epoch 00048 | Train AUC: 0.9223 | Train Loss: 0.3912 | Validation AUC: 0.9454 | Validation loss: 0.3958\n",
      "Epoch 00049 | Train AUC: 0.9221 | Train Loss: 0.3942 | Validation AUC: 0.9433 | Validation loss: 0.4060\n",
      "Epoch 00050 | Train AUC: 0.9223 | Train Loss: 0.3919 | Validation AUC: 0.9446 | Validation loss: 0.4003\n",
      "Epoch 00051 | Train AUC: 0.9229 | Train Loss: 0.3913 | Validation AUC: 0.9454 | Validation loss: 0.3962\n",
      "Epoch 00052 | Train AUC: 0.9231 | Train Loss: 0.3910 | Validation AUC: 0.9471 | Validation loss: 0.3957\n",
      "Epoch 00053 | Train AUC: 0.9237 | Train Loss: 0.3909 | Validation AUC: 0.9513 | Validation loss: 0.3956\n",
      "Epoch 00054 | Train AUC: 0.9243 | Train Loss: 0.3909 | Validation AUC: 0.9537 | Validation loss: 0.3942\n",
      "Epoch 00055 | Train AUC: 0.9239 | Train Loss: 0.3909 | Validation AUC: 0.9537 | Validation loss: 0.3863\n",
      "Epoch 00056 | Train AUC: 0.9243 | Train Loss: 0.3908 | Validation AUC: 0.9546 | Validation loss: 0.3820\n",
      "Epoch 00057 | Train AUC: 0.9243 | Train Loss: 0.3900 | Validation AUC: 0.9579 | Validation loss: 0.3814\n",
      "Epoch 00058 | Train AUC: 0.9340 | Train Loss: 0.3838 | Validation AUC: 0.9600 | Validation loss: 0.3733\n",
      "Epoch 00059 | Train AUC: 0.9352 | Train Loss: 0.3838 | Validation AUC: 0.9625 | Validation loss: 0.3674\n",
      "Epoch 00060 | Train AUC: 0.9400 | Train Loss: 0.3838 | Validation AUC: 0.9679 | Validation loss: 0.3671\n",
      "Epoch 00061 | Train AUC: 0.9403 | Train Loss: 0.3838 | Validation AUC: 0.9738 | Validation loss: 0.3650\n",
      "Epoch 00062 | Train AUC: 0.9414 | Train Loss: 0.3838 | Validation AUC: 0.9738 | Validation loss: 0.3467\n",
      "Epoch 00063 | Train AUC: 0.9429 | Train Loss: 0.3838 | Validation AUC: 0.9738 | Validation loss: 0.3413\n",
      "Epoch 00064 | Train AUC: 0.9445 | Train Loss: 0.3838 | Validation AUC: 0.9738 | Validation loss: 0.3396\n",
      "Epoch 00065 | Train AUC: 0.9458 | Train Loss: 0.3838 | Validation AUC: 0.9738 | Validation loss: 0.3392\n",
      "Epoch 00066 | Train AUC: 0.9457 | Train Loss: 0.3838 | Validation AUC: 0.9738 | Validation loss: 0.3391\n",
      "Epoch 00067 | Train AUC: 0.9469 | Train Loss: 0.3838 | Validation AUC: 0.9738 | Validation loss: 0.3391\n",
      "Epoch 00068 | Train AUC: 0.9522 | Train Loss: 0.3837 | Validation AUC: 0.9729 | Validation loss: 0.3391\n",
      "Epoch 00069 | Train AUC: 0.9541 | Train Loss: 0.3837 | Validation AUC: 0.9729 | Validation loss: 0.3391\n",
      "Epoch 00070 | Train AUC: 0.9551 | Train Loss: 0.3836 | Validation AUC: 0.9729 | Validation loss: 0.3392\n",
      "Epoch 00071 | Train AUC: 0.9569 | Train Loss: 0.3768 | Validation AUC: 0.9729 | Validation loss: 0.3392\n",
      "Epoch 00072 | Train AUC: 0.9601 | Train Loss: 0.3717 | Validation AUC: 0.9725 | Validation loss: 0.3406\n",
      "Epoch 00073 | Train AUC: 0.9556 | Train Loss: 0.3910 | Validation AUC: 0.9654 | Validation loss: 0.3715\n",
      "Epoch 00074 | Train AUC: 0.8296 | Train Loss: 0.5425 | Validation AUC: 0.9125 | Validation loss: 0.5446\n",
      "Epoch 00075 | Train AUC: 0.9652 | Train Loss: 0.3598 | Validation AUC: 0.9758 | Validation loss: 0.3537\n",
      "Epoch 00076 | Train AUC: 0.9447 | Train Loss: 0.3837 | Validation AUC: 0.9738 | Validation loss: 0.3386\n",
      "Epoch 00077 | Train AUC: 0.9315 | Train Loss: 0.3837 | Validation AUC: 0.9604 | Validation loss: 0.3696\n",
      "Epoch 00078 | Train AUC: 0.9269 | Train Loss: 0.3937 | Validation AUC: 0.9475 | Validation loss: 0.3968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00079 | Train AUC: 0.9251 | Train Loss: 0.4039 | Validation AUC: 0.9258 | Validation loss: 0.4088\n",
      "Epoch 00080 | Train AUC: 0.9261 | Train Loss: 0.4118 | Validation AUC: 0.9225 | Validation loss: 0.4224\n",
      "Epoch 00081 | Train AUC: 0.9247 | Train Loss: 0.4182 | Validation AUC: 0.9133 | Validation loss: 0.4225\n",
      "Epoch 00082 | Train AUC: 0.9237 | Train Loss: 0.4272 | Validation AUC: 0.9133 | Validation loss: 0.4222\n",
      "Epoch 00083 | Train AUC: 0.9161 | Train Loss: 0.4277 | Validation AUC: 0.9125 | Validation loss: 0.4220\n",
      "Epoch 00084 | Train AUC: 0.9153 | Train Loss: 0.4278 | Validation AUC: 0.9125 | Validation loss: 0.4218\n",
      "Epoch 00085 | Train AUC: 0.9156 | Train Loss: 0.4276 | Validation AUC: 0.9012 | Validation loss: 0.4216\n",
      "Epoch 00086 | Train AUC: 0.9159 | Train Loss: 0.4271 | Validation AUC: 0.9012 | Validation loss: 0.4214\n",
      "Epoch 00087 | Train AUC: 0.9151 | Train Loss: 0.4266 | Validation AUC: 0.8892 | Validation loss: 0.4213\n",
      "Epoch 00088 | Train AUC: 0.9147 | Train Loss: 0.4263 | Validation AUC: 0.8892 | Validation loss: 0.4211\n",
      "Epoch 00089 | Train AUC: 0.9152 | Train Loss: 0.4261 | Validation AUC: 0.8892 | Validation loss: 0.4210\n",
      "Epoch 00090 | Train AUC: 0.9152 | Train Loss: 0.4260 | Validation AUC: 0.8892 | Validation loss: 0.4209\n",
      "Epoch 00091 | Train AUC: 0.9152 | Train Loss: 0.4260 | Validation AUC: 0.8892 | Validation loss: 0.4208\n",
      "Epoch 00092 | Train AUC: 0.9152 | Train Loss: 0.4260 | Validation AUC: 0.8892 | Validation loss: 0.4206\n",
      "Epoch 00093 | Train AUC: 0.9152 | Train Loss: 0.4260 | Validation AUC: 0.8892 | Validation loss: 0.4206\n",
      "Epoch 00094 | Train AUC: 0.9152 | Train Loss: 0.4259 | Validation AUC: 0.8892 | Validation loss: 0.4205\n",
      "Epoch 00095 | Train AUC: 0.9152 | Train Loss: 0.4259 | Validation AUC: 0.8892 | Validation loss: 0.4204\n",
      "Epoch 00096 | Train AUC: 0.9159 | Train Loss: 0.4259 | Validation AUC: 0.8892 | Validation loss: 0.4203\n",
      "Epoch 00097 | Train AUC: 0.9159 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4203\n",
      "Epoch 00098 | Train AUC: 0.9159 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4202\n",
      "Epoch 00099 | Train AUC: 0.9159 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4201\n",
      "Epoch 00100 | Train AUC: 0.9159 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4201\n",
      "Epoch 00101 | Train AUC: 0.9159 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4200\n",
      "Epoch 00102 | Train AUC: 0.9159 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4200\n",
      "Epoch 00103 | Train AUC: 0.9159 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4200\n",
      "Epoch 00104 | Train AUC: 0.9159 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4199\n",
      "Epoch 00105 | Train AUC: 0.9159 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4199\n",
      "Epoch 00106 | Train AUC: 0.9159 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4199\n",
      "Epoch 00107 | Train AUC: 0.9159 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4199\n",
      "Epoch 00108 | Train AUC: 0.9159 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4198\n",
      "Epoch 00109 | Train AUC: 0.9159 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4198\n",
      "Epoch 00110 | Train AUC: 0.9159 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4198\n",
      "Epoch 00111 | Train AUC: 0.9158 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4198\n",
      "Epoch 00112 | Train AUC: 0.9158 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4198\n",
      "Epoch 00113 | Train AUC: 0.9158 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4198\n",
      "Epoch 00114 | Train AUC: 0.9158 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4198\n",
      "Epoch 00115 | Train AUC: 0.9089 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4198\n",
      "Epoch 00116 | Train AUC: 0.9089 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4197\n",
      "Epoch 00117 | Train AUC: 0.9089 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4197\n",
      "Epoch 00118 | Train AUC: 0.9089 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4197\n",
      "Epoch 00119 | Train AUC: 0.9089 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4197\n",
      "Epoch 00120 | Train AUC: 0.9089 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4197\n",
      "Epoch 00121 | Train AUC: 0.9087 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4197\n",
      "Epoch 00122 | Train AUC: 0.9087 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4197\n",
      "Epoch 00123 | Train AUC: 0.9087 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4197\n",
      "Epoch 00124 | Train AUC: 0.9087 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4197\n",
      "Epoch 00125 | Train AUC: 0.9087 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4197\n",
      "Epoch 00126 | Train AUC: 0.9087 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4197\n",
      "Epoch 00127 | Train AUC: 0.9087 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4197\n",
      "Epoch 00128 | Train AUC: 0.9087 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4197\n",
      "Epoch 00129 | Train AUC: 0.9087 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4197\n",
      "Epoch 00130 | Train AUC: 0.9087 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4197\n",
      "Epoch 00131 | Train AUC: 0.9087 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4197\n",
      "Epoch 00132 | Train AUC: 0.9087 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4197\n",
      "Epoch 00133 | Train AUC: 0.9087 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4197\n",
      "Epoch 00134 | Train AUC: 0.9085 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4197\n",
      "Epoch 00135 | Train AUC: 0.9085 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4197\n",
      "Epoch 00136 | Train AUC: 0.9085 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4197\n",
      "Epoch 00137 | Train AUC: 0.9085 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4197\n",
      "Epoch 00138 | Train AUC: 0.9085 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4197\n",
      "Epoch 00139 | Train AUC: 0.9085 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4197\n",
      "Epoch 00140 | Train AUC: 0.9085 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4197\n",
      "Epoch 00141 | Train AUC: 0.9085 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4197\n",
      "Epoch 00142 | Train AUC: 0.9083 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4197\n",
      "Epoch 00143 | Train AUC: 0.9081 | Train Loss: 0.4259 | Validation AUC: 0.8875 | Validation loss: 0.4197\n",
      "Epoch 00144 | Train AUC: 0.9081 | Train Loss: 0.4259 | Validation AUC: 0.8867 | Validation loss: 0.4198\n",
      "Epoch 00145 | Train AUC: 0.9081 | Train Loss: 0.4259 | Validation AUC: 0.8867 | Validation loss: 0.4198\n",
      "Epoch 00146 | Train AUC: 0.9081 | Train Loss: 0.4259 | Validation AUC: 0.8867 | Validation loss: 0.4198\n",
      "Epoch 00147 | Train AUC: 0.9081 | Train Loss: 0.4259 | Validation AUC: 0.8867 | Validation loss: 0.4198\n",
      "Epoch 00148 | Train AUC: 0.9081 | Train Loss: 0.4259 | Validation AUC: 0.8867 | Validation loss: 0.4198\n",
      "Epoch 00149 | Train AUC: 0.9081 | Train Loss: 0.4259 | Validation AUC: 0.8867 | Validation loss: 0.4198\n",
      "Epoch 00150 | Train AUC: 0.9081 | Train Loss: 0.4259 | Validation AUC: 0.8867 | Validation loss: 0.4198\n",
      "Epoch 00151 | Train AUC: 0.9081 | Train Loss: 0.4259 | Validation AUC: 0.8867 | Validation loss: 0.4198\n",
      "Epoch 00152 | Train AUC: 0.9081 | Train Loss: 0.4259 | Validation AUC: 0.8867 | Validation loss: 0.4198\n",
      "Epoch 00153 | Train AUC: 0.9081 | Train Loss: 0.4259 | Validation AUC: 0.8867 | Validation loss: 0.4198\n",
      "Epoch 00154 | Train AUC: 0.9081 | Train Loss: 0.4259 | Validation AUC: 0.8867 | Validation loss: 0.4198\n",
      "Epoch 00155 | Train AUC: 0.9081 | Train Loss: 0.4259 | Validation AUC: 0.8867 | Validation loss: 0.4198\n",
      "Epoch 00156 | Train AUC: 0.9081 | Train Loss: 0.4259 | Validation AUC: 0.8867 | Validation loss: 0.4198\n",
      "Epoch 00157 | Train AUC: 0.9081 | Train Loss: 0.4259 | Validation AUC: 0.8867 | Validation loss: 0.4198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00158 | Train AUC: 0.9081 | Train Loss: 0.4259 | Validation AUC: 0.8867 | Validation loss: 0.4198\n",
      "Epoch 00159 | Train AUC: 0.9081 | Train Loss: 0.4259 | Validation AUC: 0.8867 | Validation loss: 0.4198\n",
      "Epoch 00160 | Train AUC: 0.9081 | Train Loss: 0.4259 | Validation AUC: 0.8867 | Validation loss: 0.4198\n",
      "Epoch 00161 | Train AUC: 0.9081 | Train Loss: 0.4259 | Validation AUC: 0.8867 | Validation loss: 0.4198\n",
      "Epoch 00162 | Train AUC: 0.9081 | Train Loss: 0.4259 | Validation AUC: 0.8867 | Validation loss: 0.4198\n",
      "Epoch 00163 | Train AUC: 0.9081 | Train Loss: 0.4259 | Validation AUC: 0.8867 | Validation loss: 0.4198\n",
      "Epoch 00164 | Train AUC: 0.9081 | Train Loss: 0.4259 | Validation AUC: 0.8867 | Validation loss: 0.4198\n",
      "Epoch 00165 | Train AUC: 0.9081 | Train Loss: 0.4259 | Validation AUC: 0.8858 | Validation loss: 0.4198\n",
      "Epoch 00166 | Train AUC: 0.9081 | Train Loss: 0.4259 | Validation AUC: 0.8858 | Validation loss: 0.4198\n",
      "Epoch 00167 | Train AUC: 0.9073 | Train Loss: 0.4259 | Validation AUC: 0.8858 | Validation loss: 0.4198\n",
      "Epoch 00168 | Train AUC: 0.9073 | Train Loss: 0.4259 | Validation AUC: 0.8858 | Validation loss: 0.4198\n",
      "Epoch 00169 | Train AUC: 0.9073 | Train Loss: 0.4259 | Validation AUC: 0.8858 | Validation loss: 0.4198\n",
      "Epoch 00170 | Train AUC: 0.9073 | Train Loss: 0.4259 | Validation AUC: 0.8858 | Validation loss: 0.4198\n",
      "Epoch 00171 | Train AUC: 0.9073 | Train Loss: 0.4259 | Validation AUC: 0.8858 | Validation loss: 0.4198\n",
      "Epoch 00172 | Train AUC: 0.9073 | Train Loss: 0.4259 | Validation AUC: 0.8858 | Validation loss: 0.4198\n",
      "Epoch 00173 | Train AUC: 0.9073 | Train Loss: 0.4259 | Validation AUC: 0.8858 | Validation loss: 0.4198\n",
      "Epoch 00174 | Train AUC: 0.9073 | Train Loss: 0.4259 | Validation AUC: 0.8858 | Validation loss: 0.4199\n",
      "Epoch 00175 | Train AUC: 0.9073 | Train Loss: 0.4259 | Validation AUC: 0.8858 | Validation loss: 0.4199\n",
      "Epoch 00176 | Train AUC: 0.9073 | Train Loss: 0.4259 | Validation AUC: 0.8858 | Validation loss: 0.4199\n",
      "Epoch 00177 | Train AUC: 0.9073 | Train Loss: 0.4259 | Validation AUC: 0.8858 | Validation loss: 0.4199\n",
      "Epoch 00178 | Train AUC: 0.9073 | Train Loss: 0.4259 | Validation AUC: 0.8858 | Validation loss: 0.4199\n",
      "Epoch 00179 | Train AUC: 0.9073 | Train Loss: 0.4259 | Validation AUC: 0.8858 | Validation loss: 0.4199\n",
      "Epoch 00180 | Train AUC: 0.9073 | Train Loss: 0.4259 | Validation AUC: 0.8850 | Validation loss: 0.4199\n",
      "Epoch 00181 | Train AUC: 0.9071 | Train Loss: 0.4259 | Validation AUC: 0.8850 | Validation loss: 0.4199\n",
      "Epoch 00182 | Train AUC: 0.9071 | Train Loss: 0.4259 | Validation AUC: 0.8850 | Validation loss: 0.4199\n",
      "Epoch 00183 | Train AUC: 0.9071 | Train Loss: 0.4259 | Validation AUC: 0.8850 | Validation loss: 0.4199\n",
      "Epoch 00184 | Train AUC: 0.9071 | Train Loss: 0.4259 | Validation AUC: 0.8850 | Validation loss: 0.4199\n",
      "Epoch 00185 | Train AUC: 0.9071 | Train Loss: 0.4259 | Validation AUC: 0.8850 | Validation loss: 0.4199\n",
      "Epoch 00186 | Train AUC: 0.9073 | Train Loss: 0.4259 | Validation AUC: 0.8850 | Validation loss: 0.4199\n",
      "Epoch 00187 | Train AUC: 0.9073 | Train Loss: 0.4259 | Validation AUC: 0.8850 | Validation loss: 0.4199\n",
      "Epoch 00188 | Train AUC: 0.9073 | Train Loss: 0.4259 | Validation AUC: 0.8850 | Validation loss: 0.4199\n",
      "Epoch 00189 | Train AUC: 0.9073 | Train Loss: 0.4259 | Validation AUC: 0.8850 | Validation loss: 0.4199\n",
      "Epoch 00190 | Train AUC: 0.9073 | Train Loss: 0.4259 | Validation AUC: 0.8850 | Validation loss: 0.4199\n",
      "Epoch 00191 | Train AUC: 0.9073 | Train Loss: 0.4259 | Validation AUC: 0.8850 | Validation loss: 0.4199\n",
      "Epoch 00192 | Train AUC: 0.9073 | Train Loss: 0.4259 | Validation AUC: 0.8850 | Validation loss: 0.4199\n",
      "Epoch 00193 | Train AUC: 0.9073 | Train Loss: 0.4259 | Validation AUC: 0.8858 | Validation loss: 0.4199\n",
      "Epoch 00194 | Train AUC: 0.9073 | Train Loss: 0.4259 | Validation AUC: 0.8858 | Validation loss: 0.4199\n",
      "Epoch 00195 | Train AUC: 0.9073 | Train Loss: 0.4259 | Validation AUC: 0.8850 | Validation loss: 0.4199\n",
      "Epoch 00196 | Train AUC: 0.9065 | Train Loss: 0.4259 | Validation AUC: 0.8850 | Validation loss: 0.4199\n",
      "Epoch 00197 | Train AUC: 0.9065 | Train Loss: 0.4259 | Validation AUC: 0.8850 | Validation loss: 0.4199\n",
      "Epoch 00198 | Train AUC: 0.9065 | Train Loss: 0.4259 | Validation AUC: 0.8850 | Validation loss: 0.4199\n",
      "Epoch 00199 | Train AUC: 0.9065 | Train Loss: 0.4259 | Validation AUC: 0.8850 | Validation loss: 0.4199\n",
      "Epoch 00200 | Train AUC: 0.9065 | Train Loss: 0.4259 | Validation AUC: 0.8850 | Validation loss: 0.4199\n",
      "Epoch 00201 | Train AUC: 0.9065 | Train Loss: 0.4259 | Validation AUC: 0.8850 | Validation loss: 0.4199\n",
      "Epoch 00202 | Train AUC: 0.9065 | Train Loss: 0.4259 | Validation AUC: 0.8850 | Validation loss: 0.4200\n",
      "Epoch 00203 | Train AUC: 0.9065 | Train Loss: 0.4259 | Validation AUC: 0.8850 | Validation loss: 0.4200\n",
      "Epoch 00204 | Train AUC: 0.9065 | Train Loss: 0.4259 | Validation AUC: 0.8850 | Validation loss: 0.4200\n",
      "Epoch 00205 | Train AUC: 0.9065 | Train Loss: 0.4259 | Validation AUC: 0.8850 | Validation loss: 0.4200\n",
      "Epoch 00206 | Train AUC: 0.9065 | Train Loss: 0.4259 | Validation AUC: 0.8858 | Validation loss: 0.4200\n",
      "Epoch 00207 | Train AUC: 0.9065 | Train Loss: 0.4259 | Validation AUC: 0.8858 | Validation loss: 0.4200\n",
      "Epoch 00208 | Train AUC: 0.9065 | Train Loss: 0.4259 | Validation AUC: 0.8858 | Validation loss: 0.4200\n",
      "Epoch 00209 | Train AUC: 0.9065 | Train Loss: 0.4259 | Validation AUC: 0.8858 | Validation loss: 0.4200\n",
      "Epoch 00210 | Train AUC: 0.9065 | Train Loss: 0.4259 | Validation AUC: 0.8858 | Validation loss: 0.4200\n",
      "Epoch 00211 | Train AUC: 0.9069 | Train Loss: 0.4259 | Validation AUC: 0.8858 | Validation loss: 0.4200\n",
      "Epoch 00212 | Train AUC: 0.9071 | Train Loss: 0.4259 | Validation AUC: 0.8858 | Validation loss: 0.4200\n",
      "Epoch 00213 | Train AUC: 0.9071 | Train Loss: 0.4259 | Validation AUC: 0.8867 | Validation loss: 0.4200\n",
      "Epoch 00214 | Train AUC: 0.9073 | Train Loss: 0.4259 | Validation AUC: 0.8867 | Validation loss: 0.4200\n",
      "Epoch 00215 | Train AUC: 0.9073 | Train Loss: 0.4259 | Validation AUC: 0.8867 | Validation loss: 0.4201\n",
      "Epoch 00216 | Train AUC: 0.9073 | Train Loss: 0.4259 | Validation AUC: 0.8867 | Validation loss: 0.4201\n",
      "Epoch 00217 | Train AUC: 0.9073 | Train Loss: 0.4259 | Validation AUC: 0.8867 | Validation loss: 0.4201\n",
      "Epoch 00218 | Train AUC: 0.9073 | Train Loss: 0.4259 | Validation AUC: 0.8867 | Validation loss: 0.4201\n",
      "Epoch 00219 | Train AUC: 0.9073 | Train Loss: 0.4259 | Validation AUC: 0.8875 | Validation loss: 0.4201\n",
      "Epoch 00220 | Train AUC: 0.9073 | Train Loss: 0.4259 | Validation AUC: 0.8875 | Validation loss: 0.4201\n",
      "Epoch 00221 | Train AUC: 0.9075 | Train Loss: 0.4259 | Validation AUC: 0.8875 | Validation loss: 0.4201\n",
      "Epoch 00222 | Train AUC: 0.9075 | Train Loss: 0.4259 | Validation AUC: 0.8875 | Validation loss: 0.4201\n",
      "Epoch 00223 | Train AUC: 0.9075 | Train Loss: 0.4259 | Validation AUC: 0.8875 | Validation loss: 0.4201\n",
      "Epoch 00224 | Train AUC: 0.9075 | Train Loss: 0.4259 | Validation AUC: 0.8875 | Validation loss: 0.4201\n",
      "Epoch 00225 | Train AUC: 0.9075 | Train Loss: 0.4259 | Validation AUC: 0.8875 | Validation loss: 0.4201\n",
      "Epoch 00226 | Train AUC: 0.9075 | Train Loss: 0.4259 | Validation AUC: 0.8875 | Validation loss: 0.4201\n",
      "Epoch 00227 | Train AUC: 0.9075 | Train Loss: 0.4259 | Validation AUC: 0.8875 | Validation loss: 0.4201\n",
      "Epoch 00228 | Train AUC: 0.9075 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4201\n",
      "Epoch 00229 | Train AUC: 0.9075 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4201\n",
      "Epoch 00230 | Train AUC: 0.9075 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4202\n",
      "Epoch 00231 | Train AUC: 0.9075 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4202\n",
      "Epoch 00232 | Train AUC: 0.9075 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4202\n",
      "Epoch 00233 | Train AUC: 0.9075 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4202\n",
      "Epoch 00234 | Train AUC: 0.9075 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4202\n",
      "Epoch 00235 | Train AUC: 0.9075 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4202\n",
      "Epoch 00236 | Train AUC: 0.9075 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00237 | Train AUC: 0.9077 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4202\n",
      "Epoch 00238 | Train AUC: 0.9077 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4202\n",
      "Epoch 00239 | Train AUC: 0.9077 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4202\n",
      "Epoch 00240 | Train AUC: 0.9077 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4202\n",
      "Epoch 00241 | Train AUC: 0.9077 | Train Loss: 0.4259 | Validation AUC: 0.8883 | Validation loss: 0.4203\n",
      "Epoch 00242 | Train AUC: 0.9077 | Train Loss: 0.4259 | Validation AUC: 0.8892 | Validation loss: 0.4203\n",
      "Epoch 00243 | Train AUC: 0.9077 | Train Loss: 0.4259 | Validation AUC: 0.8892 | Validation loss: 0.4203\n",
      "Epoch 00244 | Train AUC: 0.9077 | Train Loss: 0.4259 | Validation AUC: 0.8892 | Validation loss: 0.4203\n",
      "Epoch 00245 | Train AUC: 0.9077 | Train Loss: 0.4259 | Validation AUC: 0.8892 | Validation loss: 0.4203\n",
      "Epoch 00246 | Train AUC: 0.9077 | Train Loss: 0.4259 | Validation AUC: 0.8892 | Validation loss: 0.4203\n",
      "Epoch 00247 | Train AUC: 0.9079 | Train Loss: 0.4259 | Validation AUC: 0.8892 | Validation loss: 0.4203\n",
      "Epoch 00248 | Train AUC: 0.9079 | Train Loss: 0.4259 | Validation AUC: 0.8892 | Validation loss: 0.4203\n",
      "Epoch 00249 | Train AUC: 0.9079 | Train Loss: 0.4259 | Validation AUC: 0.8892 | Validation loss: 0.4203\n",
      "Epoch 00250 | Train AUC: 0.9079 | Train Loss: 0.4259 | Validation AUC: 0.8892 | Validation loss: 0.4203\n",
      "Epoch 00251 | Train AUC: 0.9079 | Train Loss: 0.4259 | Validation AUC: 0.8892 | Validation loss: 0.4203\n",
      "Epoch 00252 | Train AUC: 0.9079 | Train Loss: 0.4259 | Validation AUC: 0.8892 | Validation loss: 0.4203\n",
      "Epoch 00253 | Train AUC: 0.9079 | Train Loss: 0.4259 | Validation AUC: 0.8892 | Validation loss: 0.4203\n",
      "Epoch 00254 | Train AUC: 0.9081 | Train Loss: 0.4259 | Validation AUC: 0.8892 | Validation loss: 0.4203\n",
      "Epoch 00255 | Train AUC: 0.9147 | Train Loss: 0.4259 | Validation AUC: 0.8892 | Validation loss: 0.4203\n",
      "Epoch 00256 | Train AUC: 0.9147 | Train Loss: 0.4259 | Validation AUC: 0.8892 | Validation loss: 0.4203\n",
      "Epoch 00257 | Train AUC: 0.9147 | Train Loss: 0.4259 | Validation AUC: 0.8892 | Validation loss: 0.4203\n",
      "Epoch 00258 | Train AUC: 0.9147 | Train Loss: 0.4259 | Validation AUC: 0.8892 | Validation loss: 0.4204\n",
      "Epoch 00259 | Train AUC: 0.9149 | Train Loss: 0.4259 | Validation AUC: 0.8892 | Validation loss: 0.4204\n",
      "Epoch 00260 | Train AUC: 0.9149 | Train Loss: 0.4259 | Validation AUC: 0.8892 | Validation loss: 0.4204\n",
      "Epoch 00261 | Train AUC: 0.9151 | Train Loss: 0.4259 | Validation AUC: 0.8900 | Validation loss: 0.4204\n",
      "Epoch 00262 | Train AUC: 0.9153 | Train Loss: 0.4259 | Validation AUC: 0.8900 | Validation loss: 0.4204\n",
      "Epoch 00263 | Train AUC: 0.9155 | Train Loss: 0.4259 | Validation AUC: 0.8900 | Validation loss: 0.4204\n",
      "Epoch 00264 | Train AUC: 0.9155 | Train Loss: 0.4259 | Validation AUC: 0.8900 | Validation loss: 0.4204\n",
      "Epoch 00265 | Train AUC: 0.9155 | Train Loss: 0.4259 | Validation AUC: 0.8900 | Validation loss: 0.4204\n",
      "Epoch 00266 | Train AUC: 0.9155 | Train Loss: 0.4259 | Validation AUC: 0.8900 | Validation loss: 0.4204\n",
      "Epoch 00267 | Train AUC: 0.9157 | Train Loss: 0.4259 | Validation AUC: 0.8900 | Validation loss: 0.4204\n",
      "Epoch 00268 | Train AUC: 0.9159 | Train Loss: 0.4259 | Validation AUC: 0.8900 | Validation loss: 0.4204\n",
      "Epoch 00269 | Train AUC: 0.9159 | Train Loss: 0.4259 | Validation AUC: 0.8900 | Validation loss: 0.4204\n",
      "Epoch 00270 | Train AUC: 0.9159 | Train Loss: 0.4259 | Validation AUC: 0.8900 | Validation loss: 0.4204\n",
      "Epoch 00271 | Train AUC: 0.9159 | Train Loss: 0.4259 | Validation AUC: 0.8900 | Validation loss: 0.4204\n",
      "Epoch 00272 | Train AUC: 0.9159 | Train Loss: 0.4259 | Validation AUC: 0.8900 | Validation loss: 0.4204\n",
      "Epoch 00273 | Train AUC: 0.9159 | Train Loss: 0.4259 | Validation AUC: 0.8900 | Validation loss: 0.4205\n",
      "Epoch 00274 | Train AUC: 0.9159 | Train Loss: 0.4259 | Validation AUC: 0.8900 | Validation loss: 0.4205\n",
      "Epoch 00275 | Train AUC: 0.9159 | Train Loss: 0.4259 | Validation AUC: 0.8900 | Validation loss: 0.4205\n",
      "Epoch 00276 | Train AUC: 0.9159 | Train Loss: 0.4259 | Validation AUC: 0.8900 | Validation loss: 0.4205\n",
      "Epoch 00277 | Train AUC: 0.9161 | Train Loss: 0.4259 | Validation AUC: 0.8900 | Validation loss: 0.4205\n",
      "Epoch 00278 | Train AUC: 0.9161 | Train Loss: 0.4259 | Validation AUC: 0.8900 | Validation loss: 0.4205\n",
      "Epoch 00279 | Train AUC: 0.9161 | Train Loss: 0.4259 | Validation AUC: 0.8900 | Validation loss: 0.4205\n",
      "Epoch 00280 | Train AUC: 0.9161 | Train Loss: 0.4259 | Validation AUC: 0.9012 | Validation loss: 0.4205\n",
      "Epoch 00281 | Train AUC: 0.9161 | Train Loss: 0.4259 | Validation AUC: 0.9012 | Validation loss: 0.4205\n",
      "Epoch 00282 | Train AUC: 0.9163 | Train Loss: 0.4259 | Validation AUC: 0.9012 | Validation loss: 0.4205\n",
      "Epoch 00283 | Train AUC: 0.9163 | Train Loss: 0.4259 | Validation AUC: 0.9012 | Validation loss: 0.4205\n",
      "Epoch 00284 | Train AUC: 0.9163 | Train Loss: 0.4259 | Validation AUC: 0.9012 | Validation loss: 0.4205\n",
      "Epoch 00285 | Train AUC: 0.9163 | Train Loss: 0.4259 | Validation AUC: 0.9012 | Validation loss: 0.4205\n",
      "Epoch 00286 | Train AUC: 0.9163 | Train Loss: 0.4259 | Validation AUC: 0.9012 | Validation loss: 0.4205\n",
      "Epoch 00287 | Train AUC: 0.9163 | Train Loss: 0.4259 | Validation AUC: 0.9012 | Validation loss: 0.4205\n",
      "Epoch 00288 | Train AUC: 0.9163 | Train Loss: 0.4259 | Validation AUC: 0.9012 | Validation loss: 0.4206\n",
      "Epoch 00289 | Train AUC: 0.9163 | Train Loss: 0.4259 | Validation AUC: 0.9012 | Validation loss: 0.4206\n",
      "Epoch 00290 | Train AUC: 0.9163 | Train Loss: 0.4259 | Validation AUC: 0.9012 | Validation loss: 0.4206\n",
      "Epoch 00291 | Train AUC: 0.9163 | Train Loss: 0.4259 | Validation AUC: 0.9012 | Validation loss: 0.4206\n",
      "Epoch 00292 | Train AUC: 0.9163 | Train Loss: 0.4259 | Validation AUC: 0.9012 | Validation loss: 0.4206\n",
      "Epoch 00293 | Train AUC: 0.9165 | Train Loss: 0.4259 | Validation AUC: 0.9012 | Validation loss: 0.4206\n",
      "Epoch 00294 | Train AUC: 0.9165 | Train Loss: 0.4259 | Validation AUC: 0.9012 | Validation loss: 0.4206\n",
      "Epoch 00295 | Train AUC: 0.9165 | Train Loss: 0.4259 | Validation AUC: 0.9012 | Validation loss: 0.4206\n",
      "Epoch 00296 | Train AUC: 0.9165 | Train Loss: 0.4259 | Validation AUC: 0.9012 | Validation loss: 0.4206\n",
      "Epoch 00297 | Train AUC: 0.9165 | Train Loss: 0.4259 | Validation AUC: 0.9012 | Validation loss: 0.4206\n",
      "Epoch 00298 | Train AUC: 0.9165 | Train Loss: 0.4259 | Validation AUC: 0.9012 | Validation loss: 0.4206\n",
      "Epoch 00299 | Train AUC: 0.9165 | Train Loss: 0.4259 | Validation AUC: 0.9012 | Validation loss: 0.4206\n",
      "==== Test Phase ====\n",
      "test auc : 0.9090909090909091\n",
      "=================\n",
      "Start 1-th fold\n",
      "==== Train Phase ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/dgl/frame.py:204: UserWarning: Initializer is not set. Use zero initializer instead. To suppress this warning, use `set_initializer` to explicitly specify which initializer to use.\n",
      "  dgl_warning('Initializer is not set. Use zero initializer instead.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000 | Train AUC: 0.3273 | Train Loss: 0.8546 | Validation AUC: 0.2133 | Validation loss: 0.9220\n",
      "Epoch 00001 | Train AUC: 0.3955 | Train Loss: 0.8131 | Validation AUC: 0.3008 | Validation loss: 0.8429\n",
      "Epoch 00002 | Train AUC: 0.6193 | Train Loss: 0.6847 | Validation AUC: 0.5342 | Validation loss: 0.7093\n",
      "Epoch 00003 | Train AUC: 0.8338 | Train Loss: 0.5204 | Validation AUC: 0.9113 | Validation loss: 0.4719\n",
      "Epoch 00004 | Train AUC: 0.8387 | Train Loss: 0.5071 | Validation AUC: 0.9183 | Validation loss: 0.4611\n",
      "Epoch 00005 | Train AUC: 0.8488 | Train Loss: 0.4874 | Validation AUC: 0.9200 | Validation loss: 0.4487\n",
      "Epoch 00006 | Train AUC: 0.8523 | Train Loss: 0.4789 | Validation AUC: 0.9158 | Validation loss: 0.4405\n",
      "Epoch 00007 | Train AUC: 0.8545 | Train Loss: 0.4754 | Validation AUC: 0.9117 | Validation loss: 0.4328\n",
      "Epoch 00008 | Train AUC: 0.8541 | Train Loss: 0.4694 | Validation AUC: 0.9142 | Validation loss: 0.4232\n",
      "Epoch 00009 | Train AUC: 0.8529 | Train Loss: 0.4624 | Validation AUC: 0.9167 | Validation loss: 0.4167\n",
      "Epoch 00010 | Train AUC: 0.8531 | Train Loss: 0.4620 | Validation AUC: 0.9267 | Validation loss: 0.4110\n",
      "Epoch 00011 | Train AUC: 0.8556 | Train Loss: 0.4582 | Validation AUC: 0.9283 | Validation loss: 0.4100\n",
      "Epoch 00012 | Train AUC: 0.8584 | Train Loss: 0.4542 | Validation AUC: 0.9250 | Validation loss: 0.4110\n",
      "Epoch 00013 | Train AUC: 0.8596 | Train Loss: 0.4517 | Validation AUC: 0.9250 | Validation loss: 0.4105\n",
      "Epoch 00014 | Train AUC: 0.8613 | Train Loss: 0.4437 | Validation AUC: 0.9242 | Validation loss: 0.4101\n",
      "Epoch 00015 | Train AUC: 0.8615 | Train Loss: 0.4442 | Validation AUC: 0.9242 | Validation loss: 0.4103\n",
      "Epoch 00016 | Train AUC: 0.8658 | Train Loss: 0.4416 | Validation AUC: 0.9200 | Validation loss: 0.4098\n",
      "Epoch 00017 | Train AUC: 0.8634 | Train Loss: 0.4359 | Validation AUC: 0.9308 | Validation loss: 0.4091\n",
      "Epoch 00018 | Train AUC: 0.8614 | Train Loss: 0.4353 | Validation AUC: 0.9317 | Validation loss: 0.4088\n",
      "Epoch 00019 | Train AUC: 0.8636 | Train Loss: 0.4337 | Validation AUC: 0.9317 | Validation loss: 0.4084\n",
      "Epoch 00020 | Train AUC: 0.8630 | Train Loss: 0.4309 | Validation AUC: 0.9254 | Validation loss: 0.4077\n",
      "Epoch 00021 | Train AUC: 0.8648 | Train Loss: 0.4304 | Validation AUC: 0.9254 | Validation loss: 0.4064\n",
      "Epoch 00022 | Train AUC: 0.8709 | Train Loss: 0.4288 | Validation AUC: 0.9271 | Validation loss: 0.4039\n",
      "Epoch 00023 | Train AUC: 0.8727 | Train Loss: 0.4287 | Validation AUC: 0.9283 | Validation loss: 0.4008\n",
      "Epoch 00024 | Train AUC: 0.8740 | Train Loss: 0.4279 | Validation AUC: 0.9292 | Validation loss: 0.3979\n",
      "Epoch 00025 | Train AUC: 0.8738 | Train Loss: 0.4270 | Validation AUC: 0.9171 | Validation loss: 0.3960\n",
      "Epoch 00026 | Train AUC: 0.8734 | Train Loss: 0.4267 | Validation AUC: 0.9171 | Validation loss: 0.3948\n",
      "Epoch 00027 | Train AUC: 0.8734 | Train Loss: 0.4266 | Validation AUC: 0.9171 | Validation loss: 0.3941\n",
      "Epoch 00028 | Train AUC: 0.8734 | Train Loss: 0.4265 | Validation AUC: 0.9171 | Validation loss: 0.3936\n",
      "Epoch 00029 | Train AUC: 0.8643 | Train Loss: 0.4264 | Validation AUC: 0.9183 | Validation loss: 0.3933\n",
      "Epoch 00030 | Train AUC: 0.8589 | Train Loss: 0.4263 | Validation AUC: 0.9183 | Validation loss: 0.3930\n",
      "Epoch 00031 | Train AUC: 0.8589 | Train Loss: 0.4262 | Validation AUC: 0.9183 | Validation loss: 0.3928\n",
      "Epoch 00032 | Train AUC: 0.8652 | Train Loss: 0.4261 | Validation AUC: 0.9183 | Validation loss: 0.3925\n",
      "Epoch 00033 | Train AUC: 0.8655 | Train Loss: 0.4260 | Validation AUC: 0.9196 | Validation loss: 0.3923\n",
      "Epoch 00034 | Train AUC: 0.8653 | Train Loss: 0.4260 | Validation AUC: 0.9196 | Validation loss: 0.3921\n",
      "Epoch 00035 | Train AUC: 0.8664 | Train Loss: 0.4260 | Validation AUC: 0.9196 | Validation loss: 0.3918\n",
      "Epoch 00036 | Train AUC: 0.8675 | Train Loss: 0.4260 | Validation AUC: 0.9213 | Validation loss: 0.3916\n",
      "Epoch 00037 | Train AUC: 0.8675 | Train Loss: 0.4260 | Validation AUC: 0.9213 | Validation loss: 0.3915\n",
      "Epoch 00038 | Train AUC: 0.8675 | Train Loss: 0.4260 | Validation AUC: 0.9213 | Validation loss: 0.3913\n",
      "Epoch 00039 | Train AUC: 0.8675 | Train Loss: 0.4260 | Validation AUC: 0.9213 | Validation loss: 0.3911\n",
      "Epoch 00040 | Train AUC: 0.8675 | Train Loss: 0.4260 | Validation AUC: 0.9213 | Validation loss: 0.3909\n",
      "Epoch 00041 | Train AUC: 0.8616 | Train Loss: 0.4260 | Validation AUC: 0.9213 | Validation loss: 0.3907\n",
      "Epoch 00042 | Train AUC: 0.8616 | Train Loss: 0.4260 | Validation AUC: 0.9213 | Validation loss: 0.3906\n",
      "Epoch 00043 | Train AUC: 0.8620 | Train Loss: 0.4260 | Validation AUC: 0.9213 | Validation loss: 0.3904\n",
      "Epoch 00044 | Train AUC: 0.8622 | Train Loss: 0.4260 | Validation AUC: 0.9213 | Validation loss: 0.3903\n",
      "Epoch 00045 | Train AUC: 0.8622 | Train Loss: 0.4260 | Validation AUC: 0.9213 | Validation loss: 0.3902\n",
      "Epoch 00046 | Train AUC: 0.8624 | Train Loss: 0.4259 | Validation AUC: 0.9213 | Validation loss: 0.3901\n",
      "Epoch 00047 | Train AUC: 0.8566 | Train Loss: 0.4259 | Validation AUC: 0.9213 | Validation loss: 0.3900\n",
      "Epoch 00048 | Train AUC: 0.8566 | Train Loss: 0.4259 | Validation AUC: 0.9083 | Validation loss: 0.3899\n",
      "Epoch 00049 | Train AUC: 0.8566 | Train Loss: 0.4250 | Validation AUC: 0.9083 | Validation loss: 0.3898\n",
      "Epoch 00050 | Train AUC: 0.8566 | Train Loss: 0.4272 | Validation AUC: 0.9208 | Validation loss: 0.3896\n",
      "Epoch 00051 | Train AUC: 0.8564 | Train Loss: 0.4277 | Validation AUC: 0.9208 | Validation loss: 0.3884\n",
      "Epoch 00052 | Train AUC: 0.8566 | Train Loss: 0.4204 | Validation AUC: 0.9200 | Validation loss: 0.3894\n",
      "Epoch 00053 | Train AUC: 0.8681 | Train Loss: 0.4260 | Validation AUC: 0.9217 | Validation loss: 0.3892\n",
      "Epoch 00054 | Train AUC: 0.8640 | Train Loss: 0.4260 | Validation AUC: 0.9208 | Validation loss: 0.4015\n",
      "Epoch 00055 | Train AUC: 0.8634 | Train Loss: 0.4334 | Validation AUC: 0.9100 | Validation loss: 0.4032\n",
      "Epoch 00056 | Train AUC: 0.8656 | Train Loss: 0.4364 | Validation AUC: 0.9092 | Validation loss: 0.4173\n",
      "Epoch 00057 | Train AUC: 0.8634 | Train Loss: 0.4338 | Validation AUC: 0.9100 | Validation loss: 0.4031\n",
      "Epoch 00058 | Train AUC: 0.8632 | Train Loss: 0.4331 | Validation AUC: 0.9100 | Validation loss: 0.4029\n",
      "Epoch 00059 | Train AUC: 0.8647 | Train Loss: 0.4260 | Validation AUC: 0.9208 | Validation loss: 0.4028\n",
      "Epoch 00060 | Train AUC: 0.8650 | Train Loss: 0.4260 | Validation AUC: 0.9217 | Validation loss: 0.3886\n",
      "Epoch 00061 | Train AUC: 0.8683 | Train Loss: 0.4260 | Validation AUC: 0.9217 | Validation loss: 0.3885\n",
      "Epoch 00062 | Train AUC: 0.8628 | Train Loss: 0.4260 | Validation AUC: 0.9083 | Validation loss: 0.3884\n",
      "Epoch 00063 | Train AUC: 0.8568 | Train Loss: 0.4254 | Validation AUC: 0.9083 | Validation loss: 0.3883\n",
      "Epoch 00064 | Train AUC: 0.8566 | Train Loss: 0.4211 | Validation AUC: 0.9208 | Validation loss: 0.3883\n",
      "Epoch 00065 | Train AUC: 0.8579 | Train Loss: 0.4206 | Validation AUC: 0.9208 | Validation loss: 0.3882\n",
      "Epoch 00066 | Train AUC: 0.8581 | Train Loss: 0.4237 | Validation AUC: 0.9083 | Validation loss: 0.3882\n",
      "Epoch 00067 | Train AUC: 0.8579 | Train Loss: 0.4217 | Validation AUC: 0.9208 | Validation loss: 0.3881\n",
      "Epoch 00068 | Train AUC: 0.8579 | Train Loss: 0.4217 | Validation AUC: 0.9208 | Validation loss: 0.3881\n",
      "Epoch 00069 | Train AUC: 0.8581 | Train Loss: 0.4200 | Validation AUC: 0.9100 | Validation loss: 0.3880\n",
      "Epoch 00070 | Train AUC: 0.8579 | Train Loss: 0.4193 | Validation AUC: 0.9100 | Validation loss: 0.3880\n",
      "Epoch 00071 | Train AUC: 0.8579 | Train Loss: 0.4194 | Validation AUC: 0.9208 | Validation loss: 0.3880\n",
      "Epoch 00072 | Train AUC: 0.8579 | Train Loss: 0.4197 | Validation AUC: 0.9208 | Validation loss: 0.3879\n",
      "Epoch 00073 | Train AUC: 0.8579 | Train Loss: 0.4192 | Validation AUC: 0.9200 | Validation loss: 0.3879\n",
      "Epoch 00074 | Train AUC: 0.8579 | Train Loss: 0.4193 | Validation AUC: 0.9100 | Validation loss: 0.3879\n",
      "Epoch 00075 | Train AUC: 0.8579 | Train Loss: 0.4193 | Validation AUC: 0.9100 | Validation loss: 0.3878\n",
      "Epoch 00076 | Train AUC: 0.8579 | Train Loss: 0.4191 | Validation AUC: 0.9200 | Validation loss: 0.3878\n",
      "Epoch 00077 | Train AUC: 0.8579 | Train Loss: 0.4193 | Validation AUC: 0.9208 | Validation loss: 0.3878\n",
      "Epoch 00078 | Train AUC: 0.8579 | Train Loss: 0.4192 | Validation AUC: 0.9208 | Validation loss: 0.3877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00079 | Train AUC: 0.8579 | Train Loss: 0.4191 | Validation AUC: 0.9200 | Validation loss: 0.3877\n",
      "Epoch 00080 | Train AUC: 0.8579 | Train Loss: 0.4190 | Validation AUC: 0.9100 | Validation loss: 0.3877\n",
      "Epoch 00081 | Train AUC: 0.8579 | Train Loss: 0.4192 | Validation AUC: 0.9100 | Validation loss: 0.3876\n",
      "Epoch 00082 | Train AUC: 0.8579 | Train Loss: 0.4190 | Validation AUC: 0.9100 | Validation loss: 0.3876\n",
      "Epoch 00083 | Train AUC: 0.8579 | Train Loss: 0.4190 | Validation AUC: 0.9200 | Validation loss: 0.3876\n",
      "Epoch 00084 | Train AUC: 0.8579 | Train Loss: 0.4191 | Validation AUC: 0.9204 | Validation loss: 0.3876\n",
      "Epoch 00085 | Train AUC: 0.8579 | Train Loss: 0.4191 | Validation AUC: 0.9208 | Validation loss: 0.3876\n",
      "Epoch 00086 | Train AUC: 0.8579 | Train Loss: 0.4190 | Validation AUC: 0.9200 | Validation loss: 0.3875\n",
      "Epoch 00087 | Train AUC: 0.8579 | Train Loss: 0.4190 | Validation AUC: 0.9100 | Validation loss: 0.3875\n",
      "Epoch 00088 | Train AUC: 0.8579 | Train Loss: 0.4190 | Validation AUC: 0.9100 | Validation loss: 0.3875\n",
      "Epoch 00089 | Train AUC: 0.8579 | Train Loss: 0.4190 | Validation AUC: 0.9100 | Validation loss: 0.3875\n",
      "Epoch 00090 | Train AUC: 0.8579 | Train Loss: 0.4190 | Validation AUC: 0.9100 | Validation loss: 0.3874\n",
      "Epoch 00091 | Train AUC: 0.8579 | Train Loss: 0.4190 | Validation AUC: 0.9100 | Validation loss: 0.3874\n",
      "Epoch 00092 | Train AUC: 0.8579 | Train Loss: 0.4190 | Validation AUC: 0.9200 | Validation loss: 0.3874\n",
      "Epoch 00093 | Train AUC: 0.8579 | Train Loss: 0.4190 | Validation AUC: 0.9200 | Validation loss: 0.3874\n",
      "Epoch 00094 | Train AUC: 0.8579 | Train Loss: 0.4190 | Validation AUC: 0.9200 | Validation loss: 0.3874\n",
      "Epoch 00095 | Train AUC: 0.8579 | Train Loss: 0.4190 | Validation AUC: 0.9200 | Validation loss: 0.3873\n",
      "Epoch 00096 | Train AUC: 0.8579 | Train Loss: 0.4190 | Validation AUC: 0.9100 | Validation loss: 0.3873\n",
      "Epoch 00097 | Train AUC: 0.8579 | Train Loss: 0.4190 | Validation AUC: 0.9100 | Validation loss: 0.3873\n",
      "Epoch 00098 | Train AUC: 0.8579 | Train Loss: 0.4190 | Validation AUC: 0.9100 | Validation loss: 0.3873\n",
      "Epoch 00099 | Train AUC: 0.8579 | Train Loss: 0.4190 | Validation AUC: 0.9100 | Validation loss: 0.3873\n",
      "Epoch 00100 | Train AUC: 0.8579 | Train Loss: 0.4190 | Validation AUC: 0.9100 | Validation loss: 0.3873\n",
      "Epoch 00101 | Train AUC: 0.8579 | Train Loss: 0.4190 | Validation AUC: 0.9100 | Validation loss: 0.3872\n",
      "Epoch 00102 | Train AUC: 0.8519 | Train Loss: 0.4189 | Validation AUC: 0.9100 | Validation loss: 0.3872\n",
      "Epoch 00103 | Train AUC: 0.8519 | Train Loss: 0.4190 | Validation AUC: 0.9100 | Validation loss: 0.3872\n",
      "Epoch 00104 | Train AUC: 0.8519 | Train Loss: 0.4190 | Validation AUC: 0.9200 | Validation loss: 0.3872\n",
      "Epoch 00105 | Train AUC: 0.8519 | Train Loss: 0.4190 | Validation AUC: 0.9200 | Validation loss: 0.3872\n",
      "Epoch 00106 | Train AUC: 0.8519 | Train Loss: 0.4190 | Validation AUC: 0.9100 | Validation loss: 0.3872\n",
      "Epoch 00107 | Train AUC: 0.8519 | Train Loss: 0.4189 | Validation AUC: 0.9100 | Validation loss: 0.3871\n",
      "Epoch 00108 | Train AUC: 0.8519 | Train Loss: 0.4189 | Validation AUC: 0.9100 | Validation loss: 0.3871\n",
      "Epoch 00109 | Train AUC: 0.8519 | Train Loss: 0.4190 | Validation AUC: 0.9100 | Validation loss: 0.3871\n",
      "Epoch 00110 | Train AUC: 0.8519 | Train Loss: 0.4190 | Validation AUC: 0.9100 | Validation loss: 0.3871\n",
      "Epoch 00111 | Train AUC: 0.8519 | Train Loss: 0.4189 | Validation AUC: 0.9100 | Validation loss: 0.3871\n",
      "Epoch 00112 | Train AUC: 0.8519 | Train Loss: 0.4189 | Validation AUC: 0.9100 | Validation loss: 0.3871\n",
      "Epoch 00113 | Train AUC: 0.8519 | Train Loss: 0.4189 | Validation AUC: 0.9100 | Validation loss: 0.3871\n",
      "Epoch 00114 | Train AUC: 0.8519 | Train Loss: 0.4189 | Validation AUC: 0.9100 | Validation loss: 0.3871\n",
      "Epoch 00115 | Train AUC: 0.8519 | Train Loss: 0.4189 | Validation AUC: 0.9100 | Validation loss: 0.3870\n",
      "Epoch 00116 | Train AUC: 0.8519 | Train Loss: 0.4189 | Validation AUC: 0.9100 | Validation loss: 0.3870\n",
      "Epoch 00117 | Train AUC: 0.8519 | Train Loss: 0.4189 | Validation AUC: 0.9100 | Validation loss: 0.3870\n",
      "Epoch 00118 | Train AUC: 0.8519 | Train Loss: 0.4189 | Validation AUC: 0.9100 | Validation loss: 0.3870\n",
      "Epoch 00119 | Train AUC: 0.8519 | Train Loss: 0.4189 | Validation AUC: 0.9100 | Validation loss: 0.3870\n",
      "Epoch 00120 | Train AUC: 0.8519 | Train Loss: 0.4189 | Validation AUC: 0.9100 | Validation loss: 0.3870\n",
      "Epoch 00121 | Train AUC: 0.8519 | Train Loss: 0.4189 | Validation AUC: 0.9100 | Validation loss: 0.3870\n",
      "Epoch 00122 | Train AUC: 0.8519 | Train Loss: 0.4189 | Validation AUC: 0.9100 | Validation loss: 0.3870\n",
      "Epoch 00123 | Train AUC: 0.8519 | Train Loss: 0.4189 | Validation AUC: 0.9100 | Validation loss: 0.3869\n",
      "Epoch 00124 | Train AUC: 0.8519 | Train Loss: 0.4189 | Validation AUC: 0.9100 | Validation loss: 0.3869\n",
      "Epoch 00125 | Train AUC: 0.8519 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3869\n",
      "Epoch 00126 | Train AUC: 0.8519 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3869\n",
      "Epoch 00127 | Train AUC: 0.8519 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3869\n",
      "Epoch 00128 | Train AUC: 0.8519 | Train Loss: 0.4189 | Validation AUC: 0.9100 | Validation loss: 0.3869\n",
      "Epoch 00129 | Train AUC: 0.8519 | Train Loss: 0.4189 | Validation AUC: 0.9100 | Validation loss: 0.3869\n",
      "Epoch 00130 | Train AUC: 0.8519 | Train Loss: 0.4189 | Validation AUC: 0.9100 | Validation loss: 0.3869\n",
      "Epoch 00131 | Train AUC: 0.8519 | Train Loss: 0.4189 | Validation AUC: 0.9100 | Validation loss: 0.3869\n",
      "Epoch 00132 | Train AUC: 0.8519 | Train Loss: 0.4189 | Validation AUC: 0.9100 | Validation loss: 0.3868\n",
      "Epoch 00133 | Train AUC: 0.8519 | Train Loss: 0.4189 | Validation AUC: 0.9100 | Validation loss: 0.3868\n",
      "Epoch 00134 | Train AUC: 0.8519 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3868\n",
      "Epoch 00135 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3868\n",
      "Epoch 00136 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3868\n",
      "Epoch 00137 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3868\n",
      "Epoch 00138 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3868\n",
      "Epoch 00139 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3868\n",
      "Epoch 00140 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3867\n",
      "Epoch 00141 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3867\n",
      "Epoch 00142 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3867\n",
      "Epoch 00143 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3867\n",
      "Epoch 00144 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3867\n",
      "Epoch 00145 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3867\n",
      "Epoch 00146 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3867\n",
      "Epoch 00147 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3867\n",
      "Epoch 00148 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3866\n",
      "Epoch 00149 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3866\n",
      "Epoch 00150 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3866\n",
      "Epoch 00151 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3866\n",
      "Epoch 00152 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3866\n",
      "Epoch 00153 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3866\n",
      "Epoch 00154 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3866\n",
      "Epoch 00155 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3866\n",
      "Epoch 00156 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3866\n",
      "Epoch 00157 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00158 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3865\n",
      "Epoch 00159 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3865\n",
      "Epoch 00160 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3865\n",
      "Epoch 00161 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3865\n",
      "Epoch 00162 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3865\n",
      "Epoch 00163 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3865\n",
      "Epoch 00164 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3865\n",
      "Epoch 00165 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3865\n",
      "Epoch 00166 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3864\n",
      "Epoch 00167 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3864\n",
      "Epoch 00168 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3864\n",
      "Epoch 00169 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3864\n",
      "Epoch 00170 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3864\n",
      "Epoch 00171 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3864\n",
      "Epoch 00172 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3864\n",
      "Epoch 00173 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3864\n",
      "Epoch 00174 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3864\n",
      "Epoch 00175 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3864\n",
      "Epoch 00176 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3863\n",
      "Epoch 00177 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3863\n",
      "Epoch 00178 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3863\n",
      "Epoch 00179 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3863\n",
      "Epoch 00180 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3863\n",
      "Epoch 00181 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3863\n",
      "Epoch 00182 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3863\n",
      "Epoch 00183 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3863\n",
      "Epoch 00184 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3863\n",
      "Epoch 00185 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3863\n",
      "Epoch 00186 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3862\n",
      "Epoch 00187 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3862\n",
      "Epoch 00188 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3862\n",
      "Epoch 00189 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3862\n",
      "Epoch 00190 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3862\n",
      "Epoch 00191 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3862\n",
      "Epoch 00192 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3862\n",
      "Epoch 00193 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3862\n",
      "Epoch 00194 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3862\n",
      "Epoch 00195 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3862\n",
      "Epoch 00196 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3862\n",
      "Epoch 00197 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3861\n",
      "Epoch 00198 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3861\n",
      "Epoch 00199 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3861\n",
      "Epoch 00200 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3861\n",
      "Epoch 00201 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3861\n",
      "Epoch 00202 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3861\n",
      "Epoch 00203 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3861\n",
      "Epoch 00204 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3861\n",
      "Epoch 00205 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3861\n",
      "Epoch 00206 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3861\n",
      "Epoch 00207 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3861\n",
      "Epoch 00208 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3861\n",
      "Epoch 00209 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3861\n",
      "Epoch 00210 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3860\n",
      "Epoch 00211 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3860\n",
      "Epoch 00212 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3860\n",
      "Epoch 00213 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3860\n",
      "Epoch 00214 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3860\n",
      "Epoch 00215 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3860\n",
      "Epoch 00216 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3860\n",
      "Epoch 00217 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3860\n",
      "Epoch 00218 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3860\n",
      "Epoch 00219 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3860\n",
      "Epoch 00220 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3860\n",
      "Epoch 00221 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3860\n",
      "Epoch 00222 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3860\n",
      "Epoch 00223 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3859\n",
      "Epoch 00224 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3859\n",
      "Epoch 00225 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3859\n",
      "Epoch 00226 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3859\n",
      "Epoch 00227 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3859\n",
      "Epoch 00228 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3859\n",
      "Epoch 00229 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3859\n",
      "Epoch 00230 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3859\n",
      "Epoch 00231 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3859\n",
      "Epoch 00232 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3859\n",
      "Epoch 00233 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3859\n",
      "Epoch 00234 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3859\n",
      "Epoch 00235 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3859\n",
      "Epoch 00236 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00237 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3859\n",
      "Epoch 00238 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3858\n",
      "Epoch 00239 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3858\n",
      "Epoch 00240 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3858\n",
      "Epoch 00241 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3858\n",
      "Epoch 00242 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3858\n",
      "Epoch 00243 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3858\n",
      "Epoch 00244 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3858\n",
      "Epoch 00245 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3858\n",
      "Epoch 00246 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3858\n",
      "Epoch 00247 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3858\n",
      "Epoch 00248 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3858\n",
      "Epoch 00249 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3858\n",
      "Epoch 00250 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3858\n",
      "Epoch 00251 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3858\n",
      "Epoch 00252 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3858\n",
      "Epoch 00253 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3858\n",
      "Epoch 00254 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3857\n",
      "Epoch 00255 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3857\n",
      "Epoch 00256 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3857\n",
      "Epoch 00257 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3857\n",
      "Epoch 00258 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3857\n",
      "Epoch 00259 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3857\n",
      "Epoch 00260 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3857\n",
      "Epoch 00261 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3857\n",
      "Epoch 00262 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3857\n",
      "Epoch 00263 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3857\n",
      "Epoch 00264 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3857\n",
      "Epoch 00265 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3857\n",
      "Epoch 00266 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3857\n",
      "Epoch 00267 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3857\n",
      "Epoch 00268 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3857\n",
      "Epoch 00269 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3857\n",
      "Epoch 00270 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3857\n",
      "Epoch 00271 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3856\n",
      "Epoch 00272 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3856\n",
      "Epoch 00273 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3856\n",
      "Epoch 00274 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3856\n",
      "Epoch 00275 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3856\n",
      "Epoch 00276 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3856\n",
      "Epoch 00277 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3856\n",
      "Epoch 00278 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3856\n",
      "Epoch 00279 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3856\n",
      "Epoch 00280 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3856\n",
      "Epoch 00281 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3856\n",
      "Epoch 00282 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3856\n",
      "Epoch 00283 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3856\n",
      "Epoch 00284 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3856\n",
      "Epoch 00285 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3856\n",
      "Epoch 00286 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3856\n",
      "Epoch 00287 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3856\n",
      "Epoch 00288 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3856\n",
      "Epoch 00289 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3856\n",
      "Epoch 00290 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3856\n",
      "Epoch 00291 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3856\n",
      "Epoch 00292 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3856\n",
      "Epoch 00293 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3855\n",
      "Epoch 00294 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3855\n",
      "Epoch 00295 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3855\n",
      "Epoch 00296 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3855\n",
      "Epoch 00297 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3855\n",
      "Epoch 00298 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3855\n",
      "Epoch 00299 | Train AUC: 0.8521 | Train Loss: 0.4189 | Validation AUC: 0.9200 | Validation loss: 0.3855\n",
      "==== Test Phase ====\n",
      "test auc : 0.8603896103896105\n",
      "=================\n",
      "Start 2-th fold\n",
      "==== Train Phase ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/dgl/frame.py:204: UserWarning: Initializer is not set. Use zero initializer instead. To suppress this warning, use `set_initializer` to explicitly specify which initializer to use.\n",
      "  dgl_warning('Initializer is not set. Use zero initializer instead.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000 | Train AUC: 0.8597 | Train Loss: 0.5450 | Validation AUC: 0.8960 | Validation loss: 0.5244\n",
      "Epoch 00001 | Train AUC: 0.3548 | Train Loss: 0.8558 | Validation AUC: 0.2556 | Validation loss: 0.8505\n",
      "Epoch 00002 | Train AUC: 0.4155 | Train Loss: 0.8273 | Validation AUC: 0.3081 | Validation loss: 0.8307\n",
      "Epoch 00003 | Train AUC: 0.4948 | Train Loss: 0.7705 | Validation AUC: 0.3718 | Validation loss: 0.7998\n",
      "Epoch 00004 | Train AUC: 0.8973 | Train Loss: 0.4714 | Validation AUC: 0.8250 | Validation loss: 0.5332\n",
      "Epoch 00005 | Train AUC: 0.8595 | Train Loss: 0.4559 | Validation AUC: 0.8992 | Validation loss: 0.4929\n",
      "Epoch 00006 | Train AUC: 0.8345 | Train Loss: 0.4833 | Validation AUC: 0.8952 | Validation loss: 0.5140\n",
      "Epoch 00007 | Train AUC: 0.8242 | Train Loss: 0.4876 | Validation AUC: 0.8867 | Validation loss: 0.5181\n",
      "Epoch 00008 | Train AUC: 0.8264 | Train Loss: 0.4886 | Validation AUC: 0.8758 | Validation loss: 0.5192\n",
      "Epoch 00009 | Train AUC: 0.8215 | Train Loss: 0.4887 | Validation AUC: 0.8790 | Validation loss: 0.5195\n",
      "Epoch 00010 | Train AUC: 0.8146 | Train Loss: 0.4875 | Validation AUC: 0.8790 | Validation loss: 0.5195\n",
      "Epoch 00011 | Train AUC: 0.8164 | Train Loss: 0.4855 | Validation AUC: 0.8798 | Validation loss: 0.5193\n",
      "Epoch 00012 | Train AUC: 0.8185 | Train Loss: 0.4841 | Validation AUC: 0.8694 | Validation loss: 0.5191\n",
      "Epoch 00013 | Train AUC: 0.8168 | Train Loss: 0.4834 | Validation AUC: 0.8694 | Validation loss: 0.5188\n",
      "Epoch 00014 | Train AUC: 0.8241 | Train Loss: 0.4831 | Validation AUC: 0.8694 | Validation loss: 0.5183\n",
      "Epoch 00015 | Train AUC: 0.8261 | Train Loss: 0.4828 | Validation AUC: 0.8702 | Validation loss: 0.5174\n",
      "Epoch 00016 | Train AUC: 0.8286 | Train Loss: 0.4808 | Validation AUC: 0.8734 | Validation loss: 0.5157\n",
      "Epoch 00017 | Train AUC: 0.8306 | Train Loss: 0.4723 | Validation AUC: 0.8766 | Validation loss: 0.5111\n",
      "Epoch 00018 | Train AUC: 0.8445 | Train Loss: 0.4670 | Validation AUC: 0.8782 | Validation loss: 0.4955\n",
      "Epoch 00019 | Train AUC: 0.8537 | Train Loss: 0.4524 | Validation AUC: 0.8827 | Validation loss: 0.4902\n",
      "Epoch 00020 | Train AUC: 0.8586 | Train Loss: 0.4376 | Validation AUC: 0.8984 | Validation loss: 0.4759\n",
      "Epoch 00021 | Train AUC: 0.8891 | Train Loss: 0.4260 | Validation AUC: 0.9121 | Validation loss: 0.4701\n",
      "Epoch 00022 | Train AUC: 0.9114 | Train Loss: 0.3925 | Validation AUC: 0.9157 | Validation loss: 0.4423\n",
      "Epoch 00023 | Train AUC: 0.8899 | Train Loss: 0.4302 | Validation AUC: 0.8665 | Validation loss: 0.4593\n",
      "Epoch 00024 | Train AUC: 0.8014 | Train Loss: 0.5443 | Validation AUC: 0.7746 | Validation loss: 0.6117\n",
      "Epoch 00025 | Train AUC: 0.8931 | Train Loss: 0.4301 | Validation AUC: 0.8734 | Validation loss: 0.4499\n",
      "Epoch 00026 | Train AUC: 0.9178 | Train Loss: 0.3919 | Validation AUC: 0.9105 | Validation loss: 0.4075\n",
      "Epoch 00027 | Train AUC: 0.9111 | Train Loss: 0.4044 | Validation AUC: 0.9210 | Validation loss: 0.4284\n",
      "Epoch 00028 | Train AUC: 0.9042 | Train Loss: 0.4176 | Validation AUC: 0.9040 | Validation loss: 0.4513\n",
      "Epoch 00029 | Train AUC: 0.8863 | Train Loss: 0.4189 | Validation AUC: 0.8903 | Validation loss: 0.4568\n",
      "Epoch 00030 | Train AUC: 0.8810 | Train Loss: 0.4189 | Validation AUC: 0.8923 | Validation loss: 0.4582\n",
      "Epoch 00031 | Train AUC: 0.8798 | Train Loss: 0.4259 | Validation AUC: 0.8915 | Validation loss: 0.4583\n",
      "Epoch 00032 | Train AUC: 0.8800 | Train Loss: 0.4259 | Validation AUC: 0.8927 | Validation loss: 0.4581\n",
      "Epoch 00033 | Train AUC: 0.8799 | Train Loss: 0.4324 | Validation AUC: 0.8919 | Validation loss: 0.4578\n",
      "Epoch 00034 | Train AUC: 0.8797 | Train Loss: 0.4328 | Validation AUC: 0.8940 | Validation loss: 0.4574\n",
      "Epoch 00035 | Train AUC: 0.8812 | Train Loss: 0.4320 | Validation AUC: 0.8940 | Validation loss: 0.4570\n",
      "Epoch 00036 | Train AUC: 0.8836 | Train Loss: 0.4259 | Validation AUC: 0.8948 | Validation loss: 0.4566\n",
      "Epoch 00037 | Train AUC: 0.8854 | Train Loss: 0.4189 | Validation AUC: 0.8956 | Validation loss: 0.4562\n",
      "Epoch 00038 | Train AUC: 0.8863 | Train Loss: 0.4189 | Validation AUC: 0.8956 | Validation loss: 0.4558\n",
      "Epoch 00039 | Train AUC: 0.8865 | Train Loss: 0.4189 | Validation AUC: 0.8944 | Validation loss: 0.4552\n",
      "Epoch 00040 | Train AUC: 0.8852 | Train Loss: 0.4189 | Validation AUC: 0.8944 | Validation loss: 0.4538\n",
      "Epoch 00041 | Train AUC: 0.8927 | Train Loss: 0.4188 | Validation AUC: 0.8952 | Validation loss: 0.4509\n",
      "Epoch 00042 | Train AUC: 0.8995 | Train Loss: 0.4128 | Validation AUC: 0.8960 | Validation loss: 0.4465\n",
      "Epoch 00043 | Train AUC: 0.9097 | Train Loss: 0.4048 | Validation AUC: 0.8968 | Validation loss: 0.4419\n",
      "Epoch 00044 | Train AUC: 0.9184 | Train Loss: 0.3980 | Validation AUC: 0.9105 | Validation loss: 0.4269\n",
      "Epoch 00045 | Train AUC: 0.9219 | Train Loss: 0.3924 | Validation AUC: 0.9137 | Validation loss: 0.4177\n",
      "Epoch 00046 | Train AUC: 0.9428 | Train Loss: 0.3557 | Validation AUC: 0.9202 | Validation loss: 0.3986\n",
      "Epoch 00047 | Train AUC: 0.9323 | Train Loss: 0.3724 | Validation AUC: 0.9230 | Validation loss: 0.3939\n",
      "Epoch 00048 | Train AUC: 0.9207 | Train Loss: 0.4108 | Validation AUC: 0.9161 | Validation loss: 0.4267\n",
      "Epoch 00049 | Train AUC: 0.9386 | Train Loss: 0.3695 | Validation AUC: 0.9254 | Validation loss: 0.3843\n",
      "Epoch 00050 | Train AUC: 0.9442 | Train Loss: 0.3557 | Validation AUC: 0.9266 | Validation loss: 0.3842\n",
      "Epoch 00051 | Train AUC: 0.9375 | Train Loss: 0.3626 | Validation AUC: 0.9379 | Validation loss: 0.3847\n",
      "Epoch 00052 | Train AUC: 0.9324 | Train Loss: 0.3831 | Validation AUC: 0.9347 | Validation loss: 0.4210\n",
      "Epoch 00053 | Train AUC: 0.9245 | Train Loss: 0.3907 | Validation AUC: 0.9331 | Validation loss: 0.4258\n",
      "Epoch 00054 | Train AUC: 0.9166 | Train Loss: 0.3907 | Validation AUC: 0.9315 | Validation loss: 0.4281\n",
      "Epoch 00055 | Train AUC: 0.9168 | Train Loss: 0.3907 | Validation AUC: 0.9290 | Validation loss: 0.4403\n",
      "Epoch 00056 | Train AUC: 0.9168 | Train Loss: 0.3907 | Validation AUC: 0.9161 | Validation loss: 0.4409\n",
      "Epoch 00057 | Train AUC: 0.9164 | Train Loss: 0.3922 | Validation AUC: 0.9153 | Validation loss: 0.4420\n",
      "Epoch 00058 | Train AUC: 0.9172 | Train Loss: 0.3907 | Validation AUC: 0.9169 | Validation loss: 0.4409\n",
      "Epoch 00059 | Train AUC: 0.9184 | Train Loss: 0.3907 | Validation AUC: 0.9306 | Validation loss: 0.4301\n",
      "Epoch 00060 | Train AUC: 0.9194 | Train Loss: 0.3907 | Validation AUC: 0.9323 | Validation loss: 0.4258\n",
      "Epoch 00061 | Train AUC: 0.9197 | Train Loss: 0.3907 | Validation AUC: 0.9331 | Validation loss: 0.4201\n",
      "Epoch 00062 | Train AUC: 0.9270 | Train Loss: 0.3791 | Validation AUC: 0.9339 | Validation loss: 0.4127\n",
      "Epoch 00063 | Train AUC: 0.9365 | Train Loss: 0.3696 | Validation AUC: 0.9403 | Validation loss: 0.3886\n",
      "Epoch 00064 | Train AUC: 0.9442 | Train Loss: 0.3623 | Validation AUC: 0.9286 | Validation loss: 0.3709\n",
      "Epoch 00065 | Train AUC: 0.9448 | Train Loss: 0.3533 | Validation AUC: 0.9278 | Validation loss: 0.3697\n",
      "Epoch 00066 | Train AUC: 0.9448 | Train Loss: 0.3508 | Validation AUC: 0.9278 | Validation loss: 0.3697\n",
      "Epoch 00067 | Train AUC: 0.9465 | Train Loss: 0.3600 | Validation AUC: 0.9290 | Validation loss: 0.3698\n",
      "Epoch 00068 | Train AUC: 0.9440 | Train Loss: 0.3626 | Validation AUC: 0.9383 | Validation loss: 0.3747\n",
      "Epoch 00069 | Train AUC: 0.9428 | Train Loss: 0.3626 | Validation AUC: 0.9399 | Validation loss: 0.3701\n",
      "Epoch 00070 | Train AUC: 0.9369 | Train Loss: 0.3696 | Validation AUC: 0.9399 | Validation loss: 0.3733\n",
      "Epoch 00071 | Train AUC: 0.9362 | Train Loss: 0.3696 | Validation AUC: 0.9391 | Validation loss: 0.3804\n",
      "Epoch 00072 | Train AUC: 0.9354 | Train Loss: 0.3696 | Validation AUC: 0.9391 | Validation loss: 0.3832\n",
      "Epoch 00073 | Train AUC: 0.9358 | Train Loss: 0.3696 | Validation AUC: 0.9391 | Validation loss: 0.3954\n",
      "Epoch 00074 | Train AUC: 0.9367 | Train Loss: 0.3696 | Validation AUC: 0.9367 | Validation loss: 0.3978\n",
      "Epoch 00075 | Train AUC: 0.9297 | Train Loss: 0.3696 | Validation AUC: 0.9367 | Validation loss: 0.3979\n",
      "Epoch 00076 | Train AUC: 0.9297 | Train Loss: 0.3696 | Validation AUC: 0.9359 | Validation loss: 0.4005\n",
      "Epoch 00077 | Train AUC: 0.9295 | Train Loss: 0.3696 | Validation AUC: 0.9359 | Validation loss: 0.4100\n",
      "Epoch 00078 | Train AUC: 0.9295 | Train Loss: 0.3696 | Validation AUC: 0.9359 | Validation loss: 0.4118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00079 | Train AUC: 0.9288 | Train Loss: 0.3696 | Validation AUC: 0.9343 | Validation loss: 0.4119\n",
      "Epoch 00080 | Train AUC: 0.9288 | Train Loss: 0.3696 | Validation AUC: 0.9335 | Validation loss: 0.4119\n",
      "Epoch 00081 | Train AUC: 0.9288 | Train Loss: 0.3696 | Validation AUC: 0.9327 | Validation loss: 0.4119\n",
      "Epoch 00082 | Train AUC: 0.9284 | Train Loss: 0.3696 | Validation AUC: 0.9302 | Validation loss: 0.4119\n",
      "Epoch 00083 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9302 | Validation loss: 0.4119\n",
      "Epoch 00084 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9315 | Validation loss: 0.4119\n",
      "Epoch 00085 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9315 | Validation loss: 0.4119\n",
      "Epoch 00086 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9306 | Validation loss: 0.4119\n",
      "Epoch 00087 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9177 | Validation loss: 0.4119\n",
      "Epoch 00088 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9177 | Validation loss: 0.4120\n",
      "Epoch 00089 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9169 | Validation loss: 0.4120\n",
      "Epoch 00090 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9169 | Validation loss: 0.4120\n",
      "Epoch 00091 | Train AUC: 0.9279 | Train Loss: 0.3697 | Validation AUC: 0.9169 | Validation loss: 0.4120\n",
      "Epoch 00092 | Train AUC: 0.9279 | Train Loss: 0.3697 | Validation AUC: 0.9169 | Validation loss: 0.4120\n",
      "Epoch 00093 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9169 | Validation loss: 0.4120\n",
      "Epoch 00094 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9169 | Validation loss: 0.4120\n",
      "Epoch 00095 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9306 | Validation loss: 0.4119\n",
      "Epoch 00096 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9298 | Validation loss: 0.4119\n",
      "Epoch 00097 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9169 | Validation loss: 0.4120\n",
      "Epoch 00098 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9169 | Validation loss: 0.4120\n",
      "Epoch 00099 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9169 | Validation loss: 0.4120\n",
      "Epoch 00100 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9169 | Validation loss: 0.4120\n",
      "Epoch 00101 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9169 | Validation loss: 0.4120\n",
      "Epoch 00102 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9169 | Validation loss: 0.4120\n",
      "Epoch 00103 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9169 | Validation loss: 0.4120\n",
      "Epoch 00104 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9298 | Validation loss: 0.4120\n",
      "Epoch 00105 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9298 | Validation loss: 0.4120\n",
      "Epoch 00106 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9298 | Validation loss: 0.4120\n",
      "Epoch 00107 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9298 | Validation loss: 0.4120\n",
      "Epoch 00108 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9298 | Validation loss: 0.4120\n",
      "Epoch 00109 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9298 | Validation loss: 0.4120\n",
      "Epoch 00110 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9298 | Validation loss: 0.4120\n",
      "Epoch 00111 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9298 | Validation loss: 0.4120\n",
      "Epoch 00112 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9302 | Validation loss: 0.4120\n",
      "Epoch 00113 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9306 | Validation loss: 0.4120\n",
      "Epoch 00114 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9306 | Validation loss: 0.4120\n",
      "Epoch 00115 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9306 | Validation loss: 0.4120\n",
      "Epoch 00116 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9306 | Validation loss: 0.4120\n",
      "Epoch 00117 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9306 | Validation loss: 0.4120\n",
      "Epoch 00118 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9306 | Validation loss: 0.4120\n",
      "Epoch 00119 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9306 | Validation loss: 0.4120\n",
      "Epoch 00120 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9306 | Validation loss: 0.4120\n",
      "Epoch 00121 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9306 | Validation loss: 0.4120\n",
      "Epoch 00122 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9306 | Validation loss: 0.4120\n",
      "Epoch 00123 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9306 | Validation loss: 0.4120\n",
      "Epoch 00124 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9306 | Validation loss: 0.4121\n",
      "Epoch 00125 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9306 | Validation loss: 0.4121\n",
      "Epoch 00126 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9306 | Validation loss: 0.4121\n",
      "Epoch 00127 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9306 | Validation loss: 0.4121\n",
      "Epoch 00128 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9306 | Validation loss: 0.4121\n",
      "Epoch 00129 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9306 | Validation loss: 0.4121\n",
      "Epoch 00130 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9306 | Validation loss: 0.4121\n",
      "Epoch 00131 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9298 | Validation loss: 0.4121\n",
      "Epoch 00132 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9298 | Validation loss: 0.4121\n",
      "Epoch 00133 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9298 | Validation loss: 0.4121\n",
      "Epoch 00134 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9298 | Validation loss: 0.4121\n",
      "Epoch 00135 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9298 | Validation loss: 0.4121\n",
      "Epoch 00136 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9298 | Validation loss: 0.4121\n",
      "Epoch 00137 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9298 | Validation loss: 0.4122\n",
      "Epoch 00138 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9298 | Validation loss: 0.4122\n",
      "Epoch 00139 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9298 | Validation loss: 0.4122\n",
      "Epoch 00140 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9298 | Validation loss: 0.4122\n",
      "Epoch 00141 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9298 | Validation loss: 0.4122\n",
      "Epoch 00142 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9298 | Validation loss: 0.4122\n",
      "Epoch 00143 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9298 | Validation loss: 0.4122\n",
      "Epoch 00144 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9298 | Validation loss: 0.4122\n",
      "Epoch 00145 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9298 | Validation loss: 0.4123\n",
      "Epoch 00146 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9298 | Validation loss: 0.4123\n",
      "Epoch 00147 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9298 | Validation loss: 0.4123\n",
      "Epoch 00148 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9298 | Validation loss: 0.4123\n",
      "Epoch 00149 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9298 | Validation loss: 0.4123\n",
      "Epoch 00150 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9298 | Validation loss: 0.4123\n",
      "Epoch 00151 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9298 | Validation loss: 0.4124\n",
      "Epoch 00152 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9298 | Validation loss: 0.4124\n",
      "Epoch 00153 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9298 | Validation loss: 0.4124\n",
      "Epoch 00154 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9298 | Validation loss: 0.4124\n",
      "Epoch 00155 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9298 | Validation loss: 0.4124\n",
      "Epoch 00156 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9298 | Validation loss: 0.4125\n",
      "Epoch 00157 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9298 | Validation loss: 0.4125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00158 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9298 | Validation loss: 0.4125\n",
      "Epoch 00159 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9298 | Validation loss: 0.4125\n",
      "Epoch 00160 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9298 | Validation loss: 0.4126\n",
      "Epoch 00161 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9298 | Validation loss: 0.4126\n",
      "Epoch 00162 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9298 | Validation loss: 0.4126\n",
      "Epoch 00163 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9298 | Validation loss: 0.4127\n",
      "Epoch 00164 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9298 | Validation loss: 0.4127\n",
      "Epoch 00165 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9298 | Validation loss: 0.4127\n",
      "Epoch 00166 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9298 | Validation loss: 0.4128\n",
      "Epoch 00167 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9298 | Validation loss: 0.4128\n",
      "Epoch 00168 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9298 | Validation loss: 0.4128\n",
      "Epoch 00169 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9298 | Validation loss: 0.4129\n",
      "Epoch 00170 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9298 | Validation loss: 0.4129\n",
      "Epoch 00171 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9298 | Validation loss: 0.4130\n",
      "Epoch 00172 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9298 | Validation loss: 0.4130\n",
      "Epoch 00173 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9298 | Validation loss: 0.4130\n",
      "Epoch 00174 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9298 | Validation loss: 0.4131\n",
      "Epoch 00175 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9298 | Validation loss: 0.4131\n",
      "Epoch 00176 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9298 | Validation loss: 0.4132\n",
      "Epoch 00177 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9298 | Validation loss: 0.4132\n",
      "Epoch 00178 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9298 | Validation loss: 0.4133\n",
      "Epoch 00179 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9286 | Validation loss: 0.4133\n",
      "Epoch 00180 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9286 | Validation loss: 0.4133\n",
      "Epoch 00181 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9286 | Validation loss: 0.4134\n",
      "Epoch 00182 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9286 | Validation loss: 0.4134\n",
      "Epoch 00183 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9286 | Validation loss: 0.4134\n",
      "Epoch 00184 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9286 | Validation loss: 0.4135\n",
      "Epoch 00185 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9286 | Validation loss: 0.4135\n",
      "Epoch 00186 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9286 | Validation loss: 0.4135\n",
      "Epoch 00187 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9286 | Validation loss: 0.4135\n",
      "Epoch 00188 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9286 | Validation loss: 0.4135\n",
      "Epoch 00189 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9286 | Validation loss: 0.4135\n",
      "Epoch 00190 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9294 | Validation loss: 0.4136\n",
      "Epoch 00191 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9294 | Validation loss: 0.4136\n",
      "Epoch 00192 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9294 | Validation loss: 0.4136\n",
      "Epoch 00193 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9294 | Validation loss: 0.4136\n",
      "Epoch 00194 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9294 | Validation loss: 0.4137\n",
      "Epoch 00195 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9294 | Validation loss: 0.4137\n",
      "Epoch 00196 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9294 | Validation loss: 0.4138\n",
      "Epoch 00197 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9294 | Validation loss: 0.4139\n",
      "Epoch 00198 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9294 | Validation loss: 0.4139\n",
      "Epoch 00199 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9294 | Validation loss: 0.4140\n",
      "Epoch 00200 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9294 | Validation loss: 0.4141\n",
      "Epoch 00201 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9294 | Validation loss: 0.4141\n",
      "Epoch 00202 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9294 | Validation loss: 0.4142\n",
      "Epoch 00203 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9294 | Validation loss: 0.4143\n",
      "Epoch 00204 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9294 | Validation loss: 0.4144\n",
      "Epoch 00205 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9294 | Validation loss: 0.4144\n",
      "Epoch 00206 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9294 | Validation loss: 0.4145\n",
      "Epoch 00207 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9294 | Validation loss: 0.4146\n",
      "Epoch 00208 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9294 | Validation loss: 0.4146\n",
      "Epoch 00209 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9294 | Validation loss: 0.4147\n",
      "Epoch 00210 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9294 | Validation loss: 0.4148\n",
      "Epoch 00211 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9294 | Validation loss: 0.4149\n",
      "Epoch 00212 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9282 | Validation loss: 0.4149\n",
      "Epoch 00213 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9282 | Validation loss: 0.4150\n",
      "Epoch 00214 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9282 | Validation loss: 0.4151\n",
      "Epoch 00215 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9282 | Validation loss: 0.4151\n",
      "Epoch 00216 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9282 | Validation loss: 0.4152\n",
      "Epoch 00217 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9282 | Validation loss: 0.4153\n",
      "Epoch 00218 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9282 | Validation loss: 0.4154\n",
      "Epoch 00219 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9282 | Validation loss: 0.4154\n",
      "Epoch 00220 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9282 | Validation loss: 0.4155\n",
      "Epoch 00221 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9282 | Validation loss: 0.4157\n",
      "Epoch 00222 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9282 | Validation loss: 0.4158\n",
      "Epoch 00223 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9282 | Validation loss: 0.4159\n",
      "Epoch 00224 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9282 | Validation loss: 0.4160\n",
      "Epoch 00225 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9282 | Validation loss: 0.4161\n",
      "Epoch 00226 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9282 | Validation loss: 0.4162\n",
      "Epoch 00227 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9282 | Validation loss: 0.4163\n",
      "Epoch 00228 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9282 | Validation loss: 0.4163\n",
      "Epoch 00229 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9282 | Validation loss: 0.4164\n",
      "Epoch 00230 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9282 | Validation loss: 0.4165\n",
      "Epoch 00231 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9282 | Validation loss: 0.4166\n",
      "Epoch 00232 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9282 | Validation loss: 0.4167\n",
      "Epoch 00233 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9282 | Validation loss: 0.4168\n",
      "Epoch 00234 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9282 | Validation loss: 0.4169\n",
      "Epoch 00235 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9282 | Validation loss: 0.4170\n",
      "Epoch 00236 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9282 | Validation loss: 0.4172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00237 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9282 | Validation loss: 0.4173\n",
      "Epoch 00238 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9282 | Validation loss: 0.4174\n",
      "Epoch 00239 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9282 | Validation loss: 0.4175\n",
      "Epoch 00240 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9282 | Validation loss: 0.4176\n",
      "Epoch 00241 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9282 | Validation loss: 0.4177\n",
      "Epoch 00242 | Train AUC: 0.9279 | Train Loss: 0.3696 | Validation AUC: 0.9282 | Validation loss: 0.4178\n",
      "Epoch 00243 | Train AUC: 0.9272 | Train Loss: 0.3696 | Validation AUC: 0.9282 | Validation loss: 0.4179\n",
      "Epoch 00244 | Train AUC: 0.9272 | Train Loss: 0.3696 | Validation AUC: 0.9282 | Validation loss: 0.4181\n",
      "Epoch 00245 | Train AUC: 0.9272 | Train Loss: 0.3696 | Validation AUC: 0.9282 | Validation loss: 0.4182\n",
      "Epoch 00246 | Train AUC: 0.9272 | Train Loss: 0.3696 | Validation AUC: 0.9282 | Validation loss: 0.4183\n",
      "Epoch 00247 | Train AUC: 0.9272 | Train Loss: 0.3696 | Validation AUC: 0.9282 | Validation loss: 0.4184\n",
      "Epoch 00248 | Train AUC: 0.9272 | Train Loss: 0.3696 | Validation AUC: 0.9282 | Validation loss: 0.4185\n",
      "Epoch 00249 | Train AUC: 0.9272 | Train Loss: 0.3696 | Validation AUC: 0.9282 | Validation loss: 0.4186\n",
      "Epoch 00250 | Train AUC: 0.9272 | Train Loss: 0.3696 | Validation AUC: 0.9282 | Validation loss: 0.4187\n",
      "Epoch 00251 | Train AUC: 0.9272 | Train Loss: 0.3696 | Validation AUC: 0.9282 | Validation loss: 0.4188\n",
      "Epoch 00252 | Train AUC: 0.9272 | Train Loss: 0.3696 | Validation AUC: 0.9282 | Validation loss: 0.4190\n",
      "Epoch 00253 | Train AUC: 0.9272 | Train Loss: 0.3696 | Validation AUC: 0.9282 | Validation loss: 0.4191\n",
      "Epoch 00254 | Train AUC: 0.9272 | Train Loss: 0.3696 | Validation AUC: 0.9274 | Validation loss: 0.4192\n",
      "Epoch 00255 | Train AUC: 0.9272 | Train Loss: 0.3696 | Validation AUC: 0.9274 | Validation loss: 0.4193\n",
      "Epoch 00256 | Train AUC: 0.9272 | Train Loss: 0.3696 | Validation AUC: 0.9274 | Validation loss: 0.4194\n",
      "Epoch 00257 | Train AUC: 0.9272 | Train Loss: 0.3696 | Validation AUC: 0.9274 | Validation loss: 0.4195\n",
      "Epoch 00258 | Train AUC: 0.9272 | Train Loss: 0.3696 | Validation AUC: 0.9274 | Validation loss: 0.4196\n",
      "Epoch 00259 | Train AUC: 0.9272 | Train Loss: 0.3696 | Validation AUC: 0.9274 | Validation loss: 0.4198\n",
      "Epoch 00260 | Train AUC: 0.9272 | Train Loss: 0.3696 | Validation AUC: 0.9274 | Validation loss: 0.4199\n",
      "Epoch 00261 | Train AUC: 0.9272 | Train Loss: 0.3696 | Validation AUC: 0.9274 | Validation loss: 0.4200\n",
      "Epoch 00262 | Train AUC: 0.9272 | Train Loss: 0.3696 | Validation AUC: 0.9274 | Validation loss: 0.4201\n",
      "Epoch 00263 | Train AUC: 0.9272 | Train Loss: 0.3696 | Validation AUC: 0.9274 | Validation loss: 0.4202\n",
      "Epoch 00264 | Train AUC: 0.9272 | Train Loss: 0.3696 | Validation AUC: 0.9274 | Validation loss: 0.4203\n",
      "Epoch 00265 | Train AUC: 0.9272 | Train Loss: 0.3696 | Validation AUC: 0.9274 | Validation loss: 0.4204\n",
      "Epoch 00266 | Train AUC: 0.9272 | Train Loss: 0.3696 | Validation AUC: 0.9274 | Validation loss: 0.4205\n",
      "Epoch 00267 | Train AUC: 0.9272 | Train Loss: 0.3696 | Validation AUC: 0.9274 | Validation loss: 0.4206\n",
      "Epoch 00268 | Train AUC: 0.9272 | Train Loss: 0.3696 | Validation AUC: 0.9274 | Validation loss: 0.4208\n",
      "Epoch 00269 | Train AUC: 0.9272 | Train Loss: 0.3696 | Validation AUC: 0.9274 | Validation loss: 0.4209\n",
      "Epoch 00270 | Train AUC: 0.9272 | Train Loss: 0.3696 | Validation AUC: 0.9274 | Validation loss: 0.4210\n",
      "Epoch 00271 | Train AUC: 0.9272 | Train Loss: 0.3696 | Validation AUC: 0.9274 | Validation loss: 0.4211\n",
      "Epoch 00272 | Train AUC: 0.9272 | Train Loss: 0.3696 | Validation AUC: 0.9274 | Validation loss: 0.4212\n",
      "Epoch 00273 | Train AUC: 0.9272 | Train Loss: 0.3696 | Validation AUC: 0.9274 | Validation loss: 0.4213\n",
      "Epoch 00274 | Train AUC: 0.9272 | Train Loss: 0.3696 | Validation AUC: 0.9274 | Validation loss: 0.4214\n",
      "Epoch 00275 | Train AUC: 0.9272 | Train Loss: 0.3696 | Validation AUC: 0.9274 | Validation loss: 0.4215\n",
      "Epoch 00276 | Train AUC: 0.9272 | Train Loss: 0.3696 | Validation AUC: 0.9274 | Validation loss: 0.4216\n",
      "Epoch 00277 | Train AUC: 0.9272 | Train Loss: 0.3696 | Validation AUC: 0.9274 | Validation loss: 0.4217\n",
      "Epoch 00278 | Train AUC: 0.9272 | Train Loss: 0.3696 | Validation AUC: 0.9274 | Validation loss: 0.4218\n",
      "Epoch 00279 | Train AUC: 0.9272 | Train Loss: 0.3696 | Validation AUC: 0.9274 | Validation loss: 0.4219\n",
      "Epoch 00280 | Train AUC: 0.9272 | Train Loss: 0.3696 | Validation AUC: 0.9274 | Validation loss: 0.4220\n",
      "Epoch 00281 | Train AUC: 0.9272 | Train Loss: 0.3696 | Validation AUC: 0.9274 | Validation loss: 0.4221\n",
      "Epoch 00282 | Train AUC: 0.9272 | Train Loss: 0.3696 | Validation AUC: 0.9274 | Validation loss: 0.4222\n",
      "Epoch 00283 | Train AUC: 0.9272 | Train Loss: 0.3696 | Validation AUC: 0.9274 | Validation loss: 0.4223\n",
      "Epoch 00284 | Train AUC: 0.9272 | Train Loss: 0.3696 | Validation AUC: 0.9274 | Validation loss: 0.4224\n",
      "Epoch 00285 | Train AUC: 0.9272 | Train Loss: 0.3696 | Validation AUC: 0.9274 | Validation loss: 0.4225\n",
      "Epoch 00286 | Train AUC: 0.9272 | Train Loss: 0.3696 | Validation AUC: 0.9274 | Validation loss: 0.4226\n",
      "Epoch 00287 | Train AUC: 0.9272 | Train Loss: 0.3696 | Validation AUC: 0.9274 | Validation loss: 0.4226\n",
      "Epoch 00288 | Train AUC: 0.9272 | Train Loss: 0.3696 | Validation AUC: 0.9274 | Validation loss: 0.4227\n",
      "Epoch 00289 | Train AUC: 0.9272 | Train Loss: 0.3696 | Validation AUC: 0.9274 | Validation loss: 0.4228\n",
      "Epoch 00290 | Train AUC: 0.9272 | Train Loss: 0.3696 | Validation AUC: 0.9274 | Validation loss: 0.4229\n",
      "Epoch 00291 | Train AUC: 0.9272 | Train Loss: 0.3696 | Validation AUC: 0.9274 | Validation loss: 0.4230\n",
      "Epoch 00292 | Train AUC: 0.9272 | Train Loss: 0.3696 | Validation AUC: 0.9274 | Validation loss: 0.4231\n",
      "Epoch 00293 | Train AUC: 0.9272 | Train Loss: 0.3696 | Validation AUC: 0.9274 | Validation loss: 0.4232\n",
      "Epoch 00294 | Train AUC: 0.9272 | Train Loss: 0.3696 | Validation AUC: 0.9274 | Validation loss: 0.4232\n",
      "Epoch 00295 | Train AUC: 0.9272 | Train Loss: 0.3696 | Validation AUC: 0.9274 | Validation loss: 0.4233\n",
      "Epoch 00296 | Train AUC: 0.9272 | Train Loss: 0.3696 | Validation AUC: 0.9274 | Validation loss: 0.4234\n",
      "Epoch 00297 | Train AUC: 0.9272 | Train Loss: 0.3696 | Validation AUC: 0.9274 | Validation loss: 0.4235\n",
      "Epoch 00298 | Train AUC: 0.9272 | Train Loss: 0.3696 | Validation AUC: 0.9274 | Validation loss: 0.4236\n",
      "Epoch 00299 | Train AUC: 0.9272 | Train Loss: 0.3696 | Validation AUC: 0.9274 | Validation loss: 0.4236\n",
      "==== Test Phase ====\n",
      "test auc : 0.9785714285714285\n",
      "=================\n",
      "Start 3-th fold\n",
      "==== Train Phase ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/dgl/frame.py:204: UserWarning: Initializer is not set. Use zero initializer instead. To suppress this warning, use `set_initializer` to explicitly specify which initializer to use.\n",
      "  dgl_warning('Initializer is not set. Use zero initializer instead.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000 | Train AUC: 0.8053 | Train Loss: 0.5671 | Validation AUC: 0.8460 | Validation loss: 0.5231\n",
      "Epoch 00001 | Train AUC: 0.8436 | Train Loss: 0.5499 | Validation AUC: 0.8520 | Validation loss: 0.5393\n",
      "Epoch 00002 | Train AUC: 0.8545 | Train Loss: 0.5274 | Validation AUC: 0.8609 | Validation loss: 0.5238\n",
      "Epoch 00003 | Train AUC: 0.8636 | Train Loss: 0.5116 | Validation AUC: 0.8560 | Validation loss: 0.5137\n",
      "Epoch 00004 | Train AUC: 0.8723 | Train Loss: 0.5004 | Validation AUC: 0.8669 | Validation loss: 0.4991\n",
      "Epoch 00005 | Train AUC: 0.8877 | Train Loss: 0.4824 | Validation AUC: 0.8831 | Validation loss: 0.4632\n",
      "Epoch 00006 | Train AUC: 0.9132 | Train Loss: 0.4710 | Validation AUC: 0.9008 | Validation loss: 0.4195\n",
      "Epoch 00007 | Train AUC: 0.9569 | Train Loss: 0.3972 | Validation AUC: 0.9460 | Validation loss: 0.3920\n",
      "Epoch 00008 | Train AUC: 0.6589 | Train Loss: 0.6891 | Validation AUC: 0.6190 | Validation loss: 0.7251\n",
      "Epoch 00009 | Train AUC: 0.5872 | Train Loss: 0.7287 | Validation AUC: 0.5315 | Validation loss: 0.7858\n",
      "Epoch 00010 | Train AUC: 0.6070 | Train Loss: 0.7106 | Validation AUC: 0.5609 | Validation loss: 0.7634\n",
      "Epoch 00011 | Train AUC: 0.6987 | Train Loss: 0.6646 | Validation AUC: 0.7056 | Validation loss: 0.6677\n",
      "Epoch 00012 | Train AUC: 0.9684 | Train Loss: 0.3714 | Validation AUC: 0.9589 | Validation loss: 0.3600\n",
      "Epoch 00013 | Train AUC: 0.9389 | Train Loss: 0.4285 | Validation AUC: 0.9032 | Validation loss: 0.4091\n",
      "Epoch 00014 | Train AUC: 0.9027 | Train Loss: 0.4505 | Validation AUC: 0.8879 | Validation loss: 0.4300\n",
      "Epoch 00015 | Train AUC: 0.8965 | Train Loss: 0.4553 | Validation AUC: 0.8778 | Validation loss: 0.4692\n",
      "Epoch 00016 | Train AUC: 0.8827 | Train Loss: 0.4580 | Validation AUC: 0.8810 | Validation loss: 0.4766\n",
      "Epoch 00017 | Train AUC: 0.8678 | Train Loss: 0.4628 | Validation AUC: 0.8823 | Validation loss: 0.4805\n",
      "Epoch 00018 | Train AUC: 0.8674 | Train Loss: 0.4652 | Validation AUC: 0.8843 | Validation loss: 0.4813\n",
      "Epoch 00019 | Train AUC: 0.8631 | Train Loss: 0.4642 | Validation AUC: 0.8863 | Validation loss: 0.4811\n",
      "Epoch 00020 | Train AUC: 0.8629 | Train Loss: 0.4604 | Validation AUC: 0.8883 | Validation loss: 0.4789\n",
      "Epoch 00021 | Train AUC: 0.8636 | Train Loss: 0.4594 | Validation AUC: 0.8883 | Validation loss: 0.4741\n",
      "Epoch 00022 | Train AUC: 0.8583 | Train Loss: 0.4589 | Validation AUC: 0.8883 | Validation loss: 0.4717\n",
      "Epoch 00023 | Train AUC: 0.8591 | Train Loss: 0.4583 | Validation AUC: 0.8923 | Validation loss: 0.4700\n",
      "Epoch 00024 | Train AUC: 0.8591 | Train Loss: 0.4575 | Validation AUC: 0.8923 | Validation loss: 0.4690\n",
      "Epoch 00025 | Train AUC: 0.8608 | Train Loss: 0.4563 | Validation AUC: 0.8944 | Validation loss: 0.4685\n",
      "Epoch 00026 | Train AUC: 0.8610 | Train Loss: 0.4540 | Validation AUC: 0.8944 | Validation loss: 0.4683\n",
      "Epoch 00027 | Train AUC: 0.8616 | Train Loss: 0.4500 | Validation AUC: 0.8964 | Validation loss: 0.4682\n",
      "Epoch 00028 | Train AUC: 0.8638 | Train Loss: 0.4480 | Validation AUC: 0.8980 | Validation loss: 0.4675\n",
      "Epoch 00029 | Train AUC: 0.8644 | Train Loss: 0.4475 | Validation AUC: 0.9008 | Validation loss: 0.4581\n",
      "Epoch 00030 | Train AUC: 0.8652 | Train Loss: 0.4473 | Validation AUC: 0.9016 | Validation loss: 0.4413\n",
      "Epoch 00031 | Train AUC: 0.8652 | Train Loss: 0.4472 | Validation AUC: 0.9024 | Validation loss: 0.4373\n",
      "Epoch 00032 | Train AUC: 0.8662 | Train Loss: 0.4472 | Validation AUC: 0.9024 | Validation loss: 0.4197\n",
      "Epoch 00033 | Train AUC: 0.8796 | Train Loss: 0.4472 | Validation AUC: 0.9004 | Validation loss: 0.4124\n",
      "Epoch 00034 | Train AUC: 0.8818 | Train Loss: 0.4472 | Validation AUC: 0.8984 | Validation loss: 0.4119\n",
      "Epoch 00035 | Train AUC: 0.8832 | Train Loss: 0.4471 | Validation AUC: 0.8984 | Validation loss: 0.4119\n",
      "Epoch 00036 | Train AUC: 0.8964 | Train Loss: 0.4471 | Validation AUC: 0.8984 | Validation loss: 0.4119\n",
      "Epoch 00037 | Train AUC: 0.8984 | Train Loss: 0.4471 | Validation AUC: 0.8992 | Validation loss: 0.4119\n",
      "Epoch 00038 | Train AUC: 0.9002 | Train Loss: 0.4471 | Validation AUC: 0.8992 | Validation loss: 0.4119\n",
      "Epoch 00039 | Train AUC: 0.9008 | Train Loss: 0.4471 | Validation AUC: 0.8992 | Validation loss: 0.4119\n",
      "Epoch 00040 | Train AUC: 0.9081 | Train Loss: 0.4470 | Validation AUC: 0.8992 | Validation loss: 0.4119\n",
      "Epoch 00041 | Train AUC: 0.9109 | Train Loss: 0.4408 | Validation AUC: 0.8992 | Validation loss: 0.4119\n",
      "Epoch 00042 | Train AUC: 0.9227 | Train Loss: 0.4260 | Validation AUC: 0.8956 | Validation loss: 0.4118\n",
      "Epoch 00043 | Train AUC: 0.9393 | Train Loss: 0.4119 | Validation AUC: 0.8883 | Validation loss: 0.4114\n",
      "Epoch 00044 | Train AUC: 0.9516 | Train Loss: 0.3919 | Validation AUC: 0.9032 | Validation loss: 0.4059\n",
      "Epoch 00045 | Train AUC: 0.9626 | Train Loss: 0.3632 | Validation AUC: 0.9278 | Validation loss: 0.3703\n",
      "Epoch 00046 | Train AUC: 0.9656 | Train Loss: 0.3582 | Validation AUC: 0.9593 | Validation loss: 0.3561\n",
      "Epoch 00047 | Train AUC: 0.9263 | Train Loss: 0.3937 | Validation AUC: 0.9601 | Validation loss: 0.3755\n",
      "Epoch 00048 | Train AUC: 0.9616 | Train Loss: 0.3704 | Validation AUC: 0.9629 | Validation loss: 0.3555\n",
      "Epoch 00049 | Train AUC: 0.9662 | Train Loss: 0.3557 | Validation AUC: 0.9585 | Validation loss: 0.3555\n",
      "Epoch 00050 | Train AUC: 0.9646 | Train Loss: 0.3559 | Validation AUC: 0.9411 | Validation loss: 0.3556\n",
      "Epoch 00051 | Train AUC: 0.9622 | Train Loss: 0.3566 | Validation AUC: 0.9298 | Validation loss: 0.3698\n",
      "Epoch 00052 | Train AUC: 0.9605 | Train Loss: 0.3625 | Validation AUC: 0.9302 | Validation loss: 0.3702\n",
      "Epoch 00053 | Train AUC: 0.9605 | Train Loss: 0.3631 | Validation AUC: 0.9294 | Validation loss: 0.3705\n",
      "Epoch 00054 | Train AUC: 0.9597 | Train Loss: 0.3630 | Validation AUC: 0.9294 | Validation loss: 0.3709\n",
      "Epoch 00055 | Train AUC: 0.9591 | Train Loss: 0.3642 | Validation AUC: 0.9294 | Validation loss: 0.3711\n",
      "Epoch 00056 | Train AUC: 0.9601 | Train Loss: 0.3625 | Validation AUC: 0.9294 | Validation loss: 0.3704\n",
      "Epoch 00057 | Train AUC: 0.9603 | Train Loss: 0.3615 | Validation AUC: 0.9302 | Validation loss: 0.3701\n",
      "Epoch 00058 | Train AUC: 0.9605 | Train Loss: 0.3564 | Validation AUC: 0.9310 | Validation loss: 0.3698\n",
      "Epoch 00059 | Train AUC: 0.9622 | Train Loss: 0.3556 | Validation AUC: 0.9395 | Validation loss: 0.3556\n",
      "Epoch 00060 | Train AUC: 0.9628 | Train Loss: 0.3558 | Validation AUC: 0.9496 | Validation loss: 0.3556\n",
      "Epoch 00061 | Train AUC: 0.9648 | Train Loss: 0.3563 | Validation AUC: 0.9552 | Validation loss: 0.3555\n",
      "Epoch 00062 | Train AUC: 0.9658 | Train Loss: 0.3511 | Validation AUC: 0.9589 | Validation loss: 0.3555\n",
      "Epoch 00063 | Train AUC: 0.9656 | Train Loss: 0.3522 | Validation AUC: 0.9577 | Validation loss: 0.3555\n",
      "Epoch 00064 | Train AUC: 0.9644 | Train Loss: 0.3626 | Validation AUC: 0.9694 | Validation loss: 0.3414\n",
      "Epoch 00065 | Train AUC: 0.9591 | Train Loss: 0.3592 | Validation AUC: 0.9742 | Validation loss: 0.3522\n",
      "Epoch 00066 | Train AUC: 0.9524 | Train Loss: 0.3734 | Validation AUC: 0.9734 | Validation loss: 0.3555\n",
      "Epoch 00067 | Train AUC: 0.9520 | Train Loss: 0.3733 | Validation AUC: 0.9730 | Validation loss: 0.3555\n",
      "Epoch 00068 | Train AUC: 0.9522 | Train Loss: 0.3709 | Validation AUC: 0.9750 | Validation loss: 0.3555\n",
      "Epoch 00069 | Train AUC: 0.9569 | Train Loss: 0.3558 | Validation AUC: 0.9742 | Validation loss: 0.3535\n",
      "Epoch 00070 | Train AUC: 0.9627 | Train Loss: 0.3576 | Validation AUC: 0.9742 | Validation loss: 0.3415\n",
      "Epoch 00071 | Train AUC: 0.9681 | Train Loss: 0.3584 | Validation AUC: 0.9742 | Validation loss: 0.3414\n",
      "Epoch 00072 | Train AUC: 0.9630 | Train Loss: 0.3566 | Validation AUC: 0.9742 | Validation loss: 0.3415\n",
      "Epoch 00073 | Train AUC: 0.9626 | Train Loss: 0.3545 | Validation AUC: 0.9742 | Validation loss: 0.3429\n",
      "Epoch 00074 | Train AUC: 0.9584 | Train Loss: 0.3584 | Validation AUC: 0.9750 | Validation loss: 0.3520\n",
      "Epoch 00075 | Train AUC: 0.9520 | Train Loss: 0.3629 | Validation AUC: 0.9621 | Validation loss: 0.3555\n",
      "Epoch 00076 | Train AUC: 0.9522 | Train Loss: 0.3591 | Validation AUC: 0.9746 | Validation loss: 0.3555\n",
      "Epoch 00077 | Train AUC: 0.9628 | Train Loss: 0.3514 | Validation AUC: 0.9742 | Validation loss: 0.3415\n",
      "Epoch 00078 | Train AUC: 0.9691 | Train Loss: 0.3537 | Validation AUC: 0.9742 | Validation loss: 0.3414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00079 | Train AUC: 0.9658 | Train Loss: 0.3498 | Validation AUC: 0.9734 | Validation loss: 0.3414\n",
      "Epoch 00080 | Train AUC: 0.9678 | Train Loss: 0.3538 | Validation AUC: 0.9685 | Validation loss: 0.3526\n",
      "Epoch 00081 | Train AUC: 0.9682 | Train Loss: 0.3484 | Validation AUC: 0.9649 | Validation loss: 0.3555\n",
      "Epoch 00082 | Train AUC: 0.9690 | Train Loss: 0.3485 | Validation AUC: 0.9565 | Validation loss: 0.3555\n",
      "Epoch 00083 | Train AUC: 0.9688 | Train Loss: 0.3555 | Validation AUC: 0.9444 | Validation loss: 0.3555\n",
      "Epoch 00084 | Train AUC: 0.9674 | Train Loss: 0.3556 | Validation AUC: 0.9403 | Validation loss: 0.3555\n",
      "Epoch 00085 | Train AUC: 0.9666 | Train Loss: 0.3557 | Validation AUC: 0.9310 | Validation loss: 0.3555\n",
      "Epoch 00086 | Train AUC: 0.9658 | Train Loss: 0.3559 | Validation AUC: 0.9310 | Validation loss: 0.3685\n",
      "Epoch 00087 | Train AUC: 0.9654 | Train Loss: 0.3564 | Validation AUC: 0.9302 | Validation loss: 0.3696\n",
      "Epoch 00088 | Train AUC: 0.9656 | Train Loss: 0.3560 | Validation AUC: 0.9310 | Validation loss: 0.3696\n",
      "Epoch 00089 | Train AUC: 0.9664 | Train Loss: 0.3557 | Validation AUC: 0.9310 | Validation loss: 0.3582\n",
      "Epoch 00090 | Train AUC: 0.9684 | Train Loss: 0.3556 | Validation AUC: 0.9403 | Validation loss: 0.3555\n",
      "Epoch 00091 | Train AUC: 0.9698 | Train Loss: 0.3555 | Validation AUC: 0.9444 | Validation loss: 0.3555\n",
      "Epoch 00092 | Train AUC: 0.9698 | Train Loss: 0.3471 | Validation AUC: 0.9621 | Validation loss: 0.3555\n",
      "Epoch 00093 | Train AUC: 0.9684 | Train Loss: 0.3421 | Validation AUC: 0.9669 | Validation loss: 0.3414\n",
      "Epoch 00094 | Train AUC: 0.9641 | Train Loss: 0.3417 | Validation AUC: 0.9738 | Validation loss: 0.3414\n",
      "Epoch 00095 | Train AUC: 0.9566 | Train Loss: 0.3675 | Validation AUC: 0.9621 | Validation loss: 0.3555\n",
      "Epoch 00096 | Train AUC: 0.9641 | Train Loss: 0.3417 | Validation AUC: 0.9738 | Validation loss: 0.3414\n",
      "Epoch 00097 | Train AUC: 0.9674 | Train Loss: 0.3416 | Validation AUC: 0.9677 | Validation loss: 0.3414\n",
      "Epoch 00098 | Train AUC: 0.9692 | Train Loss: 0.3382 | Validation AUC: 0.9641 | Validation loss: 0.3555\n",
      "Epoch 00099 | Train AUC: 0.9700 | Train Loss: 0.3474 | Validation AUC: 0.9476 | Validation loss: 0.3555\n",
      "Epoch 00100 | Train AUC: 0.9698 | Train Loss: 0.3553 | Validation AUC: 0.9435 | Validation loss: 0.3555\n",
      "Epoch 00101 | Train AUC: 0.9686 | Train Loss: 0.3555 | Validation AUC: 0.9310 | Validation loss: 0.3555\n",
      "Epoch 00102 | Train AUC: 0.9674 | Train Loss: 0.3555 | Validation AUC: 0.9310 | Validation loss: 0.3629\n",
      "Epoch 00103 | Train AUC: 0.9618 | Train Loss: 0.3555 | Validation AUC: 0.9323 | Validation loss: 0.3696\n",
      "Epoch 00104 | Train AUC: 0.9610 | Train Loss: 0.3556 | Validation AUC: 0.9315 | Validation loss: 0.3696\n",
      "Epoch 00105 | Train AUC: 0.9609 | Train Loss: 0.3557 | Validation AUC: 0.9327 | Validation loss: 0.3696\n",
      "Epoch 00106 | Train AUC: 0.9609 | Train Loss: 0.3557 | Validation AUC: 0.9327 | Validation loss: 0.3696\n",
      "Epoch 00107 | Train AUC: 0.9609 | Train Loss: 0.3558 | Validation AUC: 0.9339 | Validation loss: 0.3696\n",
      "Epoch 00108 | Train AUC: 0.9609 | Train Loss: 0.3558 | Validation AUC: 0.9339 | Validation loss: 0.3696\n",
      "Epoch 00109 | Train AUC: 0.9611 | Train Loss: 0.3557 | Validation AUC: 0.9339 | Validation loss: 0.3696\n",
      "Epoch 00110 | Train AUC: 0.9613 | Train Loss: 0.3556 | Validation AUC: 0.9339 | Validation loss: 0.3696\n",
      "Epoch 00111 | Train AUC: 0.9615 | Train Loss: 0.3556 | Validation AUC: 0.9339 | Validation loss: 0.3696\n",
      "Epoch 00112 | Train AUC: 0.9626 | Train Loss: 0.3555 | Validation AUC: 0.9339 | Validation loss: 0.3696\n",
      "Epoch 00113 | Train AUC: 0.9623 | Train Loss: 0.3555 | Validation AUC: 0.9335 | Validation loss: 0.3696\n",
      "Epoch 00114 | Train AUC: 0.9625 | Train Loss: 0.3555 | Validation AUC: 0.9335 | Validation loss: 0.3696\n",
      "Epoch 00115 | Train AUC: 0.9624 | Train Loss: 0.3555 | Validation AUC: 0.9335 | Validation loss: 0.3692\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-7dadfc892af7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "auc_scores = []\n",
    "\n",
    "for i, (for_train_val_idx, for_test_idx) in enumerate(kf.split(np.arange(len(all_idx)),y=known_labels)):\n",
    "    train_val_idx = all_idx[for_train_val_idx]\n",
    "    train_idx, val_idx = train_test_split(train_val_idx,test_size=0.33,stratify=known_labels[for_train_val_idx])\n",
    "    test_idx = all_idx[for_test_idx]\n",
    "    # create graph\n",
    "    g = DGLGraph()\n",
    "    g.add_nodes(num_nodes)\n",
    "    g.add_edges(merged_network['src'].values, merged_network['dst'].values)\n",
    "    g.edata.update({'rel_type': edge_type, 'norm': edge_norm})\n",
    "    # create model\n",
    "    model = Model(len(g),\n",
    "                  n_hidden,\n",
    "                  num_classes,\n",
    "                  num_rels,\n",
    "                  node_feature_array,\n",
    "                  num_bases=n_bases,\n",
    "                  num_hidden_layers=n_hidden_layers)\n",
    "    # optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=l2norm)\n",
    "    print(\"Start {}-th fold\".format(i))\n",
    "    print(\"==== Train Phase ====\")\n",
    "    model.train()\n",
    "    best_auc = 0.0\n",
    "    best_auc_logits = None\n",
    "    for epoch in range(n_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        logits = model.forward(g)\n",
    "        loss = F.cross_entropy(logits[train_idx], labels[train_idx])\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        train_auc = roc_auc_score(y_true=labels[train_idx].detach().numpy(),y_score=logits[train_idx].detach().numpy()[:,1])\n",
    "        train_loss = F.cross_entropy(logits[train_idx], labels[train_idx])\n",
    "        val_auc = roc_auc_score(y_true=labels[val_idx].detach().numpy(),y_score=logits[val_idx].detach().numpy()[:,1])\n",
    "        val_loss = F.cross_entropy(logits[val_idx], labels[val_idx])\n",
    "        \n",
    "        if val_auc >= best_auc:\n",
    "            best_auc = val_auc\n",
    "            best_auc_logits = logits\n",
    "            \n",
    "        print(\"Epoch {:05d} | \".format(epoch) +\n",
    "              \"Train AUC: {:.4f} | Train Loss: {:.4f} | \".format(\n",
    "                  train_auc, loss.item()) +\n",
    "              \"Validation AUC: {:.4f} | Validation loss: {:.4f}\".format(\n",
    "                  val_auc, val_loss.item()))\n",
    "    print(\"==== Test Phase ====\")\n",
    "    model.eval()\n",
    "    test_auc = roc_auc_score(y_true=labels[test_idx].detach().numpy(),y_score=best_auc_logits[test_idx].detach().numpy()[:,1])\n",
    "    auc_scores.append(test_auc)\n",
    "    print(\"test auc : {}\".format(test_auc))\n",
    "    print(\"=================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.mean(auc_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "結果\n",
    "\n",
    "- (32,16)\n",
    "    - amazon :\n",
    "    - alpha : \n",
    "    - otc : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=l2norm)\n",
    "\n",
    "print(\"start training...\")\n",
    "model.train()\n",
    "for epoch in range(n_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    logits = model.forward(g)\n",
    "    loss = F.cross_entropy(logits[train_idx], labels[train_idx])\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    train_acc = torch.sum(logits[train_idx].argmax(dim=1) == labels[train_idx])\n",
    "    train_acc = train_acc.item() / len(train_idx)\n",
    "    val_loss = F.cross_entropy(logits[val_idx], labels[val_idx])\n",
    "    val_acc = torch.sum(logits[val_idx].argmax(dim=1) == labels[val_idx])\n",
    "    val_acc = val_acc.item() / len(val_idx)\n",
    "    print(\"Epoch {:05d} | \".format(epoch) +\n",
    "          \"Train Accuracy: {:.4f} | Train Loss: {:.4f} | \".format(\n",
    "              train_acc, loss.item()) +\n",
    "          \"Validation Accuracy: {:.4f} | Validation loss: {:.4f}\".format(\n",
    "              val_acc, val_loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = logits[val_idx].detach().numpy()[:,1]\n",
    "\n",
    "y_true = labels[val_idx].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "roc_auc_score(y_true=labels[val_idx].detach().numpy(),y_score=logits[val_idx].detach().numpy()[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_ = plt.hist(logits[val_idx].detach().numpy()[:,1][y_true==1],alpha=0.5)\n",
    "_ = plt.hist(logits[val_idx].detach().numpy()[:,1][y_true==0],alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
